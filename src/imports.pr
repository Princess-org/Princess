import set
import lexer
import toolchain
import parser
import vector

def skip_whitespace(list: **lexer::TokenList) {
    while @list and 
        ((@list).value.tpe == lexer::TokenType::COMMENT or
        (@list).value.tpe == lexer::TokenType::ERROR or
        (@list).value.tpe == lexer::TokenType::WHITESPACE) {
        @list = (@list).next
    }
}

def next_token(list: **lexer::TokenList) -> lexer::Token {
    skip_whitespace(list)
    if not (@list) { return [] !lexer::Token}
    let token = (@list).value
    (@list) = (@list).next
    return token
}

def collect_identifier(list: **lexer::TokenList) -> &parser::Node {
    var token = next_token(list)
    let path = vector::make(String)
    var prefix = false
    if token.tpe == lexer::TokenType::DOUBLE_COLON {
        prefix = true
        token = next_token(list)
    }
    while token.tpe == lexer::TokenType::IDENTIFIER {
        path.push(token.value.str)
        token = next_token(list)
        if token.tpe == lexer::TokenType::DOUBLE_COLON {
            token = next_token(list)
            continue
        } else {
            break
        }
    }

    if path.length == 0 { return null }

    let node = [ kind = parser::NodeKind::IDENTIFIER ] !Node
    node.value.identifier.path = path
    return node
}

export let collected_modules = set::make()

export def find_imports(module: &toolchain::Module) {
    toolchain::progress_update(module, toolchain::ProgressUpdate::START)

    if not module.tokens {
        module.tokens = lexer::lex(module.text)
    }

    let imports = set::make()
    
    // Collect imports
    var list = module.tokens
    var tok = next_token(*list)
    while list != null {
        if tok.tpe == lexer::TokenType::K_IMPORT {
            loop {
                let ident = collect_identifier(*list)
                if ident {
                    let path = identifier_to_path(ident)
                    let file = find_module_file(path, module)
                    if file and not collected_modules.contains(file) {
                        collected_modules.add(file)
                        let new_module = create_module_if_absent(file, parser::identifier_to_str(ident))
                        find_imports(new_module)
                    }
                }
                tok = next_token(*list)
                if tok.tpe == lexer::TokenType::K_IMPORT { continue }
                if tok.tpe == lexer::TokenType::NEW_LINE or tok.tpe == lexer::TokenType::SEMICOLON { break }
                if tok.tpe == lexer::TokenType::K_AS {
                    collect_identifier(*list)
                    tok = next_token(*list)
                }
                if tok.tpe == lexer::TokenType::COMMA {
                    tok = next_token(*list)
                    while tok.tpe == lexer::TokenType::NEW_LINE { tok = next_token(*list) }
                    continue
                }
                break
            }
        }
        tok = next_token(*list)
    }

    toolchain::progress_update(module, toolchain::ProgressUpdate::END)
}