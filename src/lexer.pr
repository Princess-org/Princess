import buffer
import util

// TODO Implement triple quoted strings

// Reserve 0 for empty token
export type TokenType = enum {
    DOT = 1
    COLON
    DOUBLE_COLON
    COMMA
    SEMICOLON
    ARROW
    NEW_LINE
    QUESTION_MARK
    O_PAREN
    C_PAREN
    O_BRACE
    C_BRACE
    O_SQUARE
    C_SQUARE
    OP_RANGE
    OP_RANGE_INC
    OP_VARARGS
    OP_CAST
    OP_AUTOCAST
    OP_DEREF
    OP_ASSIGN
    OP_ADD
    OP_SUB
    OP_MUL
    OP_DIV
    OP_MOD
    OP_BOR
    OP_BAND
    OP_BXOR
    OP_BNOT
    OP_SHL
    OP_SHR
    OP_INC
    OP_DEC
    OP_EQ
    OP_NEQ
    OP_LEQ
    OP_GEQ
    OP_LT
    OP_GT
    OP_PADD_EQ
    OP_PSUB_EQ
    OP_ADD_EQ
    OP_SUB_EQ
    OP_MUL_EQ
    OP_DIV_EQ
    OP_MOD_EQ
    OP_OR_EQ
    OP_AND_EQ
    OP_XOR_EQ
    OP_SHL_EQ
    OP_SHR_EQ
    K_DO
    K_TYPE
    K_ENUM
    K_STRUCT
    K_IF
    K_ELSE
    K_NOT
    K_AND
    K_OR
    K_VAR
    K_LET
    K_CONST
    K_WHILE
    K_TRUE
    K_FALSE
    K_WORD
    K_NULL
    K_SWITCH
    K_FOR
    K_IN
    K_LOOP
    K_CONTINUE
    K_BREAK
    K_RETURN
    K_UNSIGNED
    K_LABEL
    K_GO_TO
    K_CASE
    K_SIZE_OF
    K_ALIGN_OF
    K_DEF
    K_EXPORT
    K_IMPORT
    K_AS
    K_FROM
    INTEGER
    FLOAT
    STRING
    CHAR
    IDENTIFIER
    COMMENT
    ERROR
    PRAGMA
    WHITESPACE
    EOF
}

export type TokenValue = struct #union {
    str: string
    ch: char
    i: uint64
    f: double
}

export type Token = struct {
    tpe: TokenType
    line: int
    column: int
    value: TokenValue
}

export type TokenList = struct {
    value: Token
    next: *TokenList
}

type Keyword = struct {
    token_type: TokenType
    str: string
}

let KEYWORDS = [
    {TokenType::K_DO, "do"} !Keyword,
    {TokenType::K_TYPE, "type"} !Keyword,
    {TokenType::K_ENUM, "enum"} !Keyword,
    {TokenType::K_STRUCT, "struct"} !Keyword,
    {TokenType::K_IF, "if"} !Keyword,
    {TokenType::K_ELSE, "else"} !Keyword,
    {TokenType::K_NOT, "not"} !Keyword,
    {TokenType::K_AND, "and"} !Keyword,
    {TokenType::K_OR, "or"} !Keyword,
    {TokenType::K_VAR, "var"} !Keyword,
    {TokenType::K_LET, "let"} !Keyword,
    {TokenType::K_CONST, "const"} !Keyword,
    {TokenType::K_WHILE, "while"} !Keyword,
    {TokenType::K_TRUE, "true"} !Keyword,
    {TokenType::K_FALSE, "false"} !Keyword,
    {TokenType::K_WORD, "word"} !Keyword,
    {TokenType::K_NULL, "null"} !Keyword,
    {TokenType::K_SWITCH, "switch"} !Keyword,
    {TokenType::K_FOR, "for"} !Keyword,
    {TokenType::K_IN, "in"} !Keyword,
    {TokenType::K_LOOP, "loop"} !Keyword,
    {TokenType::K_CONTINUE, "continue"} !Keyword,
    {TokenType::K_BREAK, "break"} !Keyword,
    {TokenType::K_RETURN, "return"} !Keyword,
    {TokenType::K_UNSIGNED, "unsigned"} !Keyword,
    {TokenType::K_LABEL, "label"} !Keyword,
    {TokenType::K_GO_TO, "go_to"} !Keyword,
    {TokenType::K_CASE, "case"} !Keyword,
    {TokenType::K_SIZE_OF, "size_of"} !Keyword,
    {TokenType::K_ALIGN_OF, "align_of"} !Keyword,
    {TokenType::K_DEF, "def"} !Keyword,
    {TokenType::K_EXPORT, "export"} !Keyword,
    {TokenType::K_IMPORT, "import"} !Keyword,
    {TokenType::K_AS, "as"} !Keyword,
    {TokenType::K_FROM, "from"} !Keyword
]

/* We just leak the memory, thats what we do
export def free_token_list(list: *TokenList) {
    while list != null {
        let value = (@list).value
        if (value.tpe == TokenType::STRING or value.tpe == TokenType::IDENTIFIER or
            value.tpe == TokenType::ERROR or value.tpe == TokenType::COMMENT or
            value.tpe == TokenType::PRAGMA) {
            free(value.value.str)
        }
        var tmp = list
        list = (@list).next
        free(tmp)
    }
}
*/

export def print_token_list(list: *TokenList) {
    while list != null {
        let value = (@list).value
        print(value.line, ":", value.column, " = ", value.tpe, ": ")
        if (value.tpe == TokenType::STRING or value.tpe == TokenType::IDENTIFIER or
            value.tpe == TokenType::ERROR or value.tpe == TokenType::COMMENT or
            value.tpe == TokenType::PRAGMA) {
            let str = value.value.str
            print(str)
        } else if (value.tpe == TokenType::INTEGER) {
            print(value.value.i)
        } else if (value.tpe == TokenType::CHAR) {
            print(value.value.ch)
        } else if (value.tpe == TokenType::FLOAT) {
            print(value.value.f)
        }
        print("\n")
        list = (@list).next
    }
}

def simple_token(tpe: TokenType, line: int, column: int) -> Token {
    return {
        tpe, line, column 
    } !Token
}

def error_token(s: string, line: int, column: int) -> Token {
    var tok = {
        TokenType::ERROR, line, column
    } !Token
    tok.value.str = s
    return tok
}

def valid_hex_char(a: char) -> bool {
    return a >= '0' and a <= '9' or a >= 'a' and a <= 'f' or a >= 'A' and a <= 'F'
}

def parse_hex_char(a: char) -> int {
    if a >= '0' and a <= '9' {
        return a - '0'
    } else if a >= 'a' and a <= 'f' {
        return a - 'a' + 10
    } else if a >= 'A' and a <= 'F' {
        return a - 'A' + 10
    }
    return -1
}

def is_text(a: char) -> bool {
    return a == '_' or a >= 'a' and a <= 'z' or a >= 'A' and a <= 'Z'
}

def is_alphanumeric(a: char) -> bool {
    return is_text(a) or a >= '0' and a <= '9'
}

def parse_simple_escape_sequence(escape_char: char) -> int {
    switch escape_char {
        case 'a': return '\a'
        case 'b': return '\b'
        case 'f': return '\f'
        case 'n': return '\n'
        case 'r': return '\r'
        case 't': return '\t'
        case 'v': return '\v'
        case '0': return '\0'
        case '"': return '"'
        case '\'': return '\''
        case '\\': return '\\'
    }
    return -1
}

// TODO Use a state instead of passing all of these parameters one by one
def next_char(s: string, i: *int, line: *int, column: *int) -> char {
    @i += 1
    @column += 1
    if @i >= length(s) {
        return 0x1A !char
    }

    let c = s[@i]
    return c
}

def peek_char(s: string, i: *int, n: int) -> char {
    if @i + n >= length(s) {
        return 0x1A !char
    }
    return s[@i + n]
}

def parse_string(s: string, i: *int, line: *int, column: *int) -> Token {
    let start_line = @line
    let start_column = @column
    
    var buf = buffer::make_buffer()
    var end_of_string = false
    while @i < length(s) {
        let c = next_char(s, i, line, column)
        if c == '\\' {
            let escape_char = next_char(s, i, line, column)
            let c = parse_simple_escape_sequence(escape_char)
            if c >= 0 {
                buffer::append_char(*buf, c !char)
            } else if escape_char == 'x' or escape_char == 'u' or escape_char == 'U' {

                var count: int
                if escape_char == 'x' {
                    count = 1
                } else if escape_char == 'u' {
                    count = 2
                } else {
                    count = 4
                }

                var code_point: uint64 = 0
                for var v in 0..count {
                    let e1 = next_char(s, i, line, column)
                    let e2 = next_char(s, i, line, column)

                    if not valid_hex_char(e1) or not valid_hex_char(e2) {
                        return error_token("Invalid escape sequence\n", start_line, start_column)
                    }
                    let esc_char = parse_hex_char(e1) << 4 | parse_hex_char(e2)
                    code_point = code_point << 8 | esc_char
                }
                if count == 1 {
                    buffer::append_char(*buf, code_point !char)
                } else {
                    if code_point <= 0x007F {
                        buffer::append_char(*buf, code_point !char)
                    } else if code_point <= 0x07FF {
                        buffer::append_char(*buf, ((code_point >> 6) | 0b11000000) !char)
                        buffer::append_char(*buf, (code_point & 0b00111111 | 0b10000000) !char)
                    } else if code_point <= 0xFFFF {
                        buffer::append_char(*buf, ((code_point >> 12) | 0b11100000) !char)
                        buffer::append_char(*buf, ((code_point >> 6 & 0b00111111) | 0b10000000) !char)
                        buffer::append_char(*buf, (code_point & 0b00111111 | 0b10000000) !char)
                    } else if code_point <= 0x10FFFF {
                        buffer::append_char(*buf, ((code_point >> 18) | 0b11110000) !char)
                        buffer::append_char(*buf, ((code_point >> 12 & 0b00111111) | 0b10000000) !char)
                        buffer::append_char(*buf, ((code_point >> 6 & 0b00111111) | 0b10000000) !char)
                        buffer::append_char(*buf, (code_point & 0b00111111 | 0b10000000) !char)
                    } else {
                        return error_token("Invalid unicode sequence\n", start_line, start_column)
                    }
                }
            } else if escape_char == '\n' {
                @line += 1
                @column = 0
            } else {
                return error_token("Invalid escape sequence\n", start_line, start_column)
            }
        } else if c == '"' {
            end_of_string = true
            break
        } else if c == '\n' {
            @line += 1
            @column = 0
            buffer::append_char(*buf, c)
        } else {
            buffer::append_char(*buf, c)
        }
    }

    if not end_of_string {
        return error_token("Unexpected end of file while parsing string literal\n", start_line, start_column)
    }

    next_char(s, i, line, column)
    let str = buffer::to_string(*buf)
    let tok = {
        TokenType::STRING, start_line, start_column
    } !Token
    tok.value.str = str
    return tok
}

def parse_char(s: string, i: *int, line: *int, column: *int) -> Token {
    let start_line = @line
    let start_column = @column

    var result: char
    let c = next_char(s, i, line, column)
    if c == '\\' {
        let escape_char = next_char(s, i, line, column)
        let c = parse_simple_escape_sequence(escape_char)
        if c >= 0 {
            result = c !char
        } else if escape_char == 'x' {            
            let e1 = next_char(s, i, line, column)
            let e2 = next_char(s, i, line, column)
            if not valid_hex_char(e1) or not valid_hex_char(e2) {
                return error_token("Invalid escape sequence\n", start_line, start_column)
            }
            let esc_char = parse_hex_char(e1) << 4 | parse_hex_char(e2)
            result = esc_char !char
        } else {
            return error_token("Invalid escape sequence\n", start_line, start_column)
        }
    } else if c == '\n' {
        @line += 1
        @column = 0
        return error_token("Unexpected new line\n", start_line, start_column) 
    } else {
        result = c
    }
    
    if next_char(s, i, line, column) == '\'' {
        next_char(s, i, line, column)
        var tok = {
            TokenType::CHAR, start_line, start_column
        } !Token
        tok.value.ch = result
        return tok
    }

    return error_token("Unexpected end of file while parsing character\n", start_line, start_column)
}

// TODO Refactor the following three functions into one

def parse_hex_int(s: string, i: *int, line: *int, column: *int) -> Token {
    let start_line = @line
    let start_column = @column

    next_char(s, i, line, column)
    next_char(s, i, line, column)

    var result: uint64 = 0
    while @i < length(s) {
        let c = peek_char(s, i, 0)
        if valid_hex_char(c) {
            result *= 16
            result += parse_hex_char(c)
            next_char(s, i, line, column)
        } else {
            break  
        }
    }

    let tok = {
        TokenType::INTEGER, start_line, start_column
    } !Token
    tok.value.i = result
    return tok
}

def parse_oct_int(s: string, i: *int, line: *int, column: *int) -> Token {
    let start_line = @line
    let start_column = @column

    next_char(s, i, line, column)
    next_char(s, i, line, column)

    var result: uint64 = 0
    while @i < length(s) {
        let c = peek_char(s, i, 0)
        if c >= '0' and c <= '7' {
            result *= 8
            result += c - '0'
            next_char(s, i, line, column)
        } else {
            break  
        }
    }

    let tok = {
        TokenType::INTEGER, start_line, start_column
    } !Token
    tok.value.i = result
    return tok
}

def parse_bin_int(s: string, i: *int, line: *int, column: *int) -> Token {
    let start_line = @line
    let start_column = @column

    next_char(s, i, line, column)
    next_char(s, i, line, column)

    var result: uint64 = 0
    while @i < length(s) {
        let c = peek_char(s, i, 0)
        if c >= '0' and c <= '1' {
            result *= 2
            result += c - '0'
            next_char(s, i, line, column)
        } else {
            break  
        }
    }

    let tok = {
        TokenType::INTEGER, start_line, start_column
    } !Token
    tok.value.i = result
    return tok
}

def parse_int(s: string, i: *int, line: *int, column: *int) -> Token {
    let start_line = @line
    let start_column = @column

    let c = peek_char(s, i, 0)
    if c == '0' {
        let r = peek_char(s, i, 1)
        if r == 'b' {
            return parse_bin_int(s, i, line, column)
        } else if r == 'o' {
            return parse_oct_int(s, i, line, column)
        } else if r == 'x' {
            return parse_hex_int(s, i, line, column)
        }
    }

    var result: uint64 = 0
    while @i < length(s) {
        let c = peek_char(s, i, 0)
        if c >= '0' and c <= '9' {
            result *= 10
            result += c - '0'
            next_char(s, i, line, column)
        } else {
            break  
        }
    }
    
    let tok = {
        TokenType::INTEGER, start_line, start_column
    } !Token
    tok.value.i = result
    return tok
}

def parse_float(s: string, i: *int, line: *int, column: *int) -> Token {
    let start_line = @line
    let start_column = @column

    var a = 0.0
    var e = 0
    var c = peek_char(s, i, 0)

    while c >= '0' and c <= '9' {
        a = a * 10 + c - '0'
        c = next_char(s, i, line, column)
    }
    if c == '.' {
        c = next_char(s, i, line, column)
        while c >= '0' and c <= '9' {
            a = a * 10 + c - '0'
            e -= 1
            c = next_char(s, i, line, column)
        }
    }
    if c == 'e' or c == 'E' {
        var sign = 1
        var j = 0
        c = next_char(s, i, line, column)
        if c == '-' {
            sign = -1
            c = next_char(s, i, line, column)
        } else if c == '+' {
            c = next_char(s, i, line, column)
        }
        while c >= '0' and c <= '9' {
            j = j * 10 + c - '0'
            c = next_char(s, i, line, column)
        }
        e += j * sign
    }
    while e > 0 {
        a *= 10
        e -= 1
    }
    while e < 0 {
        a *= 0.1
        e += 1
    }

    let tok = {
        TokenType::FLOAT, start_line, start_column
    } !Token
    tok.value.f = a
    return tok
}

def parse_number(s: string, i: *int, line: *int, column: *int) -> Token {
    let start_line = @line
    let start_column = @column

    var j = 0
    var is_float = false
    loop {
        let c = peek_char(s, i, j)
        if c == '.' {
            let c2 = peek_char(s, i, j + 1)
            if c2 != '.' {
                is_float = true
            }
            break
        } else if c == 'e' or c == 'E' {
            is_float = true
            break
        } else if c >= '0' and c <= '9' {
            j += 1
        } else {
            break
        }
    }

    if is_float {
        return parse_float(s, i, line, column)
    }
    return parse_int(s, i, line, column)
}

def parse_identifier(s: string, i: *int, line: *int, column: *int) -> Token {
    let start_line = @line
    let start_column = @column

    var c = peek_char(s, i, 0)
    var buf = buffer::make_buffer()
    while is_alphanumeric(c) {
        buffer::append_char(*buf, c)
        c = next_char(s, i, line, column)
    }
    let str = buffer::to_string(*buf)

    for var i in 0..KEYWORDS.size {
        let keyword = KEYWORDS[i]
        if keyword.str == str {
            return simple_token(keyword.token_type, start_line, start_column)
        }
    }

    let tok = {
        TokenType::IDENTIFIER, start_line, start_column
    } !Token
    tok.value.str = str
    return tok
}

def parse_eol_comment(s: string, i: *int, line: *int, column: *int) -> Token {
    let start_line = @line
    let start_column = @column
    
    var buf = buffer::make_buffer()

    next_char(s, i, line, column)
    next_char(s, i, line, column)
    buffer::append_str(*buf, "//")

    var c = peek_char(s, i, 0)
    while c != '\n' and c != 0x1A {
        buffer::append_char(*buf, c)
        c = next_char(s, i, line, column)
    }
    var str = buffer::to_string(*buf)
    
    let tok = {
        TokenType::COMMENT, start_line, start_column
    } !Token
    tok.value.str = str

    return tok
}

def parse_comment(s: string, i: *int, line: *int, column: *int) -> Token {
    let start_line = @line
    let start_column = @column

    var buf = buffer::make_buffer()

    next_char(s, i, line, column)
    next_char(s, i, line, column)
    buffer::append_str(*buf, "/*")

    var depth = 1
    var c = peek_char(s, i, 0)
    while depth > 0 and c != 0x1A {
        buffer::append_char(*buf, c)

        if c == '/' {
            if peek_char(s, i, 1) == '*' {
                depth += 1
                buffer::append_char(*buf, '*')
                next_char(s, i, line, column)
            }
        } else if c == '*' {
            if peek_char(s, i, 1) == '/' {
                depth -= 1
                buffer::append_char(*buf, '/')
                next_char(s, i, line, column)
            }
        } else if c == '\n' {
            @line += 1
            @column = 0
        }
        c = next_char(s, i, line, column)
    }

    var str = buffer::to_string(*buf)
    let tok = {
        TokenType::COMMENT, start_line, start_column
    } !Token
    tok.value.str = str
    return tok
}

def parse_pragma(s: string, i: *int, line: *int, column: *int) -> Token {
    let start_line = @line
    let start_column = @column

    var buf = buffer::make_buffer()
    var c = peek_char(s, i, 0)
    while c == '#' or is_text(c) or is_alphanumeric(c) {
        buffer::append_char(*buf, c)
        c = next_char(s, i, line, column)
    }

    var str = buffer::to_string(*buf)
    let tok = {
        TokenType::PRAGMA, start_line, start_column
    } !Token
    tok.value.str = str
    return tok  
}

def parse_symbol(s: string, i: *int, line: *int, column: *int) -> Token {
    let start_line = @line
    let start_column = @column

    let first = peek_char(s, i, 0)
    let second = peek_char(s, i, 1)
    let third = peek_char(s, i, 2)

    var tt: TokenType = TokenType::ERROR
    var length = 3

    if first == '<' and second == '<' and third == '=' {
        tt = TokenType::OP_SHL_EQ
    } else if first == '>' and second == '>' and third == '=' {
        tt = TokenType::OP_SHR_EQ
    } else if first == '+' and second == '+' and third == '=' {
        tt = TokenType::OP_PADD_EQ
    } else if first == '-' and second == '-' and third == '=' {
        tt = TokenType::OP_PSUB_EQ
    } else if first == '.' and second == '.' and third == '=' {
        tt = TokenType::OP_RANGE_INC
    } else if first == '.' and second == '.' and third == '.' {
        tt = TokenType::OP_VARARGS
    } else {
        length = 2
        if second == '=' {
            switch first {
                case '+': tt = TokenType::OP_ADD_EQ
                case '-': tt = TokenType::OP_SUB_EQ
                case '*': tt = TokenType::OP_MUL_EQ
                case '/': tt = TokenType::OP_DIV_EQ
                case '%': tt = TokenType::OP_MOD_EQ
                case '&': tt = TokenType::OP_AND_EQ
                case '|': tt = TokenType::OP_OR_EQ
                case '^': tt = TokenType::OP_XOR_EQ
                case '!': tt = TokenType::OP_NEQ
                case '>': tt = TokenType::OP_GEQ
                case '<': tt = TokenType::OP_LEQ
                case '=': tt = TokenType::OP_EQ
            }
        } else if first == '.' and second == '.' {
            tt = TokenType::OP_RANGE
        } else if first == '!' and second == '!' {
            tt = TokenType::OP_AUTOCAST
        } else if first == '-' and second == '>' {
            tt = TokenType::ARROW
        } else if first == ':' and second == ':' {
            tt = TokenType::DOUBLE_COLON
        } else if first == '+' and second == '+' {
            tt = TokenType::OP_INC
        } else if first == '-' and second == '-' {
            tt = TokenType::OP_DEC
        } else if first == '<' and second == '<' {
            tt = TokenType::OP_SHL
        } else if first == '>' and second == '>' {
            tt = TokenType::OP_SHR
        } else {
            length = 1
            switch first {
                case '>': tt = TokenType::OP_GT
                case '<': tt = TokenType::OP_LT
                case '{': tt = TokenType::O_BRACE
                case '}': tt = TokenType::C_BRACE
                case '[': tt = TokenType::O_SQUARE
                case ']': tt = TokenType::C_SQUARE
                case '+': tt = TokenType::OP_ADD
                case '-': tt = TokenType::OP_SUB
                case '*': tt = TokenType::OP_MUL
                case '/': tt = TokenType::OP_DIV
                case '%': tt = TokenType::OP_MOD
                case '&': tt = TokenType::OP_BAND
                case '|': tt = TokenType::OP_BOR
                case '^': tt = TokenType::OP_BXOR
                case '~': tt = TokenType::OP_BNOT
                case '!': tt = TokenType::OP_CAST
                case '@': tt = TokenType::OP_DEREF  
                case '=': tt = TokenType::OP_ASSIGN                    
                case ',': tt = TokenType::COMMA  
                case ':': tt = TokenType::COLON
                case '?': tt = TokenType::QUESTION_MARK
                case '.': tt = TokenType::DOT
                case ';': tt = TokenType::SEMICOLON
            }
        }
    }

    if tt == TokenType::ERROR {
        next_char(s, i, line, column)
        return error_token("Invalid symbol\n", start_line, start_column)
    }
    
    for var j in 0..length {
        next_char(s, i, line, column)
    }
    return simple_token(tt, start_line, start_column)
}

def is_whitespace(c: char) -> bool {
    return c == ' ' or c == '\t' or c == '\r'
}

def parse_whitespace(depth: int, s: string, i: *int, line: *int, column: *int) -> Token {
    let start_line = @line
    let start_column = @column

    var c = peek_char(s, i, 0)
    while is_whitespace(c) or (c == '\n' and depth > 0) {
        if c == '\n' {
            @line += 1
            @column = 0
        }
        c = next_char(s, i, line, column)
    }
    return simple_token(TokenType::WHITESPACE, start_line, start_column)
}

export def lex(s: string) -> *TokenList {
    var line = 0
    var column = 0
    var i = 0

    var token_list = allocate(TokenList)
    var head = token_list
    var depth = 0

    while i < length(s) {
        let c = peek_char(s, *i, 0)

        var token: Token
        if is_whitespace(c) or c == '\n' and depth > 0 {
            // TODO Make this work inside {}
            token = parse_whitespace(depth, s, *i, *line, *column)
        } else if c == '\n' {
            token = simple_token(TokenType::NEW_LINE, line, column)
            column = 0
            line += 1
            i += 1
        } else if c == '(' {
            depth += 1
            token = simple_token(TokenType::O_PAREN, line, column)
            i += 1
            column += 1
        } else if c == ')' {
            depth -= 1
            token = simple_token(TokenType::C_PAREN, line, column)
            i += 1
            column += 1            
        } else if c == '"' {
            token = parse_string(s, *i, *line, *column)
        } else if c == '\'' {
            token = parse_char(s, *i, *line, *column)
        } else if c >= '0' and c <= '9' {
            token = parse_number(s, *i, *line, *column)
        } else if c == '.' {
            let next = peek_char(s, *i, 1)
            if next >= '0' and next <= '9' {
                token = parse_number(s, *i, *line, *column)
            } else {
                token = parse_symbol(s, *i, *line, *column)
            }
        } else if c == '#' {
            token = parse_pragma(s, *i, *line, *column)
        } else if is_text(c) {
            token = parse_identifier(s, *i, *line, *column)
        } else if c == '/' {
            let next = peek_char(s, *i, 1)
            if next == '/' {
                token = parse_eol_comment(s, *i, *line, *column)
            } else if next == '*' {
                token = parse_comment(s, *i, *line, *column)
            } else {
                token = parse_symbol(s, *i, *line, *column)
            }
        } else {
            token = parse_symbol(s, *i, *line, *column)
        }

        (@token_list).value = token
        (@token_list).next = allocate(TokenList)
        token_list = (@token_list).next
    }
    (@token_list).value = simple_token(TokenType::EOF, line, column)
    (@token_list).next = null

    return head
}