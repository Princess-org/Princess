import util
import json

// Reserve 0 for empty token
export type TokenType = enum {
    DOT = 1
    COLON
    DOUBLE_COLON
    COMMA
    SEMICOLON
    ARROW
    NEW_LINE
    QUESTION_MARK
    O_PAREN
    C_PAREN
    O_BRACE
    C_BRACE
    O_SQUARE
    C_SQUARE
    OP_RANGE
    OP_RANGE_INC
    OP_VARARGS
    OP_CAST
    OP_AUTOCAST
    OP_DEREF
    OP_ASSIGN
    OP_ADD
    OP_SUB
    OP_MUL
    OP_DIV
    OP_MOD
    OP_BOR
    OP_BAND
    OP_BXOR
    OP_BNOT
    OP_SHL
    OP_SHR
    OP_INC
    OP_DEC
    OP_EQ
    OP_NEQ
    OP_LEQ
    OP_GEQ
    OP_LT
    OP_GT
    OP_PADD_EQ
    OP_PSUB_EQ
    OP_ADD_EQ
    OP_SUB_EQ
    OP_MUL_EQ
    OP_DIV_EQ
    OP_MOD_EQ
    OP_OR_EQ
    OP_AND_EQ
    OP_XOR_EQ
    OP_SHL_EQ
    OP_SHR_EQ
    K_DO
    K_TYPE
    K_ENUM
    K_STRUCT
    K_INTERFACE
    K_IF
    K_ELSE
    K_NOT
    K_AND
    K_OR
    K_VAR
    K_LET
    K_CONST
    K_WHILE
    K_TRUE
    K_FALSE
    K_WORD
    K_NULL
    K_SWITCH
    K_FOR
    K_IN
    K_LOOP
    K_CONTINUE
    K_BREAK
    K_RETURN
    K_YIELD
    K_UNSIGNED
    K_LABEL
    K_GO_TO
    K_CASE
    K_SIZE_OF
    K_ALIGN_OF
    K_DEF
    K_EXPORT
    K_IMPORT
    K_IMPLICIT
    K_AS
    K_FROM
    K_DEFINED
    K_DEFER
    K_ASSERT
    K_TYPE_OF
    K_UNDEF
    K_WEAK_REF
    INTEGER
    FLOAT
    STRING
    CHAR
    IDENTIFIER
    COMMENT
    ERROR
    PRAGMA
    WHITESPACE
    EOF
}

export type TokenValue = struct #union {
    str: StringSlice
    ch: char
    i: uint64
    f: double
}

export type Token = struct {
    tpe: TokenType
    line: int
    column: int
    end_line: int
    end_column: int
    value: TokenValue
}

export def destruct(token: *Token) {
    if token.tpe == TokenType::IDENTIFIER or
        token.tpe == TokenType::COMMENT or
        token.tpe == TokenType::ERROR or
        token.tpe == TokenType::PRAGMA or
        token.tpe == TokenType::STRING {
        __destruct__(*token.value.str)
    }
}

export def construct(copy: *Token, this: *Token) {
    copy.tpe = this.tpe
    copy.line = this.line
    copy.column = this.column
    copy.end_line = this.end_line
    copy.end_column = this.end_column

    if this.tpe == TokenType::IDENTIFIER or
        this.tpe == TokenType::COMMENT or
        this.tpe == TokenType::ERROR or 
        this.tpe == TokenType::PRAGMA or
        this.tpe == TokenType::STRING {
        copy.value.str = this.value.str
    } else {
        copy.value = this.value
    }
}

export type TokenList = struct {
    value: Token
    next: *TokenList
}

export def destruct(list: *TokenList) {
    list = list.next
    while list != null {
        let next = list.next
        destruct(*list.value)
        free(list)
        list = next
    }
}
type Keyword = struct {
    token_type: TokenType
    str: StringSlice
}

let KEYWORDS = [
    {TokenType::K_DO, "do"} !Keyword,
    {TokenType::K_TYPE, "type"} !Keyword,
    {TokenType::K_ENUM, "enum"} !Keyword,
    {TokenType::K_STRUCT, "struct"} !Keyword,
    {TokenType::K_INTERFACE, "interface"} !Keyword,
    {TokenType::K_IF, "if"} !Keyword,
    {TokenType::K_ELSE, "else"} !Keyword,
    {TokenType::K_NOT, "not"} !Keyword,
    {TokenType::K_AND, "and"} !Keyword,
    {TokenType::K_OR, "or"} !Keyword,
    {TokenType::K_VAR, "var"} !Keyword,
    {TokenType::K_LET, "let"} !Keyword,
    {TokenType::K_CONST, "const"} !Keyword,
    {TokenType::K_WHILE, "while"} !Keyword,
    {TokenType::K_TRUE, "true"} !Keyword,
    {TokenType::K_FALSE, "false"} !Keyword,
    {TokenType::K_WORD, "word"} !Keyword,
    {TokenType::K_NULL, "null"} !Keyword,
    {TokenType::K_SWITCH, "switch"} !Keyword,
    {TokenType::K_FOR, "for"} !Keyword,
    {TokenType::K_IN, "in"} !Keyword,
    {TokenType::K_LOOP, "loop"} !Keyword,
    {TokenType::K_CONTINUE, "continue"} !Keyword,
    {TokenType::K_BREAK, "break"} !Keyword,
    {TokenType::K_RETURN, "return"} !Keyword,
    {TokenType::K_UNSIGNED, "unsigned"} !Keyword,
    {TokenType::K_LABEL, "label"} !Keyword,
    {TokenType::K_GO_TO, "go_to"} !Keyword,
    {TokenType::K_CASE, "case"} !Keyword,
    {TokenType::K_SIZE_OF, "size_of"} !Keyword,
    {TokenType::K_ALIGN_OF, "align_of"} !Keyword,
    {TokenType::K_UNDEF, "undef"} !Keyword,
    {TokenType::K_DEF, "def"} !Keyword,
    {TokenType::K_EXPORT, "export"} !Keyword,
    {TokenType::K_IMPORT, "import"} !Keyword,
    {TokenType::K_ASSERT, "assert"} !Keyword,
    {TokenType::K_AS, "as"} !Keyword,
    {TokenType::K_FROM, "from"} !Keyword,
    {TokenType::K_DEFINED, "defined"} !Keyword,
    {TokenType::K_DEFER, "defer"} !Keyword,
    {TokenType::K_TYPE_OF, "type_of"} !Keyword,
    {TokenType::K_WEAK_REF, "weak_ref"} !Keyword,
    {TokenType::K_YIELD, "yield"} !Keyword,
    {TokenType::K_IMPLICIT, "implicit"} !Keyword
]

export def token_list_to_json(list: *TokenList) -> &Json {
    let res = json::make_array()
    while list != null {
        let value = list.value
        let token = json::make_object()
        token("kind") = to_string(value.tpe)
        token("line") = value.line !double
        token("column") = value.column !double
        if (value.tpe == TokenType::STRING or value.tpe == TokenType::IDENTIFIER or
            value.tpe == TokenType::ERROR or value.tpe == TokenType::COMMENT or
            value.tpe == TokenType::PRAGMA) {
            let str = value.value.str
            token("value") = str
        } else if (value.tpe == TokenType::INTEGER) {
            token("value") = value.value.i !double
        } else if (value.tpe == TokenType::CHAR) {
            token("value") = value.value.ch !double
        } else if (value.tpe == TokenType::FLOAT) {
            token("value") = value.value.f
        }
        list = list.next
        res.push(token)
    }
    return res
}

def simple_token(tpe: TokenType, line: int, column: int, end_line: int, end_column: int) -> Token {
    return {
        tpe, line, column, end_line, end_column
    } !Token
}

def error_token(s: String, line: int, column: int, end_line: int, end_column: int) -> Token {
    var tok = {
        TokenType::ERROR, line, column, end_line, end_column
    } !Token
    tok.value.str = s
    return tok
}

def valid_hex_char(a: char) -> bool {
    return a >= '0' and a <= '9' or a >= 'a' and a <= 'f' or a >= 'A' and a <= 'F'
}

def parse_hex_char(a: char) -> int {
    if a >= '0' and a <= '9' {
        return a - '0'
    } else if a >= 'a' and a <= 'f' {
        return a - 'a' + 10
    } else if a >= 'A' and a <= 'F' {
        return a - 'A' + 10
    }
    return -1
}

def is_text(a: char) -> bool {
    return a == '_' or a >= 'a' and a <= 'z' or a >= 'A' and a <= 'Z'
}

def is_alphanumeric(a: char) -> bool {
    return is_text(a) or a >= '0' and a <= '9'
}

def parse_simple_escape_sequence(escape_char: char) -> int {
    switch escape_char {
        case 'a': return '\a'
        case 'b': return '\b'
        case 'f': return '\f'
        case 'n': return '\n'
        case 'r': return '\r'
        case 't': return '\t'
        case 'v': return '\v'
        case '0': return '\0'
        case '"': return '"'
        case '\'': return '\''
        case '\\': return '\\'
    }
    return -1
}

// TODO Use a state instead of passing all of these parameters one by one
def next_char(s: Str, i: *int, line: *int, column: *int) -> char {
    @i += 1
    if @i >= length(s) {
        return 0x1A !char
    }

    let c = s(@i)
    @column += 1
    return c
}

def peek_char(s: Str, i: *int, n: int) -> char {
    if @i + n >= length(s) {
        return 0x1A !char
    }
    return s(@i + n)
}

def parse_string(s: Str, triple_quoted: bool, i: *int, line: *int, column: *int) -> Token {
    let start_line = @line
    let start_column = @column
    
    var res: StringBuffer = ""
    var end_of_string = false
    while @i < length(s) {
        let c = next_char(s, i, line, column)
        if c == '\\' {
            let escape_char = next_char(s, i, line, column)
            let c = parse_simple_escape_sequence(escape_char)
            if c >= 0 {
                res += c !char
            } else if escape_char == 'x' or escape_char == 'u' or escape_char == 'U' {

                var count: int
                if escape_char == 'x' {
                    count = 1
                } else if escape_char == 'u' {
                    count = 2
                } else {
                    count = 4
                }

                var code_point: uint64 = 0
                for var v in 0..count {
                    let e1 = next_char(s, i, line, column)
                    let e2 = next_char(s, i, line, column)

                    if not valid_hex_char(e1) or not valid_hex_char(e2) {
                        return error_token("Invalid escape sequence", start_line, start_column, @line, @column)
                    }
                    let esc_char = parse_hex_char(e1) << 4 | parse_hex_char(e2)
                    code_point = code_point << 8 | esc_char
                }
                if count == 1 {
                    res += code_point !char
                } else {
                    if code_point <= 0x10FFFF {
                        res += utf8_encode(code_point)
                    } else {
                        return error_token("Invalid unicode sequence", start_line, start_column, @line, @column)
                    }
                }
            } else if escape_char == '\n' {
                @line += 1
                @column = 0
            } else {
                return error_token("Invalid escape sequence", start_line, start_column, @line, @column)
            }
        } else if c == '"' {
            if triple_quoted {
                if peek_char(s, i, 1) == '"' and peek_char(s, i, 2) == '"' {
                    @i += 2
                    end_of_string = true
                    break
                } else {
                    res += c
                }
            } else {
                end_of_string = true
                break
            }
        } else if c == '\n' {
            @line += 1
            @column = 0
            res += c
        } else {
            res += c
        }
    }

    if not end_of_string {
        return error_token("Unexpected end of file while parsing string literal", start_line, start_column, @line, @column)
    }

    next_char(s, i, line, column)
    let tok = simple_token(TokenType::STRING, start_line, start_column, @line, @column)
    tok.value.str = to_slice(res.to_str())
    return tok
}

def parse_char(s: Str, i: *int, line: *int, column: *int) -> Token {
    let start_line = @line
    let start_column = @column

    var result: char
    let c = next_char(s, i, line, column)
    if c == '\\' {
        let escape_char = next_char(s, i, line, column)
        let c = parse_simple_escape_sequence(escape_char)
        if c >= 0 {
            result = c !char
        } else if escape_char == 'x' {            
            let e1 = next_char(s, i, line, column)
            let e2 = next_char(s, i, line, column)
            if not valid_hex_char(e1) or not valid_hex_char(e2) {
                return error_token("Invalid escape sequence", start_line, start_column, @line, @column)
            }
            let esc_char = parse_hex_char(e1) << 4 | parse_hex_char(e2)
            result = esc_char !char
        } else {
            return error_token("Invalid escape sequence", start_line, start_column, @line, @column)
        }
    } else if c == '\n' {
        @line += 1
        @column = 0
        return error_token("Unexpected new line", start_line, start_column, @line, @column) 
    } else {
        result = c
    }
    
    if next_char(s, i, line, column) == '\'' {
        next_char(s, i, line, column)
        var tok = simple_token(TokenType::CHAR, start_line, start_column, @line, @column)
        tok.value.ch = result
        return tok
    }

    return error_token("Unexpected end of file while parsing character", start_line, start_column, @line, @column)
}

// TODO Refactor the following three functions into one

def parse_hex_int(s: Str, i: *int, line: *int, column: *int) -> Token {
    let start_line = @line
    let start_column = @column

    next_char(s, i, line, column)
    next_char(s, i, line, column)

    var result: uint64 = 0
    while @i < length(s) {
        let c = peek_char(s, i, 0)
        if valid_hex_char(c) {
            result *= 16
            result += parse_hex_char(c)
            next_char(s, i, line, column)
        } else {
            break  
        }
    }

    let tok = simple_token(TokenType::INTEGER, start_line, start_column, @line, @column)
    tok.value.i = result
    return tok
}

def parse_oct_int(s: Str, i: *int, line: *int, column: *int) -> Token {
    let start_line = @line
    let start_column = @column

    next_char(s, i, line, column)
    next_char(s, i, line, column)

    var result: uint64 = 0
    while @i < length(s) {
        let c = peek_char(s, i, 0)
        if c >= '0' and c <= '7' {
            result *= 8
            result += c - '0'
            next_char(s, i, line, column)
        } else {
            break  
        }
    }

    let tok = simple_token(TokenType::INTEGER, start_line, start_column, @line, @column)
    tok.value.i = result
    return tok
}

def parse_bin_int(s: Str, i: *int, line: *int, column: *int) -> Token {
    let start_line = @line
    let start_column = @column 

    next_char(s, i, line, column)
    next_char(s, i, line, column)

    var result: uint64 = 0
    while @i < length(s) {
        let c = peek_char(s, i, 0)
        if c >= '0' and c <= '1' {
            result *= 2
            result += c - '0'
            next_char(s, i, line, column)
        } else {
            break  
        }
    }

    let tok = simple_token(TokenType::INTEGER, start_line, start_column, @line, @column)
    tok.value.i = result
    return tok
}

def parse_int(s: Str, i: *int, line: *int, column: *int) -> Token {
    let start_line = @line
    let start_column = @column

    let c = peek_char(s, i, 0)
    if c == '0' {
        let r = peek_char(s, i, 1)
        if r == 'b' {
            return parse_bin_int(s, i, line, column)
        } else if r == 'o' {
            return parse_oct_int(s, i, line, column)
        } else if r == 'x' {
            return parse_hex_int(s, i, line, column)
        }
    }

    var result: uint64 = 0
    while @i < length(s) {
        let c = peek_char(s, i, 0)
        if c >= '0' and c <= '9' {
            result *= 10
            result += c - '0'
            next_char(s, i, line, column)
        } else {
            break  
        }
    }
    
    let tok = simple_token(TokenType::INTEGER, start_line, start_column, @line, @column)
    tok.value.i = result
    return tok
}

// TODO This gives the "wrong" bits for 10.555 
def parse_float(s: Str, i: *int, line: *int, column: *int) -> Token {
    let start_line = @line
    let start_column = @column

    var a = 0.0
    var e = 0
    var c = peek_char(s, i, 0)

    while c >= '0' and c <= '9' {
        a = a * 10 + c - '0'
        c = next_char(s, i, line, column)
    }
    if c == '.' {
        c = next_char(s, i, line, column)
        while c >= '0' and c <= '9' {
            a = a * 10 + c - '0'
            e -= 1
            c = next_char(s, i, line, column)
        }
    }
    if c == 'e' or c == 'E' {
        var sign = 1
        var j = 0
        c = next_char(s, i, line, column)
        if c == '-' {
            sign = -1
            c = next_char(s, i, line, column)
        } else if c == '+' {
            c = next_char(s, i, line, column)
        }
        while c >= '0' and c <= '9' {
            j = j * 10 + c - '0'
            c = next_char(s, i, line, column)
        }
        e += j * sign
    }
    while e > 0 {
        a *= 10
        e -= 1
    }
    while e < 0 {
        a *= 0.1
        e += 1
    }

    let tok = simple_token(TokenType::FLOAT, start_line, start_column, @line, @column)
    tok.value.f = a
    return tok
}

def parse_number(s: Str, i: *int, line: *int, column: *int) -> Token {
    let start_line = @line
    let start_column = @column

    var j = 0
    var is_float = false
    loop {
        let c = peek_char(s, i, j)
        if c == '.' {
            let c2 = peek_char(s, i, j + 1)
            if c2 != '.' {
                is_float = true
            }
            break
        } else if c == 'e' or c == 'E' {
            is_float = true
            break
        } else if c >= '0' and c <= '9' {
            j += 1
        } else {
            break
        }
    }

    if is_float {
        return parse_float(s, i, line, column)
    }
    return parse_int(s, i, line, column)
}

def parse_identifier(s: Str, i: *int, line: *int, column: *int) -> Token {
    let start_line = @line
    let start_column = @column

    var c = peek_char(s, i, 0)
    var start = @i
    while is_alphanumeric(c) {
        c = next_char(s, i, line, column)
    }

    for var j in 0..KEYWORDS.size {
        let keyword = KEYWORDS(j)
        if keyword.str == s.slice(start, @i) {
            return simple_token(keyword.token_type, start_line, start_column, @line, @column)
        }
    }

    let tok = simple_token(TokenType::IDENTIFIER, start_line, start_column, @line, @column)
    tok.value.str = s.slice(start, @i)
    return tok
}

def parse_eol_comment(s: Str, i: *int, line: *int, column: *int) -> Token {
    let start_line = @line
    let start_column = @column
    let start = @i

    next_char(s, i, line, column)
    next_char(s, i, line, column)

    var c = peek_char(s, i, 0)
    while c != '\n' and c != 0x1A {
        c = next_char(s, i, line, column)
    }
    
    let tok = simple_token(TokenType::COMMENT, start_line, start_column, @line, @column)
    tok.value.str = s.slice(start, @i)

    return tok
}

def parse_comment(s: Str, i: *int, line: *int, column: *int) -> Token {
    let start_line = @line
    let start_column = @column
    let start = @i

    next_char(s, i, line, column)
    next_char(s, i, line, column)

    var depth = 1
    var c = peek_char(s, i, 0)
    while depth > 0 and c != 0x1A {
        if c == '/' {
            if peek_char(s, i, 1) == '*' {
                depth += 1
                next_char(s, i, line, column)
            }
        } else if c == '*' {
            if peek_char(s, i, 1) == '/' {
                depth -= 1
                next_char(s, i, line, column)
            }
        } else if c == '\n' {
            @line += 1
            @column = 0
        }
        c = next_char(s, i, line, column)
    }

    let tok = simple_token(TokenType::COMMENT, start_line, start_column, @line, @column)
    tok.value.str = s.slice(start, @i)
    return tok
}

def parse_pragma(s: Str, i: *int, line: *int, column: *int) -> Token {
    let start_line = @line
    let start_column = @column
    let start = @i
    var c = peek_char(s, i, 0)
    while c == '#' or is_text(c) or is_alphanumeric(c) {
        c = next_char(s, i, line, column)
    }

    let tok = simple_token(TokenType::PRAGMA, start_line, start_column, @line, @column)
    tok.value.str = s.slice(start, @i)
    return tok  
}

def parse_symbol(s: Str, i: *int, line: *int, column: *int) -> Token {
    let start_line = @line
    let start_column = @column

    let first = peek_char(s, i, 0)
    let second = peek_char(s, i, 1)
    let third = peek_char(s, i, 2)

    var tt: TokenType = TokenType::ERROR
    var length = 3

    if first == '<' and second == '<' and third == '=' {
        tt = TokenType::OP_SHL_EQ
    } else if first == '>' and second == '>' and third == '=' {
        tt = TokenType::OP_SHR_EQ
    } else if first == '+' and second == '+' and third == '=' {
        tt = TokenType::OP_PADD_EQ
    } else if first == '-' and second == '-' and third == '=' {
        tt = TokenType::OP_PSUB_EQ
    } else if first == '.' and second == '.' and third == '=' {
        tt = TokenType::OP_RANGE_INC
    } else if first == '.' and second == '.' and third == '.' {
        tt = TokenType::OP_VARARGS
    } else {
        length = 2
        if second == '=' {
            switch first {
                case '+': tt = TokenType::OP_ADD_EQ
                case '-': tt = TokenType::OP_SUB_EQ
                case '*': tt = TokenType::OP_MUL_EQ
                case '/': tt = TokenType::OP_DIV_EQ
                case '%': tt = TokenType::OP_MOD_EQ
                case '&': tt = TokenType::OP_AND_EQ
                case '|': tt = TokenType::OP_OR_EQ
                case '^': tt = TokenType::OP_XOR_EQ
                case '!': tt = TokenType::OP_NEQ
                case '>': tt = TokenType::OP_GEQ
                case '<': tt = TokenType::OP_LEQ
                case '=': tt = TokenType::OP_EQ
            }
        } else if first == '.' and second == '.' {
            tt = TokenType::OP_RANGE
        } else if first == '!' and second == '!' {
            tt = TokenType::OP_AUTOCAST
        } else if first == '-' and second == '>' {
            tt = TokenType::ARROW
        } else if first == ':' and second == ':' {
            tt = TokenType::DOUBLE_COLON
        } else if first == '+' and second == '+' {
            tt = TokenType::OP_INC
        } else if first == '-' and second == '-' {
            tt = TokenType::OP_DEC
        } else if first == '<' and second == '<' {
            tt = TokenType::OP_SHL
        } else if first == '>' and second == '>' {
            tt = TokenType::OP_SHR
        } else {
            length = 1
            switch first {
                case '>': tt = TokenType::OP_GT
                case '<': tt = TokenType::OP_LT
                case '{': tt = TokenType::O_BRACE
                case '}': tt = TokenType::C_BRACE
                case '[': tt = TokenType::O_SQUARE
                case ']': tt = TokenType::C_SQUARE
                case '+': tt = TokenType::OP_ADD
                case '-': tt = TokenType::OP_SUB
                case '*': tt = TokenType::OP_MUL
                case '/': tt = TokenType::OP_DIV
                case '%': tt = TokenType::OP_MOD
                case '&': tt = TokenType::OP_BAND
                case '|': tt = TokenType::OP_BOR
                case '^': tt = TokenType::OP_BXOR
                case '~': tt = TokenType::OP_BNOT
                case '!': tt = TokenType::OP_CAST
                case '@': tt = TokenType::OP_DEREF  
                case '=': tt = TokenType::OP_ASSIGN                    
                case ',': tt = TokenType::COMMA  
                case ':': tt = TokenType::COLON
                case '?': tt = TokenType::QUESTION_MARK
                case '.': tt = TokenType::DOT
                case ';': tt = TokenType::SEMICOLON
            }
        }
    }

    if tt == TokenType::ERROR {
        next_char(s, i, line, column)
        return error_token("Invalid symbol", start_line, start_column, @line, @column)
    }
    
    for var j in 0..length {
        next_char(s, i, line, column)
    }
    return simple_token(tt, start_line, start_column, @line, @column)
}

def is_whitespace(c: char) -> bool {
    return c == ' ' or c == '\t' or c == '\r'
}

def parse_whitespace(depth: int, s: Str, i: *int, line: *int, column: *int) -> Token {
    let start_line = @line
    let start_column = @column

    var c = peek_char(s, i, 0)
    while is_whitespace(c) or (c == '\n' and depth > 0) {
        var is_newline = c == '\n'
        c = next_char(s, i, line, column)
        if is_newline {
            @line += 1
            @column = 0
        }
    }
    return simple_token(TokenType::WHITESPACE, start_line, start_column, @line, @column)
}

export def lex(s: Str, line: int = 0, column: int = 0, end_line: int = MAX_INT32, end_column: int = MAX_INT32) -> *TokenList {
    
    var token_list = zero_allocate(TokenList)
    var head = token_list
    var depth = 0

    var i = 0
    var start_column = 0
    var start_line = 0
    while i < length(s) {
        if line == start_line and start_column >= column { break }
        if start_line > line  { break }

        start_column += 1
        if s(i) == '\n' {
            start_line += 1
            start_column = 0
        }
        i += 1
    }

    while i < length(s) {
        if line == end_line and column > end_column { break }
        if line > end_line { break }

        let c = peek_char(s, *i, 0)

        var token: Token
        if is_whitespace(c) or c == '\n' and depth > 0 {
            // TODO Make this work inside {}
            token = parse_whitespace(depth, s, *i, *line, *column)
        } else if c == '\n' {
            token = simple_token(TokenType::NEW_LINE, line, column, line, column + 1)
            column = 0
            line += 1
            i += 1
        } else if c == '(' {
            depth += 1
            token = simple_token(TokenType::O_PAREN, line, column, line, column + 1)
            i += 1
            column += 1
        } else if c == ')' {
            depth -= 1
            token = simple_token(TokenType::C_PAREN, line, column, line, column + 1)
            i += 1
            column += 1            
        } else if c == '"' {
            var triple_quoted = false
            if peek_char(s, *i, 1) == '"' and peek_char(s, *i, 2) == '"' {
                i += 2
                triple_quoted = true
            }
            token = parse_string(s, triple_quoted, *i, *line, *column)
        } else if c == '\'' {
            token = parse_char(s, *i, *line, *column)
        } else if c >= '0' and c <= '9' {
            token = parse_number(s, *i, *line, *column)
        } else if c == '.' {
            let next = peek_char(s, *i, 1)
            if next >= '0' and next <= '9' {
                token = parse_number(s, *i, *line, *column)
            } else {
                token = parse_symbol(s, *i, *line, *column)
            }
        } else if c == '#' {
            token = parse_pragma(s, *i, *line, *column)
        } else if is_text(c) {
            token = parse_identifier(s, *i, *line, *column)
        } else if c == '/' {
            let next = peek_char(s, *i, 1)
            if next == '/' {
                token = parse_eol_comment(s, *i, *line, *column)
            } else if next == '*' {
                token = parse_comment(s, *i, *line, *column)
            } else {
                token = parse_symbol(s, *i, *line, *column)
            }
        } else {
            token = parse_symbol(s, *i, *line, *column)
        }

        token_list.value = token
        token_list.next = zero_allocate(TokenList)
        token_list = token_list.next
    }
    token_list.value = simple_token(TokenType::EOF, line, column, line, column + 1)
    token_list.next = null

    return head
}