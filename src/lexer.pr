import util
import json
import vector

// Reserve 0 for empty token
export type TokenType = enum {
    DOT = 1
    COLON
    DOUBLE_COLON
    COMMA
    SEMICOLON
    ARROW
    NEW_LINE
    QUESTION_MARK
    O_PAREN
    C_PAREN
    O_BRACE
    C_BRACE
    O_SQUARE
    C_SQUARE
    OP_RANGE
    OP_RANGE_INC
    OP_VARARGS
    OP_CAST
    OP_AUTOCAST
    OP_DEREF
    OP_ASSIGN
    OP_ADD
    OP_SUB
    OP_MUL
    OP_DIV
    OP_MOD
    OP_BOR
    OP_BAND
    OP_BXOR
    OP_BNOT
    OP_SHL
    OP_SHR
    OP_INC
    OP_DEC
    OP_EQ
    OP_NEQ
    OP_LEQ
    OP_GEQ
    OP_LT
    OP_GT
    OP_PADD_EQ
    OP_PSUB_EQ
    OP_ADD_EQ
    OP_SUB_EQ
    OP_MUL_EQ
    OP_DIV_EQ
    OP_MOD_EQ
    OP_OR_EQ
    OP_AND_EQ
    OP_XOR_EQ
    OP_SHL_EQ
    OP_SHR_EQ
    K_DO
    K_TYPE
    K_ENUM
    K_STRUCT
    K_INTERFACE
    K_IF
    K_ELSE
    K_NOT
    K_AND
    K_OR
    K_VAR
    K_LET
    K_CONST
    K_WHILE
    K_TRUE
    K_FALSE
    K_WORD
    K_NULL
    K_SWITCH
    K_FOR
    K_IN
    K_LOOP
    K_CONTINUE
    K_BREAK
    K_RETURN
    K_YIELD
    K_UNSIGNED
    K_LABEL
    K_GO_TO
    K_CASE
    K_SIZE_OF
    K_ALIGN_OF
    K_DEF
    K_EXPORT
    K_IMPORT
    K_IMPLICIT
    K_AS
    K_FROM
    K_DEFINED
    K_DEFER
    K_ASSERT
    K_TYPE_OF
    K_UNDEF
    K_WEAK_REF
    K_REF
    INTEGER
    FLOAT
    STRING
    CHAR
    IDENTIFIER
    COMMENT
    ERROR
    PRAGMA
    WHITESPACE
    EOF
}

export type Brace = enum {
    PAREN
    SQUARE
    BRACE
}

export type TokenValue = struct #union {
    str: StringSlice
    ch: char
    i: uint64
    f: double
}

export type Token = struct {
    tpe: TokenType
    line: int
    column: int
    end_line: int
    end_column: int
    value: TokenValue
}

export def destruct(token: *Token) {
    if token.tpe == TokenType::IDENTIFIER or
        token.tpe == TokenType::COMMENT or
        token.tpe == TokenType::ERROR or
        token.tpe == TokenType::PRAGMA or
        token.tpe == TokenType::STRING {
        __destruct__(*token.value.str)
    }
}

export def construct(copy: *Token, this: *Token) {
    copy.tpe = this.tpe
    copy.line = this.line
    copy.column = this.column
    copy.end_line = this.end_line
    copy.end_column = this.end_column

    if this.tpe == TokenType::IDENTIFIER or
        this.tpe == TokenType::COMMENT or
        this.tpe == TokenType::ERROR or 
        this.tpe == TokenType::PRAGMA or
        this.tpe == TokenType::STRING {
        copy.value.str = this.value.str
    } else {
        copy.value = this.value
    }
}

export type TokenList = struct {
    value: Token
    next: *TokenList
}

export def destruct(list: *TokenList) {
    list = list.next
    while list != null {
        let next = list.next
        destruct(*list.value)
        free(list)
        list = next
    }
}
type Keyword = struct {
    token_type: TokenType
    str: StringSlice
}

let KEYWORDS = [
    [token_type = TokenType::K_DO, str = "do"] !Keyword,
    [token_type = TokenType::K_TYPE, str = "type"] !Keyword,
    [token_type = TokenType::K_ENUM, str = "enum"] !Keyword,
    [token_type = TokenType::K_STRUCT, str = "struct"] !Keyword,
    [token_type = TokenType::K_INTERFACE, str = "interface"] !Keyword,
    [token_type = TokenType::K_IF, str = "if"] !Keyword,
    [token_type = TokenType::K_ELSE, str = "else"] !Keyword,
    [token_type = TokenType::K_NOT, str = "not"] !Keyword,
    [token_type = TokenType::K_AND, str = "and"] !Keyword,
    [token_type = TokenType::K_OR, str = "or"] !Keyword,
    [token_type = TokenType::K_VAR, str = "var"] !Keyword,
    [token_type = TokenType::K_LET, str = "let"] !Keyword,
    [token_type = TokenType::K_CONST, str = "const"] !Keyword,
    [token_type = TokenType::K_WHILE, str = "while"] !Keyword,
    [token_type = TokenType::K_TRUE, str = "true"] !Keyword,
    [token_type = TokenType::K_FALSE, str = "false"] !Keyword,
    [token_type = TokenType::K_WORD, str = "word"] !Keyword,
    [token_type = TokenType::K_NULL, str = "null"] !Keyword,
    [token_type = TokenType::K_SWITCH, str = "switch"] !Keyword,
    [token_type = TokenType::K_FOR, str = "for"] !Keyword,
    [token_type = TokenType::K_IN, str = "in"] !Keyword,
    [token_type = TokenType::K_LOOP, str = "loop"] !Keyword,
    [token_type = TokenType::K_CONTINUE, str = "continue"] !Keyword,
    [token_type = TokenType::K_BREAK, str = "break"] !Keyword,
    [token_type = TokenType::K_RETURN, str = "return"] !Keyword,
    [token_type = TokenType::K_UNSIGNED, str = "unsigned"] !Keyword,
    [token_type = TokenType::K_LABEL, str = "label"] !Keyword,
    [token_type = TokenType::K_GO_TO, str = "go_to"] !Keyword,
    [token_type = TokenType::K_CASE, str = "case"] !Keyword,
    [token_type = TokenType::K_SIZE_OF, str = "size_of"] !Keyword,
    [token_type = TokenType::K_ALIGN_OF, str = "align_of"] !Keyword,
    [token_type = TokenType::K_UNDEF, str = "undef"] !Keyword,
    [token_type = TokenType::K_DEF, str = "def"] !Keyword,
    [token_type = TokenType::K_EXPORT, str = "export"] !Keyword,
    [token_type = TokenType::K_IMPORT, str = "import"] !Keyword,
    [token_type = TokenType::K_ASSERT, str = "assert"] !Keyword,
    [token_type = TokenType::K_AS, str = "as"] !Keyword,
    [token_type = TokenType::K_FROM, str = "from"] !Keyword,
    [token_type = TokenType::K_DEFINED, str = "defined"] !Keyword,
    [token_type = TokenType::K_DEFER, str = "defer"] !Keyword,
    [token_type = TokenType::K_TYPE_OF, str = "type_of"] !Keyword,
    [token_type = TokenType::K_WEAK_REF, str = "weak_ref"] !Keyword,
    [token_type = TokenType::K_YIELD, str = "yield"] !Keyword,
    [token_type = TokenType::K_IMPLICIT, str = "implicit"] !Keyword,
    [token_type = TokenType::K_REF, str = "ref"] !Keyword
]

export def token_list_to_json(list: *TokenList) -> &Json {
    let res = json::make_array()
    while list != null {
        let value = list.value
        let token = json::make_object()
        token("kind") = to_string(value.tpe)
        token("line") = value.line !double
        token("column") = value.column !double
        if (value.tpe == TokenType::STRING or value.tpe == TokenType::IDENTIFIER or
            value.tpe == TokenType::ERROR or value.tpe == TokenType::COMMENT or
            value.tpe == TokenType::PRAGMA) {
            let str = value.value.str
            token("value") = str
        } else if (value.tpe == TokenType::INTEGER) {
            token("value") = value.value.i !double
        } else if (value.tpe == TokenType::CHAR) {
            token("value") = value.value.ch !double
        } else if (value.tpe == TokenType::FLOAT) {
            token("value") = value.value.f
        }
        list = list.next
        res.push(token)
    }
    return res
}

def simple_token(tpe: TokenType, line: int, column: int, end_line: int, end_column: int) -> Token {
    return [
        tpe = tpe, line = line, column = column, end_line = end_line, end_column = end_column
    ] !Token
}

def error_token(s: String, line: int, column: int, end_line: int, end_column: int) -> Token {
    var tok = [
        tpe = TokenType::ERROR, line = line, column = column, end_line = end_line, end_column = end_column
    ] !Token
    tok.value.str = s
    return tok
}

def valid_hex_char(a: char) -> bool {
    return a >= '0' and a <= '9' or a >= 'a' and a <= 'f' or a >= 'A' and a <= 'F'
}

def parse_hex_char(a: char) -> int {
    if a >= '0' and a <= '9' {
        return a - '0'
    } else if a >= 'a' and a <= 'f' {
        return a - 'a' + 10
    } else if a >= 'A' and a <= 'F' {
        return a - 'A' + 10
    }
    return -1
}

def is_text(a: char) -> bool {
    return a == '_' or a >= 'a' and a <= 'z' or a >= 'A' and a <= 'Z'
}

def is_alphanumeric(a: char) -> bool {
    return is_text(a) or a >= '0' and a <= '9'
}

def parse_simple_escape_sequence(escape_char: char) -> int {
    switch escape_char {
        case 'a'; return '\a'
        case 'b'; return '\b'
        case 'f'; return '\f'
        case 'n'; return '\n'
        case 'r'; return '\r'
        case 't'; return '\t'
        case 'v'; return '\v'
        case '0'; return '\0'
        case '"'; return '"'
        case '\''; return '\''
        case '\\'; return '\\'
    }
    return -1
}

// TODO Use a state instead of passing all of these parameters one by one
def next_char(s: Str, i: *int, line: *int, column: *int) -> char {
    @i += 1
    if @i >= length(s) {
        return 0x1A !char
    }

    let c = s(@i)
    @column += 1
    return c
}

def peek_char(s: Str, i: *int, n: int) -> char {
    if @i + n >= length(s) {
        return 0x1A !char
    }
    return s(@i + n)
}

def parse_string(s: Str, triple_quoted: bool, i: *int, line: *int, column: *int) -> Token {
    let start_line = @line
    let start_column = @column
    
    var res: StringBuffer = ""
    var end_of_string = false
    while @i < length(s) {
        let c = next_char(s, i, line, column)
        if c == '\\' {
            let escape_char = next_char(s, i, line, column)
            let c = parse_simple_escape_sequence(escape_char)
            if c >= 0 {
                res += c !char
            } else if escape_char == 'x' or escape_char == 'u' or escape_char == 'U' {

                var count: int
                if escape_char == 'x' {
                    count = 1
                } else if escape_char == 'u' {
                    count = 2
                } else {
                    count = 4
                }

                var code_point: uint64 = 0
                for var v in 0..count {
                    let e1 = next_char(s, i, line, column)
                    let e2 = next_char(s, i, line, column)

                    if not valid_hex_char(e1) or not valid_hex_char(e2) {
                        return error_token("Invalid escape sequence", start_line, start_column, @line, @column)
                    }
                    let esc_char = parse_hex_char(e1) << 4 | parse_hex_char(e2)
                    code_point = code_point << 8 | esc_char
                }
                if count == 1 {
                    res += code_point !char
                } else {
                    if code_point <= 0x10FFFF {
                        res += utf8_encode(code_point)
                    } else {
                        return error_token("Invalid unicode sequence", start_line, start_column, @line, @column)
                    }
                }
            } else if escape_char == '\n' {
                @line += 1
                @column = 0
            } else {
                return error_token("Invalid escape sequence", start_line, start_column, @line, @column)
            }
        } else if c == '"' {
            if triple_quoted {
                if peek_char(s, i, 1) == '"' and peek_char(s, i, 2) == '"' {
                    @i += 2
                    end_of_string = true
                    break
                } else {
                    res += c
                }
            } else {
                end_of_string = true
                break
            }
        } else if c == '\n' {
            @line += 1
            @column = 0
            res += c
        } else {
            res += c
        }
    }

    if not end_of_string {
        return error_token("Unexpected end of file while parsing string literal", start_line, start_column, @line, @column)
    }

    next_char(s, i, line, column)
    let tok = simple_token(TokenType::STRING, start_line, start_column, @line, @column)
    tok.value.str = to_slice(res.to_str())
    return tok
}

def parse_char(s: Str, i: *int, line: *int, column: *int) -> Token {
    let start_line = @line
    let start_column = @column

    var result: char
    let c = next_char(s, i, line, column)
    if c == '\\' {
        let escape_char = next_char(s, i, line, column)
        let c = parse_simple_escape_sequence(escape_char)
        if c >= 0 {
            result = c !char
        } else if escape_char == 'x' {            
            let e1 = next_char(s, i, line, column)
            let e2 = next_char(s, i, line, column)
            if not valid_hex_char(e1) or not valid_hex_char(e2) {
                return error_token("Invalid escape sequence", start_line, start_column, @line, @column)
            }
            let esc_char = parse_hex_char(e1) << 4 | parse_hex_char(e2)
            result = esc_char !char
        } else {
            return error_token("Invalid escape sequence", start_line, start_column, @line, @column)
        }
    } else if c == '\n' {
        @line += 1
        @column = 0
        return error_token("Unexpected new line", start_line, start_column, @line, @column) 
    } else {
        result = c
    }
    
    if next_char(s, i, line, column) == '\'' {
        next_char(s, i, line, column)
        var tok = simple_token(TokenType::CHAR, start_line, start_column, @line, @column)
        tok.value.ch = result
        return tok
    }

    return error_token("Unexpected end of file while parsing character", start_line, start_column, @line, @column)
}

// TODO Refactor the following three functions into one

def parse_hex_int(s: Str, i: *int, line: *int, column: *int) -> Token {
    let start_line = @line
    let start_column = @column

    next_char(s, i, line, column)
    next_char(s, i, line, column)

    var result: uint64 = 0
    while @i < length(s) {
        let c = peek_char(s, i, 0)
        if valid_hex_char(c) {
            result *= 16
            result += parse_hex_char(c)
            next_char(s, i, line, column)
        } else {
            break  
        }
    }

    let tok = simple_token(TokenType::INTEGER, start_line, start_column, @line, @column)
    tok.value.i = result
    return tok
}

def parse_oct_int(s: Str, i: *int, line: *int, column: *int) -> Token {
    let start_line = @line
    let start_column = @column

    next_char(s, i, line, column)
    next_char(s, i, line, column)

    var result: uint64 = 0
    while @i < length(s) {
        let c = peek_char(s, i, 0)
        if c >= '0' and c <= '7' {
            result *= 8
            result += c - '0'
            next_char(s, i, line, column)
        } else {
            break  
        }
    }

    let tok = simple_token(TokenType::INTEGER, start_line, start_column, @line, @column)
    tok.value.i = result
    return tok
}

def parse_bin_int(s: Str, i: *int, line: *int, column: *int) -> Token {
    let start_line = @line
    let start_column = @column 

    next_char(s, i, line, column)
    next_char(s, i, line, column)

    var result: uint64 = 0
    while @i < length(s) {
        let c = peek_char(s, i, 0)
        if c >= '0' and c <= '1' {
            result *= 2
            result += c - '0'
            next_char(s, i, line, column)
        } else {
            break  
        }
    }

    let tok = simple_token(TokenType::INTEGER, start_line, start_column, @line, @column)
    tok.value.i = result
    return tok
}

def parse_int(s: Str, i: *int, line: *int, column: *int) -> Token {
    let start_line = @line
    let start_column = @column

    let c = peek_char(s, i, 0)
    if c == '0' {
        let r = peek_char(s, i, 1)
        if r == 'b' {
            return parse_bin_int(s, i, line, column)
        } else if r == 'o' {
            return parse_oct_int(s, i, line, column)
        } else if r == 'x' {
            return parse_hex_int(s, i, line, column)
        }
    }

    var result: uint64 = 0
    while @i < length(s) {
        let c = peek_char(s, i, 0)
        if c >= '0' and c <= '9' {
            result *= 10
            result += c - '0'
            next_char(s, i, line, column)
        } else {
            break  
        }
    }
    
    let tok = simple_token(TokenType::INTEGER, start_line, start_column, @line, @column)
    tok.value.i = result
    return tok
}

// TODO This gives the "wrong" bits for 10.555 
def parse_float(s: Str, i: *int, line: *int, column: *int) -> Token {
    let start_line = @line
    let start_column = @column

    var a = 0.0
    var e = 0
    var c = peek_char(s, i, 0)

    while c >= '0' and c <= '9' {
        a = a * 10 + c - '0'
        c = next_char(s, i, line, column)
    }
    if c == '.' {
        c = next_char(s, i, line, column)
        while c >= '0' and c <= '9' {
            a = a * 10 + c - '0'
            e -= 1
            c = next_char(s, i, line, column)
        }
    }
    if c == 'e' or c == 'E' {
        var sign = 1
        var j = 0
        c = next_char(s, i, line, column)
        if c == '-' {
            sign = -1
            c = next_char(s, i, line, column)
        } else if c == '+' {
            c = next_char(s, i, line, column)
        }
        while c >= '0' and c <= '9' {
            j = j * 10 + c - '0'
            c = next_char(s, i, line, column)
        }
        e += j * sign
    }
    while e > 0 {
        a *= 10
        e -= 1
    }
    while e < 0 {
        a *= 0.1
        e += 1
    }

    let tok = simple_token(TokenType::FLOAT, start_line, start_column, @line, @column)
    tok.value.f = a
    return tok
}

def parse_number(s: Str, i: *int, line: *int, column: *int) -> Token {
    let start_line = @line
    let start_column = @column

    var j = 0
    var is_float = false
    loop {
        let c = peek_char(s, i, j)
        if c == '.' {
            let c2 = peek_char(s, i, j + 1)
            if c2 != '.' {
                is_float = true
            }
            break
        } else if c == 'e' or c == 'E' {
            is_float = true
            break
        } else if c >= '0' and c <= '9' {
            j += 1
        } else {
            break
        }
    }

    if is_float {
        return parse_float(s, i, line, column)
    }
    return parse_int(s, i, line, column)
}

def parse_identifier(s: Str, i: *int, line: *int, column: *int) -> Token {
    let start_line = @line
    let start_column = @column

    var c = peek_char(s, i, 0)
    var start = @i
    while is_alphanumeric(c) {
        c = next_char(s, i, line, column)
    }

    for var j in 0..KEYWORDS.size {
        let keyword = KEYWORDS(j)
        if keyword.str == s.slice(start, @i) {
            return simple_token(keyword.token_type, start_line, start_column, @line, @column)
        }
    }

    let tok = simple_token(TokenType::IDENTIFIER, start_line, start_column, @line, @column)
    tok.value.str = s.slice(start, @i)
    return tok
}

def parse_eol_comment(s: Str, i: *int, line: *int, column: *int) -> Token {
    let start_line = @line
    let start_column = @column
    let start = @i

    next_char(s, i, line, column)
    next_char(s, i, line, column)

    var c = peek_char(s, i, 0)
    while c != '\n' and c != 0x1A {
        c = next_char(s, i, line, column)
    }
    
    let tok = simple_token(TokenType::COMMENT, start_line, start_column, @line, @column)
    tok.value.str = s.slice(start, @i)

    return tok
}

def parse_comment(s: Str, i: *int, line: *int, column: *int) -> Token {
    let start_line = @line
    let start_column = @column
    let start = @i

    next_char(s, i, line, column)
    next_char(s, i, line, column)

    var depth = 1
    var c = peek_char(s, i, 0)
    while depth > 0 and c != 0x1A {
        if c == '/' {
            if peek_char(s, i, 1) == '*' {
                depth += 1
                next_char(s, i, line, column)
            }
        } else if c == '*' {
            if peek_char(s, i, 1) == '/' {
                depth -= 1
                next_char(s, i, line, column)
            }
        } else if c == '\n' {
            @line += 1
            @column = 0
        }
        c = next_char(s, i, line, column)
    }

    let tok = simple_token(TokenType::COMMENT, start_line, start_column, @line, @column)
    tok.value.str = s.slice(start, @i)
    return tok
}

def parse_pragma(s: Str, i: *int, line: *int, column: *int) -> Token {
    let start_line = @line
    let start_column = @column
    let start = @i
    var c = peek_char(s, i, 0)
    while c == '#' or is_text(c) or is_alphanumeric(c) {
        c = next_char(s, i, line, column)
    }

    let tok = simple_token(TokenType::PRAGMA, start_line, start_column, @line, @column)
    tok.value.str = s.slice(start, @i)
    return tok  
}

def parse_symbol(s: Str, i: *int, line: *int, column: *int) -> Token {
    let start_line = @line
    let start_column = @column

    let first = peek_char(s, i, 0)
    let second = peek_char(s, i, 1)
    let third = peek_char(s, i, 2)

    var tt: TokenType = TokenType::ERROR
    var length = 3

    if first == '<' and second == '<' and third == '=' {
        tt = TokenType::OP_SHL_EQ
    } else if first == '>' and second == '>' and third == '=' {
        tt = TokenType::OP_SHR_EQ
    } else if first == '+' and second == '+' and third == '=' {
        tt = TokenType::OP_PADD_EQ
    } else if first == '-' and second == '-' and third == '=' {
        tt = TokenType::OP_PSUB_EQ
    } else if first == '.' and second == '.' and third == '=' {
        tt = TokenType::OP_RANGE_INC
    } else if first == '.' and second == '.' and third == '.' {
        tt = TokenType::OP_VARARGS
    } else {
        length = 2
        if second == '=' {
            switch first {
                case '+'; tt = TokenType::OP_ADD_EQ
                case '-'; tt = TokenType::OP_SUB_EQ
                case '*'; tt = TokenType::OP_MUL_EQ
                case '/'; tt = TokenType::OP_DIV_EQ
                case '%'; tt = TokenType::OP_MOD_EQ
                case '&'; tt = TokenType::OP_AND_EQ
                case '|'; tt = TokenType::OP_OR_EQ
                case '^'; tt = TokenType::OP_XOR_EQ
                case '!'; tt = TokenType::OP_NEQ
                case '>'; tt = TokenType::OP_GEQ
                case '<'; tt = TokenType::OP_LEQ
                case '='; tt = TokenType::OP_EQ
            }
        } else if first == '.' and second == '.' {
            tt = TokenType::OP_RANGE
        } else if first == '!' and second == '!' {
            tt = TokenType::OP_AUTOCAST
        } else if first == '-' and second == '>' {
            tt = TokenType::ARROW
        } else if first == ':' and second == ':' {
            tt = TokenType::DOUBLE_COLON
        } else if first == '+' and second == '+' {
            tt = TokenType::OP_INC
        } else if first == '-' and second == '-' {
            tt = TokenType::OP_DEC
        } else if first == '<' and second == '<' {
            tt = TokenType::OP_SHL
        } else if first == '>' and second == '>' {
            tt = TokenType::OP_SHR
        } else {
            length = 1
            switch first {
                case '>'; tt = TokenType::OP_GT
                case '<'; tt = TokenType::OP_LT
                case '+'; tt = TokenType::OP_ADD
                case '-'; tt = TokenType::OP_SUB
                case '*'; tt = TokenType::OP_MUL
                case '/'; tt = TokenType::OP_DIV
                case '%'; tt = TokenType::OP_MOD
                case '&'; tt = TokenType::OP_BAND
                case '|'; tt = TokenType::OP_BOR
                case '^'; tt = TokenType::OP_BXOR
                case '~'; tt = TokenType::OP_BNOT
                case '!'; tt = TokenType::OP_CAST
                case '@'; tt = TokenType::OP_DEREF  
                case '='; tt = TokenType::OP_ASSIGN                    
                case ','; tt = TokenType::COMMA  
                case ':'; tt = TokenType::COLON
                case '?'; tt = TokenType::QUESTION_MARK
                case '.'; tt = TokenType::DOT
                case ';'; tt = TokenType::SEMICOLON
            }
        }
    }

    if tt == TokenType::ERROR {
        next_char(s, i, line, column)
        return error_token("Invalid symbol", start_line, start_column, @line, @column)
    }
    
    for var j in 0..length {
        next_char(s, i, line, column)
    }
    return simple_token(tt, start_line, start_column, @line, @column)
}

def is_whitespace(c: char) -> bool {
    return c == ' ' or c == '\t' or c == '\r'
}

def parse_whitespace(brace_stack: &Vector(Brace), s: Str, i: *int, line: *int, column: *int) -> Token {
    let start_line = @line
    let start_column = @column

    var c = peek_char(s, i, 0)
    while is_whitespace(c) or (c == '\n' and brace_stack.length > 0 and brace_stack.peek() == Brace::PAREN) {
        var is_newline = c == '\n'
        c = next_char(s, i, line, column)
        if is_newline {
            @line += 1
            @column = 0
        }
    }
    return simple_token(TokenType::WHITESPACE, start_line, start_column, @line, @column)
}

export def lex(s: Str, line: int = 0, column: int = 0, end_line: int = MAX_INT32, end_column: int = MAX_INT32) -> *TokenList {
    
    var token_list = zero_allocate(TokenList)
    var head = token_list
    var brace_stack = vector::make(Brace)

    var i = 0
    var start_column = 0
    var start_line = 0
    while i < length(s) {
        if line == start_line and start_column >= column { break }
        if start_line > line  { break }

        start_column += 1
        if s(i) == '\n' {
            start_line += 1
            start_column = 0
        }
        i += 1
    }

    while i < length(s) {
        if line == end_line and column > end_column { break }
        if line > end_line { break }

        let c = peek_char(s, *i, 0)

        var token: Token
        if is_whitespace(c) or c == '\n' and brace_stack.length > 0 and brace_stack.peek() == Brace::PAREN {
            // TODO Make this work inside {}
            token = parse_whitespace(brace_stack, s, *i, *line, *column)
        } else if c == '\n' {
            token = simple_token(TokenType::NEW_LINE, line, column, line, column + 1)
            column = 0
            line += 1
            i += 1
        } else if c == '(' {
            brace_stack.push(Brace::PAREN)
            token = simple_token(TokenType::O_PAREN, line, column, line, column + 1)
            i += 1
            column += 1
        } else if c == '[' {
            brace_stack.push(Brace::SQUARE)
            token = simple_token(TokenType::O_SQUARE, line, column, line, column + 1)
            i += 1
            column += 1
        } else if c == '{' {
            brace_stack.push(Brace::BRACE)
            token = simple_token(TokenType::O_BRACE, line, column, line, column + 1)
            i += 1
            column += 1
        } else if c == ')' {
            if brace_stack.length > 0 { brace_stack.pop() }
            token = simple_token(TokenType::C_PAREN, line, column, line, column + 1)
            i += 1
            column += 1            
        } else if c == ']' {
            if brace_stack.length > 0 { brace_stack.pop() }
            token = simple_token(TokenType::C_SQUARE, line, column, line, column + 1)
            i += 1
            column += 1            
        } else if c == '}' {
            if brace_stack.length > 0 { brace_stack.pop() }
            token = simple_token(TokenType::C_BRACE, line, column, line, column + 1)
            i += 1
            column += 1            
        } else if c == '"' {
            var triple_quoted = false
            if peek_char(s, *i, 1) == '"' and peek_char(s, *i, 2) == '"' {
                i += 2
                triple_quoted = true
            }
            token = parse_string(s, triple_quoted, *i, *line, *column)
        } else if c == '\'' {
            token = parse_char(s, *i, *line, *column)
        } else if c >= '0' and c <= '9' {
            token = parse_number(s, *i, *line, *column)
        } else if c == '.' {
            let next = peek_char(s, *i, 1)
            if next >= '0' and next <= '9' {
                token = parse_number(s, *i, *line, *column)
            } else {
                token = parse_symbol(s, *i, *line, *column)
            }
        } else if c == '#' {
            token = parse_pragma(s, *i, *line, *column)
        } else if is_text(c) {
            token = parse_identifier(s, *i, *line, *column)
        } else if c == '/' {
            let next = peek_char(s, *i, 1)
            if next == '/' {
                token = parse_eol_comment(s, *i, *line, *column)
            } else if next == '*' {
                token = parse_comment(s, *i, *line, *column)
            } else {
                token = parse_symbol(s, *i, *line, *column)
            }
        } else {
            token = parse_symbol(s, *i, *line, *column)
        }

        token_list.value = token
        token_list.next = zero_allocate(TokenList)
        token_list = token_list.next
    }
    token_list.value = simple_token(TokenType::EOF, line, column, line, column + 1)
    token_list.next = null

    return head
}