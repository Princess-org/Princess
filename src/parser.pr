import lexer
import vector
import map
import util
import toolchain
import typechecking
import scope
import errors
import debug
import compiler
import server::server as server

export type NodeKind = enum {
    PROGRAM
    INTEGER
    CHAR
    STRING
    FLOAT
    BOOLEAN
    IDENTIFIER
    ERROR
    DEFINED
    NULL
    UNDEF
    RANGE
    RANGE_INC
    //ARRAY_LIT // Begone
    STRUCT_LIT
    MEMBER_ACCESS
    CAST
    SIZE_OF
    ALIGN_OF
    DEFER
    ASSERT
    ADD
    SUB
    MUL
    DIV
    MOD
    AND
    OR
    UADD
    USUB
    PTR
    DEREF
    BNOT
    NOT
    BAND
    BOR
    BXOR
    SHL
    SHR
    PADD
    PSUB
    EQ
    NEQ
    GT
    LT
    GEQ
    LEQ
    PADD_EQ
    PSUB_EQ
    ADD_EQ
    SUB_EQ
    MUL_EQ
    DIV_EQ
    MOD_EQ
    AND_EQ
    OR_EQ
    XOR_EQ
    SHL_EQ
    SHR_EQ
    IMPORT
    IMPORT_MODULE
    ASSIGN
    DEF
    PARAMETER
    SWITCH
    CASE
    IF
    IF_EXPR
    STATIC_IF
    ELSE_IF
    ELSE
    LOOP
    WHILE
    FOR
    FOR_ID_DECL
    BREAK
    CONTINUE
    RETURN
    YIELD
    YIELD_FROM
    //ARRAY_SUBSCRIPT // Begone
    FUNC_CALL
    TYPE_DECL
    VAR_DECL
    ID_DECL
    ID_ASSIGN
    NAMED_ARG
    ID_DECL_STRUCT
    ID_DECL_ENUM
    FROM
    STAR
    ENUM_T
    STRUCT_T
    UNION_T
    FUNCTION_T
    CLOSURE_T
    UNSIGNED_T
    WORD_T
    PTR_T
    REF_T
    WEAK_REF_T
    ARRAY_T
    ARRAY_STATIC_T
    TYPE_T
    TYPE_OF_T
    STRUCTURAL_T
    STRUCTURAL_T_MEMBER
    TYPE_CONSTRUCTOR
    VARIANT_T
    TUPLE_T // Uses variant_t
    LAMBDA
}

export type ShareMarker = enum {
    NONE = 0
    EXPORT = 1
    IMPORT = 2
    BOTH = 3
}

export type VarDecl = enum {
    VAR
    LET
    CONST
    TYPE
}

export type MemberType = enum {
    VAR
    LET
    DEF
}

// TODO Use flags for the boolean values
export type NodeDef = struct {
    impl: bool
    has_yield: bool
    dllimport: bool
    dllexport: bool
    test: bool
    extern: bool
    inline: bool
    share: ShareMarker
    name: &Node
    params: &Vector(&Node)
    returns: &Vector(&Node)
    body: &Vector(&Node)
    has_lookup: bool
    function: &compiler::Function
    closure_type: &typechecking::Type
    // To prevent double compiles by the language server
    is_compiled: bool
    // TODO This is a bit of a hack, see its usage
    is_generic_instance: bool
    doc: Str
}

export type NodeLambda = struct {
    parameters: &Vector(&Node)
    body: &Vector(&Node)
    closure_type: &typechecking::Type
    function: &compiler::Function
}

export type NodeParam = struct {
    varargs: bool
    kw: VarDecl
    name: &Node
    tpe: &Node
    value: &Node
}

export type NodeImportModule = struct {
    name: &Node
    alias: &Node
}

export type NodeSwitch = struct {
    expr: &Node
    body: &Vector(&Node)
}

export type NodeCase = struct {
    expr: &Vector(&Node)
    body: &Vector(&Node)
}

export type NodeIf = struct {
    cond: &Node
    body: &Vector(&Node)
    else_if: &Vector(&Node)
    else_: &Node
}

export type NodeElseIf = struct {
    cond: &Node
    body: &Vector(&Node)
}

export type NodeArrayStaticT = struct {
    n: &Node
    kw: VarDecl
    tpe: &Node
}

export type NodePtrArrayT = struct {
    kw: VarDecl
    tpe: &Node
}

export type NodeFunctionT = struct {
    args: &Vector(&Node)
    ret: &Vector(&Node)
}

export type NodeVariantT = struct {
    variants: &Vector(&Node)
}

export type NodeIdDecl = struct {
    value: &Node
    tpe: &Node
}

export type NodeVarDecl = struct {
    extern: bool
    dllimport: bool
    dllexport: bool
    share: ShareMarker
    kw: VarDecl
    left: &Vector(&Node)
    right: &Vector(&Node)
    doc: Str
}

export type NodeTypeConstructor = struct {
    name: &Node
    args: &Vector(&Node)
}

export type NodeTypeDecl = struct {
    children: &Vector(&Node)
    share: ShareMarker
    left: &Vector(&Node)
    right: &Vector(&Node)
    doc: Str
}

export type NodeNamedArg = struct {
    name: &Node
    value: &Node
}

export type InlineSpecifier = enum {
    NONE
    INLINE
    NO_INLINE
}

export type NodeFuncCall = struct {
    inline: InlineSpecifier
    left: &Node
    args: &Vector(&Node)
    kwargs: &Vector(&Node)
    is_member_access: bool
    arguments: &Vector(typechecking::NamedParameter)
}

export type NodeStructLit = struct {
    args: &Vector(&Node)
    kwargs: &Vector(&Node)
}

export type NodeBinaryOp = struct {
    left: &Node
    right: &Node
}

export type NodeAssign = struct {
    left: &Vector(&Node)
    right: &Vector(&Node)
}

export type NodeForIdDecl = struct {
    kw: VarDecl
    ident: &Node
}

export type NodeFor = struct {
    iddecl: &Node
    expr: &Node
    body: &Vector(&Node)
    // This is only used by generators
    generator_next: &scope::Value
    generator_get: &scope::Value
}

export type NodeWhile = struct {
    expr: &Node
    body: &Vector(&Node)
}

export type NodeIdDeclStruct = struct {
    ident: &Node
    tpe: &Node
    is_bitfield: bool
    is_embed: bool
    bit_size: size_t
    is_const: bool
    value: &Node
}

export type NodeEnumT = struct {
    tpe: &Node
    body: &Vector(&Node)
}

export type NodeIdDeclEnum = struct {
    ident: &Node
    value: &Node
}

export type NodeIfExpr = struct {
    cond: &Node
    if_true: &Node
    if_false: &Node
}

export type NodeIdentifier = struct {
    path: &Vector(String)
    args: &Vector(&Node)
    // Vector of typechecking::NamedParameter
    types: &Vector(typechecking::NamedParameter)
    // true if the identifier starts with ::
    prefixed: bool
}

export type NodeAssert = struct {
    cond: &Node
    message: &Node
}

export type NodeStructuralMember = struct {
    name: &Node
    kw: MemberType
    params: &Vector(&Node)
    returns: &Vector(&Node)
}

export type NodeProgram = struct {
    // Map of typechecking::Type
    locals: &SMap(&typechecking::Type)
    has_defer: bool
    body: &Vector(&Node)
    function: &compiler::Function
}

export type NodeFrom = struct {
    module: &Node
    idents: &Vector(&Node)
}

export type NodeValue = struct #union {
    bin_op: NodeBinaryOp
    var_decl: NodeVarDecl
    type_decl: NodeTypeDecl
    id_decl: NodeIdDecl
    id_decl_struct: NodeIdDeclStruct
    id_decl_enum: NodeIdDeclEnum
    named_arg: NodeNamedArg
    struct_lit: NodeStructLit
    t_enum: NodeEnumT
    t_func: NodeFunctionT
    t_parr: NodePtrArrayT
    t_arrs: NodeArrayStaticT
    t_variant: NodeVariantT
    structural_member: NodeStructuralMember
    func_call: NodeFuncCall
    assign: NodeAssign
    if_expr: NodeIfExpr
    if_: NodeIf
    else_if: NodeElseIf
    switch_: NodeSwitch
    case_: NodeCase
    while_loop: NodeWhile
    for_loop: NodeFor
    for_id_decl: NodeForIdDecl
    import_module: NodeImportModule
    def_: NodeDef
    param: NodeParam
    identifier: NodeIdentifier
    assert_: NodeAssert
    program: NodeProgram
    type_constructor: NodeTypeConstructor
    from_: NodeFrom
    lambda: NodeLambda

    body: &Vector(&Node)
    expr: &Node
    i: uint64
    str: String
    f: double
}

export type SourceLoc = struct {
    filename: Str
    display_name: Str
    module: Str
    line: int
    column: int
    end_line: int
    end_column: int
}

export def lines(loc: SourceLoc) -> &[Str] {
    let module = toolchain::modules.get_or_default(loc.filename, null)
    return module.lines if module else null 
}

export let invalid_loc: SourceLoc = [
    line = -1, column = -1,
    end_line = -1, end_column = -1
] !SourceLoc

export def is_invalid(loc: SourceLoc) -> bool {
    return not to_bool(loc.filename)
}

export def == (this: SourceLoc, other: SourceLoc) -> bool {
    return this.filename == other.filename and 
        this.line == other.line and
        this.column == other.column and
        this.end_line == other.end_line and
        this.end_column == other.end_column
}
export def != (this: SourceLoc, other: SourceLoc) -> bool {
    return not (this == other)
}

export type Node = struct {
    kind: NodeKind

    loc: SourceLoc

    tpe: &typechecking::Type
    // This is for passing on a function from typechecking to the compiler
    // TODO There might be better ways of doing this
    function: &typechecking::Type
    svalue: &scope::Value
    scope: &scope::Scope
    // For things like if statements or functions
    inner_scope: &scope::Scope
    value: NodeValue
    parent: weak_ref(Node)

    // Set to prevent destructors being called on uninitalized values
    is_initializer: bool

    // This is so that we have a consistent layout, this refers to the
    // actual data in value
    body: &Vector(&Node)
    // This is used by assignment to track let
    kw: VarDecl
    module: weak_ref(toolchain::Module)
    is_recursive_type: bool

    // Need to keep copied type nodes in the tree
    variants: &SMap(&Node)
    is_assign_right: bool

    // This is used to check for changes of a node
    _hash: uint64
    signature_hash: uint64
}

export def index_of(nodes: &Vector(&Node), node: &Node) -> int64 {
    for var i in 0..nodes.length {
        if nodes(i) == node {
            return i
        }
    }
    return -1
}

def hash(node: &Node) -> uint64 {
    if not node { return 0 }
    return node._hash
}

def hash(nodes: &Vector(&Node)) -> uint64 {
    if not nodes { return 0 }
    var h: uint64 = 17
    for var i in 0..nodes.length {
        h = combine_hashes(h, hash(nodes(i)))
    }
    return h
}

def hash(path: &Vector(String)) -> uint64 {
    if not path { return 0 }
    var h: uint64 = 17
    for var i in 0..path.length {
        h = combine_hashes(h, hash(path(i)))
    }
    return h
}

export def destruct(node: *Node) {
    switch node.kind {
        case NodeKind::LOOP, NodeKind::ELSE, NodeKind::DEFER, 
            NodeKind::RETURN, NodeKind::YIELD, NodeKind::IMPORT,
            NodeKind::STRUCT_T, NodeKind::UNION_T, NodeKind::STRUCTURAL_T
            __destruct__(*node.value.body)
        case NodeKind::PROGRAM
            __destruct__(*node.value.program)
        case NodeKind::ASSERT
            __destruct__(*node.value.assert_)
        case NodeKind::IF, NodeKind::STATIC_IF
            __destruct__(*node.value.if_)
        case NodeKind::ELSE_IF
            __destruct__(*node.value.else_if)
        case NodeKind::IF_EXPR
            __destruct__(*node.value.if_expr)
        case NodeKind::WHILE
            __destruct__(*node.value.while_loop)
        case NodeKind::FOR
            __destruct__(*node.value.for_loop)
        case NodeKind::FOR_ID_DECL
            __destruct__(*node.value.for_id_decl)
        case NodeKind::DEF
            __destruct__(*node.value.def_)
        case NodeKind::CASE
            __destruct__(*node.value.case_)
        case NodeKind::SWITCH
            __destruct__(*node.value.switch_)
        case NodeKind::STRING
            __destruct__(*node.value.str)
        case NodeKind::IDENTIFIER
            __destruct__(*node.value.identifier)
        case NodeKind::STRUCT_LIT
            __destruct__(*node.value.struct_lit)
        case NodeKind::IMPORT_MODULE
            __destruct__(*node.value.import_module)
        case NodeKind::ASSIGN
            __destruct__(*node.value.assign)
        case NodeKind::PARAMETER
            __destruct__(*node.value.param)
        case NodeKind::FUNC_CALL
            __destruct__(*node.value.func_call)
        case NodeKind::TYPE_DECL
            __destruct__(*node.value.type_decl)
        case NodeKind::VAR_DECL
            __destruct__(*node.value.var_decl)
        case NodeKind::ID_DECL
            __destruct__(*node.value.id_decl)
        case NodeKind::NAMED_ARG
            __destruct__(*node.value.named_arg)
        case NodeKind::ID_DECL_STRUCT
            __destruct__(*node.value.id_decl_struct)
        case NodeKind::ID_DECL_ENUM
            __destruct__(*node.value.id_decl_enum)
        case NodeKind::ENUM_T
            __destruct__(*node.value.t_enum)
        case NodeKind::FUNCTION_T, NodeKind::CLOSURE_T
            __destruct__(*node.value.t_func)
        case NodeKind::REF_T, NodeKind::PTR_T, NodeKind::ARRAY_T, NodeKind::WEAK_REF_T
            __destruct__(*node.value.t_parr)
        case NodeKind::ARRAY_STATIC_T
            __destruct__(*node.value.t_arrs)
        case NodeKind::STRUCTURAL_T_MEMBER
            __destruct__(*node.value.structural_member)
        case NodeKind::VARIANT_T, NodeKind::TUPLE_T
            __destruct__(*node.value.t_variant)
        case NodeKind::ERROR, NodeKind::DEFINED, NodeKind::SIZE_OF, NodeKind::ALIGN_OF, NodeKind::TYPE_OF_T,
            NodeKind::UADD..=NodeKind::NOT, NodeKind::ID_ASSIGN, NodeKind::UNSIGNED_T, NodeKind::TYPE_T, NodeKind::YIELD_FROM
            __destruct__(*node.value.expr)
        case NodeKind::RANGE, NodeKind::RANGE_INC, NodeKind::MEMBER_ACCESS,
            NodeKind::CAST, NodeKind::ADD..=NodeKind::OR,
            NodeKind::BAND..=NodeKind::SHR_EQ
            __destruct__(*node.value.bin_op)
        case NodeKind::TYPE_CONSTRUCTOR
            __destruct__(*node.value.type_constructor)
        case NodeKind::FROM
            __destruct__(*node.value.from_)
        case NodeKind::INTEGER, NodeKind::CHAR, NodeKind::FLOAT,
            NodeKind::BOOLEAN, NodeKind::NULL, NodeKind::UNDEF, NodeKind::BREAK, NodeKind::CONTINUE,
            NodeKind::WORD_T, NodeKind::STAR
        case NodeKind::LAMBDA
            __destruct__(*node.value.lambda)
        case
            error(node.kind, "\n")
            assert
    }
}

// TODO Add tagged unions so this is not necessary
export def construct(copy: *Node, node: *Node) {
    copy.kind = node.kind
    copy.loc = node.loc
    copy.tpe = node.tpe
    copy.function = node.function
    copy.svalue = node.svalue
    copy.scope = node.scope
    copy.inner_scope = node.inner_scope
    copy.parent = node.parent
    copy.is_initializer = node.is_initializer
    copy.kw = node.kw
    copy.module = node.module
    copy.is_recursive_type = node.is_recursive_type
    copy.variants = node.variants
    copy._hash = node._hash
    copy.signature_hash = node.signature_hash
    
    switch node.kind {
        case NodeKind::PROGRAM
            copy.value.program = node.value.program
            copy.body = node.value.program.body
        case NodeKind::LOOP, NodeKind::ELSE, NodeKind::DEFER
            copy.value.body = node.value.body
            copy.body = copy.value.body
        case NodeKind::RETURN, NodeKind::YIELD, NodeKind::IMPORT,
            NodeKind::STRUCT_T, NodeKind::UNION_T, NodeKind::STRUCTURAL_T
            copy.value.body = node.value.body
        case NodeKind::ASSERT
            copy.value.assert_ = node.value.assert_
        case NodeKind::IF, NodeKind::STATIC_IF
            copy.value.if_ = node.value.if_
            copy.body = copy.value.if_.body
        case NodeKind::ELSE_IF
            copy.value.else_if = node.value.else_if
            copy.body = copy.value.else_if.body
        case NodeKind::IF_EXPR
            copy.value.if_expr = node.value.if_expr
        case NodeKind::WHILE
            copy.value.while_loop = node.value.while_loop
            copy.body = copy.value.while_loop.body
        case NodeKind::FOR
            copy.value.for_loop = node.value.for_loop
            copy.body = copy.value.for_loop.body
        case NodeKind::FOR_ID_DECL
            copy.value.for_id_decl = node.value.for_id_decl
        case NodeKind::DEF
            copy.value.def_ = node.value.def_
            copy.body = copy.value.def_.body
        case NodeKind::CASE
            copy.value.case_ = node.value.case_
            copy.body = copy.value.case_.body
        case NodeKind::SWITCH
            copy.value.switch_ = node.value.switch_
            copy.body = copy.value.switch_.body
        case NodeKind::STRING
            copy.value.str = node.value.str
        case NodeKind::IDENTIFIER
            // TODO This is not actually a deep copy
            copy.value.identifier = node.value.identifier
            copy.value.identifier.path = vector::copy(node.value.identifier.path)
        case NodeKind::STRUCT_LIT
            copy.value.struct_lit = node.value.struct_lit
        case NodeKind::IMPORT_MODULE
            copy.value.import_module = node.value.import_module
        case NodeKind::ASSIGN
            copy.value.assign = node.value.assign
        case NodeKind::PARAMETER
            copy.value.param = node.value.param
        case NodeKind::FUNC_CALL
            copy.value.func_call = node.value.func_call
        case NodeKind::TYPE_DECL
            copy.value.type_decl = node.value.type_decl
        case NodeKind::VAR_DECL
            copy.value.var_decl = node.value.var_decl
        case NodeKind::ID_DECL
            copy.value.id_decl = node.value.id_decl
        case NodeKind::NAMED_ARG
            copy.value.named_arg = node.value.named_arg
        case NodeKind::ID_DECL_STRUCT
            copy.value.id_decl_struct = node.value.id_decl_struct
        case NodeKind::ID_DECL_ENUM
            copy.value.id_decl_enum = node.value.id_decl_enum
        case NodeKind::ENUM_T
            copy.value.t_enum = node.value.t_enum
        case NodeKind::FUNCTION_T, NodeKind::CLOSURE_T
            copy.value.t_func = node.value.t_func
        case NodeKind::REF_T, NodeKind::PTR_T, NodeKind::ARRAY_T, NodeKind::WEAK_REF_T
            copy.value.t_parr = node.value.t_parr
        case NodeKind::ARRAY_STATIC_T
            copy.value.t_arrs = node.value.t_arrs
        case NodeKind::VARIANT_T, NodeKind::TUPLE_T
            copy.value.t_variant = node.value.t_variant
        case NodeKind::STRUCTURAL_T_MEMBER
            copy.value.structural_member = node.value.structural_member
        case NodeKind::ERROR, NodeKind::DEFINED, NodeKind::SIZE_OF, NodeKind::ALIGN_OF, NodeKind::TYPE_OF_T,
            NodeKind::UADD..=NodeKind::NOT, NodeKind::ID_ASSIGN, NodeKind::UNSIGNED_T, NodeKind::TYPE_T, NodeKind::YIELD_FROM
            copy.value.expr = node.value.expr
        case NodeKind::RANGE, NodeKind::RANGE_INC, NodeKind::MEMBER_ACCESS,
            NodeKind::CAST, NodeKind::ADD..=NodeKind::OR,
            NodeKind::BAND..=NodeKind::SHR_EQ
            copy.value.bin_op = node.value.bin_op
        case NodeKind::TYPE_CONSTRUCTOR
            copy.value.type_constructor = node.value.type_constructor
        case NodeKind::FROM
            copy.value.from_ = node.value.from_
        case NodeKind::INTEGER, NodeKind::CHAR, NodeKind::FLOAT,
            NodeKind::BOOLEAN, NodeKind::NULL, NodeKind::UNDEF, NodeKind::BREAK, NodeKind::CONTINUE,
            NodeKind::WORD_T, NodeKind::STAR
            copy.value = node.value
        case NodeKind::LAMBDA
            copy.value.lambda = node.value.lambda
        case
            error(node.kind, "\n")
            assert
    }
}

def offset(left: &Vector(&Node), changes: &[server::TextDocumentChangeEvent]) {
    if not left { return }
    for var i in 0..left.length {
        let l = left(i)
        offset(l, changes)
    }
}

export def offset(node: &Node, changes: &[server::TextDocumentChangeEvent]) {
    if not node { return }

    for var change in @changes {
        var same_line = change.end.line == node.loc.line
        if change.end.line < node.loc.line or change.end.line == node.loc.line and change.end.character < node.loc.column {
            node.loc.line += change.lines
        }
        if same_line and change.end.character < node.loc.column {
            node.loc.column += change.characters
        }

        same_line = change.end.line == node.loc.end_line
        if change.end.line < node.loc.end_line or change.end.line == node.loc.end_line and change.end.character < node.loc.end_column {
            node.loc.end_line += change.lines
        }
        if same_line and change.end.character < node.loc.end_column {
            node.loc.end_column += change.characters
        }
    }

    switch node.kind {
        case NodeKind::LOOP, NodeKind::ELSE, NodeKind::DEFER, 
            NodeKind::RETURN, NodeKind::YIELD, NodeKind::IMPORT,
            NodeKind::STRUCT_T, NodeKind::UNION_T, NodeKind::STRUCTURAL_T
            offset(node.value.body, changes)
        case NodeKind::PROGRAM
            offset(node.value.program.body, changes)
        case NodeKind::ASSERT
            offset(node.value.assert_.cond, changes)
            offset(node.value.assert_.message, changes)
        case NodeKind::IF, NodeKind::STATIC_IF
            offset(node.value.if_.cond, changes)
            offset(node.value.if_.else_if, changes)
            offset(node.value.if_.else_, changes)
            offset(node.value.if_.body, changes)
        case NodeKind::ELSE_IF
            offset(node.value.else_if.cond, changes)
            offset(node.value.else_if.body, changes)
        case NodeKind::IF_EXPR
            offset(node.value.if_expr.cond, changes)
            offset(node.value.if_expr.if_true, changes)
            offset(node.value.if_expr.if_false, changes)
        case NodeKind::WHILE
            offset(node.value.while_loop.expr, changes)
            offset(node.value.while_loop.body, changes)
        case NodeKind::FOR
            offset(node.value.for_loop.iddecl, changes)
            offset(node.value.for_loop.expr, changes)
            offset(node.value.for_loop.body, changes)
        case NodeKind::FOR_ID_DECL
            offset(node.value.for_id_decl.ident, changes)
        case NodeKind::DEF
            offset(node.value.def_.params, changes)
            offset(node.value.def_.name, changes)
            offset(node.value.def_.returns, changes)
            offset(node.value.def_.body, changes)
        case NodeKind::CASE
            offset(node.value.case_.expr, changes)
            offset(node.value.case_.body, changes)
        case NodeKind::SWITCH
            offset(node.value.switch_.expr, changes)
            offset(node.value.switch_.body, changes)
        case NodeKind::STRING
        case NodeKind::IDENTIFIER
        case NodeKind::STRUCT_LIT
            offset(node.value.struct_lit.args, changes)
            offset(node.value.struct_lit.kwargs, changes)
        case NodeKind::IMPORT_MODULE
            offset(node.value.import_module.name, changes)
            offset(node.value.import_module.alias, changes)
        case NodeKind::ASSIGN
            offset(node.value.assign.left, changes)
            offset(node.value.assign.right, changes)
        case NodeKind::PARAMETER
            offset(node.value.param.name, changes)
            offset(node.value.param.tpe, changes)
            offset(node.value.param.value, changes)
        case NodeKind::FUNC_CALL
            offset(node.value.func_call.left, changes)
            offset(node.value.func_call.args, changes)
            offset(node.value.func_call.kwargs, changes)
        case NodeKind::TYPE_DECL
            offset(node.value.type_decl.left, changes)
            offset(node.value.type_decl.right, changes)
        case NodeKind::VAR_DECL
            offset(node.value.var_decl.left, changes)
            offset(node.value.var_decl.right, changes)
        case NodeKind::ID_DECL
            offset(node.value.id_decl.value, changes)
            offset(node.value.id_decl.tpe, changes)
        case NodeKind::NAMED_ARG
            offset(node.value.named_arg.name, changes)
            offset(node.value.named_arg.value, changes)
        case NodeKind::ID_DECL_STRUCT
            offset(node.value.id_decl_struct.ident, changes)
            offset(node.value.id_decl_struct.tpe, changes)
            offset(node.value.id_decl_struct.value, changes)
        case NodeKind::ID_DECL_ENUM
            offset(node.value.id_decl_enum.ident, changes)
            offset(node.value.id_decl_enum.value, changes)
        case NodeKind::ENUM_T
            offset(node.value.t_enum.tpe, changes)
            offset(node.value.t_enum.body, changes)
        case NodeKind::FUNCTION_T, NodeKind::CLOSURE_T
            offset(node.value.t_func.args, changes)
            offset(node.value.t_func.ret, changes)
        case NodeKind::REF_T, NodeKind::PTR_T, NodeKind::ARRAY_T, NodeKind::WEAK_REF_T
            offset(node.value.t_parr.tpe, changes)
        case NodeKind::ARRAY_STATIC_T
            offset(node.value.t_arrs.tpe, changes)
        case NodeKind::VARIANT_T, NodeKind::TUPLE_T
            offset(node.value.t_variant.variants, changes)
        case NodeKind::STRUCTURAL_T_MEMBER
            offset(node.value.structural_member.name, changes)
            offset(node.value.structural_member.params, changes)
            offset(node.value.structural_member.returns, changes)
        case NodeKind::ERROR, NodeKind::DEFINED, NodeKind::SIZE_OF, NodeKind::ALIGN_OF, NodeKind::TYPE_OF_T,
            NodeKind::UADD..=NodeKind::NOT, NodeKind::ID_ASSIGN, NodeKind::UNSIGNED_T, NodeKind::TYPE_T, NodeKind::YIELD_FROM
            offset(node.value.expr, changes)
        case NodeKind::RANGE, NodeKind::RANGE_INC, NodeKind::MEMBER_ACCESS,
            NodeKind::CAST, NodeKind::ADD..=NodeKind::OR,
            NodeKind::BAND..=NodeKind::SHR_EQ:
            offset(node.value.bin_op.left, changes)
            offset(node.value.bin_op.right, changes)
        case NodeKind::TYPE_CONSTRUCTOR
            offset(node.value.type_constructor.name, changes)
            offset(node.value.type_constructor.args, changes)
        case NodeKind::FROM
            offset(node.value.from_.module, changes)
            offset(node.value.from_.idents, changes)
        case NodeKind::INTEGER, NodeKind::CHAR, NodeKind::FLOAT,
            NodeKind::BOOLEAN, NodeKind::NULL, NodeKind::UNDEF, NodeKind::BREAK, NodeKind::CONTINUE,
            NodeKind::WORD_T, NodeKind::STAR
        case NodeKind::LAMBDA
            offset(node.value.lambda.parameters, changes)
            offset(node.value.lambda.body, changes)
        case
            error(node.kind, "\n")
            assert
    }
}

def clear(vec: &Vector(&Node)) {
    if not vec { return }

    for var i in 0..vec.length {
        clear(vec(i))
    }
}

export def clear(node: &Node) {
    if not node { return }
    node.tpe = null
    node.svalue = null

    switch node.kind {
        case NodeKind::LOOP, NodeKind::ELSE, NodeKind::DEFER, 
            NodeKind::RETURN, NodeKind::YIELD, NodeKind::IMPORT,
            NodeKind::STRUCT_T, NodeKind::UNION_T, NodeKind::STRUCTURAL_T
            clear(node.value.body)
        case NodeKind::PROGRAM
            clear(node.value.program.body)
        case NodeKind::ASSERT
            clear(node.value.assert_.cond)
            clear(node.value.assert_.message)
        case NodeKind::IF, NodeKind::STATIC_IF
            clear(node.value.if_.cond)
            clear(node.value.if_.else_if)
            clear(node.value.if_.else_)
            clear(node.value.if_.body)
        case NodeKind::ELSE_IF
            clear(node.value.else_if.cond)
            clear(node.value.else_if.body)
        case NodeKind::IF_EXPR
            clear(node.value.if_expr.cond)
            clear(node.value.if_expr.if_true)
            clear(node.value.if_expr.if_false)
        case NodeKind::WHILE
            clear(node.value.while_loop.expr)
            clear(node.value.while_loop.body)
        case NodeKind::FOR
            clear(node.value.for_loop.iddecl)
            clear(node.value.for_loop.expr)
            clear(node.value.for_loop.body)
        case NodeKind::FOR_ID_DECL
            clear(node.value.for_id_decl.ident)
        case NodeKind::DEF
            clear(node.value.def_.params)
            clear(node.value.def_.name)
            clear(node.value.def_.returns)
            clear(node.value.def_.body)
        case NodeKind::CASE
            clear(node.value.case_.expr)
            clear(node.value.case_.body)
        case NodeKind::SWITCH
            clear(node.value.switch_.expr)
            clear(node.value.switch_.body)
        case NodeKind::STRING
        case NodeKind::IDENTIFIER
        case NodeKind::STRUCT_LIT
            clear(node.value.struct_lit.args)
            clear(node.value.struct_lit.kwargs)
        case NodeKind::IMPORT_MODULE
            clear(node.value.import_module.name)
            clear(node.value.import_module.alias)
        case NodeKind::ASSIGN
            clear(node.value.assign.left)
            clear(node.value.assign.right)
        case NodeKind::PARAMETER
            clear(node.value.param.name)
            clear(node.value.param.tpe)
            clear(node.value.param.value)
        case NodeKind::FUNC_CALL
            clear(node.value.func_call.left)
            clear(node.value.func_call.args)
            clear(node.value.func_call.kwargs)
        case NodeKind::TYPE_DECL
            clear(node.value.type_decl.left)
            clear(node.value.type_decl.right)
        case NodeKind::VAR_DECL
            clear(node.value.var_decl.left)
            clear(node.value.var_decl.right)
        case NodeKind::ID_DECL
            clear(node.value.id_decl.value)
            clear(node.value.id_decl.tpe)
        case NodeKind::NAMED_ARG
            clear(node.value.named_arg.name)
            clear(node.value.named_arg.value)
        case NodeKind::ID_DECL_STRUCT
            clear(node.value.id_decl_struct.ident)
            clear(node.value.id_decl_struct.tpe)
            clear(node.value.id_decl_struct.value)
        case NodeKind::ID_DECL_ENUM
            clear(node.value.id_decl_enum.ident)
            clear(node.value.id_decl_enum.value)
        case NodeKind::ENUM_T
            clear(node.value.t_enum.tpe)
            clear(node.value.t_enum.body)
        case NodeKind::FUNCTION_T, NodeKind::CLOSURE_T
            clear(node.value.t_func.args)
            clear(node.value.t_func.ret)
        case NodeKind::REF_T, NodeKind::PTR_T, NodeKind::ARRAY_T, NodeKind::WEAK_REF_T
            clear(node.value.t_parr.tpe)
        case NodeKind::ARRAY_STATIC_T
            clear(node.value.t_arrs.tpe)
        case NodeKind::VARIANT_T, NodeKind::TUPLE_T
            clear(node.value.t_variant.variants)
        case NodeKind::STRUCTURAL_T_MEMBER
            clear(node.value.structural_member.name)
            clear(node.value.structural_member.params)
            clear(node.value.structural_member.returns)
        case NodeKind::ERROR, NodeKind::DEFINED, NodeKind::SIZE_OF, NodeKind::ALIGN_OF, NodeKind::TYPE_OF_T,
            NodeKind::UADD..=NodeKind::NOT, NodeKind::ID_ASSIGN, NodeKind::UNSIGNED_T, NodeKind::TYPE_T, NodeKind::YIELD_FROM
            clear(node.value.expr)
        case NodeKind::RANGE, NodeKind::RANGE_INC, NodeKind::MEMBER_ACCESS,
            NodeKind::CAST, NodeKind::ADD..=NodeKind::OR,
            NodeKind::BAND..=NodeKind::SHR_EQ
            clear(node.value.bin_op.left)
            clear(node.value.bin_op.right)
        case NodeKind::TYPE_CONSTRUCTOR
            clear(node.value.type_constructor.name)
            clear(node.value.type_constructor.args)
        case NodeKind::FROM
            clear(node.value.from_.module)
            clear(node.value.from_.idents)
        case NodeKind::INTEGER, NodeKind::CHAR, NodeKind::FLOAT,
            NodeKind::BOOLEAN, NodeKind::NULL, NodeKind::UNDEF, NodeKind::BREAK, NodeKind::CONTINUE,
            NodeKind::WORD_T, NodeKind::STAR
        case NodeKind::LAMBDA
            clear(node.value.lambda.parameters)
            clear(node.value.lambda.body)
        case
            error(node.kind, "\n")
            assert
    }
}

def find(vec: &Vector(&Node), line: int, column: int) -> &Node {
    if not vec { return null }
    // TODO iterating vector doesn't work for some reason
    for var i in 0..vec.length {
        var node = vec(i)
        let n2 = find(node, line, column)
        if n2 {
            return n2 
        }
    }
    return null
}

export def find(node: &Node, line: int, column: int) -> &Node {
    if not node { return null }
    //error("Node: ", node.kind, " ", node.loc.line, " ", node.loc.end_line, " ", node.loc.column, " ", node.loc.end_column, "\n")
    //error("Position: ", line, " ", column, "\n")
    if line > node.loc.line and line < node.loc.end_line or
        /* on first line */ line == node.loc.line and column >= node.loc.column and 
            (node.loc.end_line > node.loc.line or column <= node.loc.end_column) or
        /* on last line */ line == node.loc.end_line and column <= node.loc.end_column and 
            (node.loc.line < node.loc.end_line or column >= node.loc.column) {

        switch node.kind {
            case NodeKind::LOOP, NodeKind::ELSE, NodeKind::DEFER, 
                NodeKind::RETURN, NodeKind::YIELD, NodeKind::IMPORT,
                NodeKind::STRUCT_T, NodeKind::UNION_T, NodeKind::STRUCTURAL_T
                var n2 = find(node.value.body, line, column)
                if n2 { return n2 }
            case NodeKind::PROGRAM
                var n2 = find(node.value.program.body, line, column)
                if n2 { return n2 }
            case NodeKind::ASSERT
                var n2 = find(node.value.assert_.cond, line, column)
                if n2 { return n2 }
                n2 = find(node.value.assert_.message, line, column)
                if n2 { return n2 }
            case NodeKind::IF, NodeKind::STATIC_IF
                var n2 = find(node.value.if_.cond, line, column)
                if n2 { return n2 }
                n2 = find(node.value.if_.body, line, column)
                if n2 { return n2 }
                n2 = find(node.value.if_.else_if, line, column)
                if n2 { return n2 }
                n2 = find(node.value.if_.else_, line, column)
                if n2 { return n2 }
            case NodeKind::ELSE_IF
                var n2 = find(node.value.else_if.cond, line, column)
                if n2 { return n2 }
                n2 = find(node.value.else_if.body, line, column)
                if n2 { return n2 }
            case NodeKind::IF_EXPR
                var n2 = find(node.value.if_expr.if_true, line, column)
                if n2 { return n2 }
                n2 = find(node.value.if_expr.cond, line, column)
                if n2 { return n2 }
                n2 = find(node.value.if_expr.if_false, line, column)
                if n2 { return n2 }
            case NodeKind::WHILE
                var n2 = find(node.value.while_loop.expr, line, column)
                if n2 { return n2 }
                n2 = find(node.value.while_loop.body, line, column)
                if n2 { return n2 }
            case NodeKind::FOR
                var n2 = find(node.value.for_loop.iddecl, line, column)
                if n2 { return n2 }
                n2 = find(node.value.for_loop.expr, line, column)
                if n2 { return n2 }
                n2 = find(node.value.for_loop.body, line, column)
                if n2 { return n2 }
            case NodeKind::FOR_ID_DECL
                var n2 = find(node.value.for_id_decl.ident, line, column)
                if n2 { return n2 }
            case NodeKind::DEF
                var n2 = find(node.value.def_.name, line, column)
                if n2 { return n2 }
                n2 = find(node.value.def_.params, line, column)
                if n2 { return n2 }
                n2 = find(node.value.def_.returns, line, column)
                if n2 { return n2 }
                n2 = find(node.value.def_.body, line, column)
                if n2 { return n2 }
            case NodeKind::CASE
                var n2 = find(node.value.case_.expr, line, column)
                if n2 { return n2 }
                n2 = find(node.value.case_.body, line, column)
                if n2 { return n2 }
            case NodeKind::SWITCH
                var n2 = find(node.value.switch_.expr, line, column)
                if n2 { return n2 }
                n2 = find(node.value.switch_.body, line, column)
                if n2 { return n2 }
            case NodeKind::STRING
                return node
            case NodeKind::IDENTIFIER
                return node
            case NodeKind::STRUCT_LIT
                var n2 = find(node.value.struct_lit.args, line, column)
                if n2 { return n2 }
                n2 = find(node.value.struct_lit.kwargs, line, column)
                if n2 { return n2 }
            case NodeKind::IMPORT_MODULE
                var n2 = find(node.value.import_module.name, line, column)
                if n2 { return n2 }
                n2 = find(node.value.import_module.alias, line, column)
                if n2 { return n2 }
            case NodeKind::ASSIGN
                var n2 = find(node.value.assign.left, line, column)
                if n2 { return n2 }
                n2 = find(node.value.assign.right, line, column)
                if n2 { return n2 }
            case NodeKind::PARAMETER
                var n2 = find(node.value.param.name, line, column)
                if n2 { return n2 }
                n2 = find(node.value.param.tpe, line, column)
                if n2 { return n2 }
                n2 = find(node.value.param.value, line, column)
                if n2 { return n2 }
            case NodeKind::FUNC_CALL
                var n2 = find(node.value.func_call.left, line, column)
                if n2 { return n2 }
                n2 = find(node.value.func_call.args, line, column)
                if n2 { return n2 }
                n2 = find(node.value.func_call.kwargs, line, column)
                if n2 { return n2 }
            case NodeKind::TYPE_DECL
                var n2 = find(node.value.type_decl.left, line, column)
                if n2 { return n2 }
                n2 = find(node.value.type_decl.right, line, column)
                if n2 { return n2 }
            case NodeKind::VAR_DECL
                var n2 = find(node.value.var_decl.left, line, column)
                if n2 { return n2 }
                n2 = find(node.value.var_decl.right, line, column)
                if n2 { return n2 }
            case NodeKind::ID_DECL
                var n2 = find(node.value.id_decl.value, line, column)
                if n2 { return n2 }
                n2 = find(node.value.id_decl.tpe, line, column)
                if n2 { return n2 }
            case NodeKind::NAMED_ARG
                var n2 = find(node.value.named_arg.name, line, column)
                if n2 { return n2 }
                n2 = find(node.value.named_arg.value, line, column)
                if n2 { return n2 }
            case NodeKind::ID_DECL_STRUCT
                var n2 = find(node.value.id_decl_struct.ident, line, column)
                if n2 { return n2 }
                n2 = find(node.value.id_decl_struct.tpe, line, column)
                if n2 { return n2 }
                n2 = find(node.value.id_decl_struct.value, line, column)
                if n2 { return n2 }
            case NodeKind::ID_DECL_ENUM
                var n2 = find(node.value.id_decl_enum.ident, line, column)
                if n2 { return n2 }
                n2 = find(node.value.id_decl_enum.value, line, column)
                if n2 { return n2 }
            case NodeKind::ENUM_T
                var n2 = find(node.value.t_enum.tpe, line, column)
                if n2 { return n2 }
                n2 = find(node.value.t_enum.body, line, column)
                if n2 { return n2 }
            case NodeKind::FUNCTION_T, NodeKind::CLOSURE_T
                var n2 = find(node.value.t_func.args, line, column)
                if n2 { return n2 }
                n2 = find(node.value.t_func.ret, line, column)
                if n2 { return n2 }
            case NodeKind::REF_T, NodeKind::PTR_T, NodeKind::ARRAY_T, NodeKind::WEAK_REF_T
                var n2 = find(node.value.t_parr.tpe, line, column)
                if n2 { return n2 }
            case NodeKind::ARRAY_STATIC_T
                var n2 = find(node.value.t_arrs.n, line, column)
                if n2 { return n2 }
                n2 = find(node.value.t_arrs.tpe, line, column)
                if n2 { return n2 }
            case NodeKind::VARIANT_T, NodeKind::TUPLE_T
                var n2 = find(node.value.t_variant.variants, line, column)
                if n2 { return n2 }
            case NodeKind::STRUCTURAL_T_MEMBER
                var n2 = find(node.value.structural_member.name, line, column)
                if n2 { return n2 }
                n2 = find(node.value.structural_member.params, line, column)
                if n2 { return n2 }
                n2 = find(node.value.structural_member.returns, line, column)
                if n2 { return n2 }
            case NodeKind::ERROR, NodeKind::DEFINED, NodeKind::SIZE_OF, NodeKind::ALIGN_OF, NodeKind::TYPE_OF_T,
                NodeKind::UADD..=NodeKind::NOT, NodeKind::ID_ASSIGN, NodeKind::UNSIGNED_T, NodeKind::TYPE_T, NodeKind::YIELD_FROM
                var n2 = find(node.value.expr, line, column)
                if n2 { return n2 }
            case NodeKind::RANGE, NodeKind::RANGE_INC, NodeKind::MEMBER_ACCESS,
                NodeKind::CAST, NodeKind::ADD..=NodeKind::OR,
                NodeKind::BAND..=NodeKind::SHR_EQ
                var n2 = find(node.value.bin_op.left, line, column)
                if n2 { return n2 }
                n2 = find(node.value.bin_op.right, line, column)
                if n2 { return n2 }
            case NodeKind::FROM
                var n2 = find(node.value.from_.module, line, column)
                if n2 { return n2 }
                n2 = find(node.value.from_.idents, line, column)
                if n2 { return n2 }
            case NodeKind::TYPE_CONSTRUCTOR
                var n2 = find(node.value.type_constructor.name, line, column)
                if n2 { return n2 }
                n2 = find(node.value.type_constructor.args, line, column)
                if n2 { return n2 }
            case NodeKind::INTEGER, NodeKind::CHAR, NodeKind::FLOAT,
                NodeKind::BOOLEAN, NodeKind::NULL, NodeKind::UNDEF, NodeKind::BREAK, NodeKind::CONTINUE,
                NodeKind::WORD_T, NodeKind::STAR
                return node
            case NodeKind::LAMBDA
                var n2 = find(node.value.lambda.parameters, line, column)
                if n2 { return n2 }
                n2 = find(node.value.lambda.body, line, column)
                if n2 { return n2 }
            case
                error(node.kind, "\n")
                assert
        }
        return node
    }
    return null
}

export type ParseState = struct {
    filename: Str
    display_name: Str
    module: Str
    has_error: bool
    has_yield: bool
    lines: &[Str]
    tokens: *lexer::TokenList
    last_token: *lexer::TokenList
    last_string: String
}

export def current_module(state: &ParseState) -> &toolchain::Module {
    return toolchain::find_module_by_path(state.filename)
}

export def make_identifier(s: String...) -> &Node {
    let vec = vector::make(String)
    for var i in 0..s.size {
        vec.push(s(i))
    }

    let node = [
        kind = NodeKind::IDENTIFIER,
        loc = [
            filename = "builtins",
            line = -1,
            column = -1            
        ] !SourceLoc
    ] !Node
    node.value.identifier.path = vec
    return node
}

export def identifier_from_str(s: Str) -> &Node {
    return make_identifier(@util::split(s, "::"))
}

// This copies a node, all the contents are the same
export def copy_node(node: &Node) -> &Node {
    let copy: &Node = @node
    return copy
}

def deep_copy_vector_of_nodes(v: &Vector(&Node), clear_svalue: bool = true) -> &Vector(&Node) {
    if not v { return null }
    let copy = vector::make(type &Node)
    for var i in 0..vector::length(v) {
        var node = v(i)
        node = deep_copy_node(node, clear_svalue)
        copy.push(node)
    }
    return copy
}

export def deep_copy_node(node: &Node, clear_svalue: bool = true) -> &Node {
    if not node { return null }
    let copy: &Node = @node
    if clear_svalue {
        copy.svalue = null
    }
    copy.tpe = typechecking::copy(node.tpe)

    switch node.kind {
        case NodeKind::PROGRAM
            copy.value.program.body = deep_copy_vector_of_nodes(node.value.program.body, clear_svalue)
            copy.body = copy.value.program.body
        case NodeKind::LOOP, NodeKind::ELSE, NodeKind::DEFER
            copy.value.body = deep_copy_vector_of_nodes(node.value.body, clear_svalue)
            copy.body = copy.value.body
        case NodeKind::RETURN, NodeKind::YIELD, NodeKind::IMPORT,
            NodeKind::STRUCT_T, NodeKind::UNION_T, NodeKind::STRUCTURAL_T
            copy.value.body = deep_copy_vector_of_nodes(node.value.body, clear_svalue)
        case NodeKind::ASSERT
            copy.value.assert_.cond = deep_copy_node(node.value.assert_.cond, clear_svalue)
            copy.value.assert_.message = deep_copy_node(node.value.assert_.message, clear_svalue)
        case NodeKind::IF, NodeKind::STATIC_IF
            copy.value.if_.cond = deep_copy_node(node.value.if_.cond, clear_svalue)
            copy.value.if_.else_if = deep_copy_vector_of_nodes(node.value.if_.else_if, clear_svalue)
            copy.value.if_.else_ = deep_copy_node(node.value.if_.else_, clear_svalue)
            copy.value.if_.body = deep_copy_vector_of_nodes(node.value.if_.body, clear_svalue)
            copy.body = copy.value.if_.body
        case NodeKind::ELSE_IF
            copy.value.else_if.cond = deep_copy_node(node.value.else_if.cond, clear_svalue)
            copy.value.else_if.body = deep_copy_vector_of_nodes(node.value.else_if.body, clear_svalue)
            copy.body = copy.value.else_if.body
        case NodeKind::IF_EXPR
            copy.value.if_expr.cond = deep_copy_node(node.value.if_expr.cond, clear_svalue)
            copy.value.if_expr.if_true = deep_copy_node(node.value.if_expr.if_true, clear_svalue)
            copy.value.if_expr.if_false = deep_copy_node(node.value.if_expr.if_false, clear_svalue)
        case NodeKind::WHILE
            copy.value.while_loop.expr = deep_copy_node(node.value.while_loop.expr, clear_svalue)
            copy.value.while_loop.body = deep_copy_vector_of_nodes(node.value.while_loop.body, clear_svalue)
            copy.body = copy.value.while_loop.body
        case NodeKind::FOR
            copy.value.for_loop.iddecl = deep_copy_node(node.value.for_loop.iddecl, clear_svalue)
            copy.value.for_loop.expr = deep_copy_node(node.value.for_loop.expr, clear_svalue)
            copy.value.for_loop.body = deep_copy_vector_of_nodes(node.value.for_loop.body, clear_svalue)
            copy.body = copy.value.for_loop.body
        case NodeKind::FOR_ID_DECL
            copy.value.for_id_decl.ident = deep_copy_node(node.value.for_id_decl.ident, clear_svalue)
        case NodeKind::DEF
            copy.value.def_.params = deep_copy_vector_of_nodes(node.value.def_.params, clear_svalue)
            copy.value.def_.returns = deep_copy_vector_of_nodes(node.value.def_.returns, clear_svalue)
            copy.value.def_.body = deep_copy_vector_of_nodes(node.value.def_.body, clear_svalue)
            copy.body = copy.value.def_.body
        case NodeKind::CASE
            copy.value.case_.expr = deep_copy_vector_of_nodes(node.value.case_.expr, clear_svalue)
            copy.value.case_.body = deep_copy_vector_of_nodes(node.value.case_.body, clear_svalue)
            copy.body = copy.value.case_.body
        case NodeKind::SWITCH
            copy.value.switch_.expr = deep_copy_node(node.value.switch_.expr, clear_svalue)
            copy.value.switch_.body = deep_copy_vector_of_nodes(node.value.switch_.body, clear_svalue)
            copy.body = copy.value.switch_.body
        case NodeKind::STRING
            copy.value.str = node.value.str
        case NodeKind::IDENTIFIER
            // TODO This is not actually a deep copy
            copy.value.identifier.path = vector::copy(node.value.identifier.path)
            copy.value.identifier.args = deep_copy_vector_of_nodes(node.value.identifier.args, clear_svalue)
        case NodeKind::STRUCT_LIT
            copy.value.struct_lit.args = deep_copy_vector_of_nodes(node.value.struct_lit.args, clear_svalue)
            copy.value.struct_lit.kwargs = deep_copy_vector_of_nodes(node.value.struct_lit.kwargs, clear_svalue)
        case NodeKind::IMPORT_MODULE
            copy.value.import_module.name = deep_copy_node(node.value.import_module.name, clear_svalue)
            copy.value.import_module.alias = deep_copy_node(node.value.import_module.alias, clear_svalue)
        case NodeKind::ASSIGN
            copy.value.assign.left = deep_copy_vector_of_nodes(node.value.assign.left, clear_svalue)
            copy.value.assign.right = deep_copy_vector_of_nodes(node.value.assign.right, clear_svalue)
        case NodeKind::PARAMETER
            copy.value.param.name = deep_copy_node(node.value.param.name, clear_svalue)
            copy.value.param.tpe = deep_copy_node(node.value.param.tpe, clear_svalue)
            copy.value.param.value = deep_copy_node(node.value.param.value, clear_svalue)
        case NodeKind::FUNC_CALL
            copy.value.func_call.left = deep_copy_node(node.value.func_call.left, clear_svalue)
            copy.value.func_call.args = deep_copy_vector_of_nodes(node.value.func_call.args, clear_svalue)
            copy.value.func_call.kwargs = deep_copy_vector_of_nodes(node.value.func_call.kwargs, clear_svalue)
        case NodeKind::TYPE_DECL
            copy.value.type_decl.left = deep_copy_vector_of_nodes(node.value.type_decl.left, clear_svalue)
            copy.value.type_decl.right = deep_copy_vector_of_nodes(node.value.type_decl.right, clear_svalue)
        case NodeKind::VAR_DECL
            copy.value.var_decl.left = deep_copy_vector_of_nodes(node.value.var_decl.left, clear_svalue)
            copy.value.var_decl.right = deep_copy_vector_of_nodes(node.value.var_decl.right, clear_svalue)
        case NodeKind::ID_DECL
            copy.value.id_decl.value = deep_copy_node(node.value.id_decl.value, clear_svalue)
            copy.value.id_decl.tpe = deep_copy_node(node.value.id_decl.tpe, clear_svalue)
        case NodeKind::NAMED_ARG
            copy.value.named_arg.name = deep_copy_node(node.value.named_arg.name, clear_svalue)
            copy.value.named_arg.value = deep_copy_node(node.value.named_arg.value, clear_svalue)
        case NodeKind::ID_DECL_STRUCT
            copy.value.id_decl_struct.ident = deep_copy_node(node.value.id_decl_struct.ident, clear_svalue)
            copy.value.id_decl_struct.tpe = deep_copy_node(node.value.id_decl_struct.tpe, clear_svalue)
            copy.value.id_decl_struct.value = deep_copy_node(node.value.id_decl_struct.value, clear_svalue)
        case NodeKind::ID_DECL_ENUM
            copy.value.id_decl_enum.ident = deep_copy_node(node.value.id_decl_enum.ident, clear_svalue)
            copy.value.id_decl_enum.value = deep_copy_node(node.value.id_decl_enum.value, clear_svalue)
        case NodeKind::ENUM_T
            copy.value.t_enum.tpe = deep_copy_node(node.value.t_enum.tpe, clear_svalue)
            copy.value.t_enum.body = deep_copy_vector_of_nodes(node.value.t_enum.body, clear_svalue)
        case NodeKind::FUNCTION_T, NodeKind::CLOSURE_T
            copy.value.t_func.args = deep_copy_vector_of_nodes(node.value.t_func.args, clear_svalue)
            copy.value.t_func.ret = deep_copy_vector_of_nodes(node.value.t_func.ret, clear_svalue)
        case NodeKind::REF_T, NodeKind::PTR_T, NodeKind::ARRAY_T, NodeKind::WEAK_REF_T
            copy.value.t_parr.tpe = deep_copy_node(node.value.t_parr.tpe, clear_svalue)
        case NodeKind::ARRAY_STATIC_T
            copy.value.t_arrs.tpe = deep_copy_node(node.value.t_arrs.tpe, clear_svalue)
        case NodeKind::VARIANT_T, NodeKind::TUPLE_T
            copy.value.t_variant.variants = deep_copy_vector_of_nodes(node.value.t_variant.variants, clear_svalue)
        case NodeKind::STRUCTURAL_T_MEMBER
            copy.value.structural_member.name = deep_copy_node(node.value.structural_member.name, clear_svalue)
            copy.value.structural_member.params = deep_copy_vector_of_nodes(node.value.structural_member.params, clear_svalue)
            copy.value.structural_member.returns = deep_copy_vector_of_nodes(node.value.structural_member.returns, clear_svalue)
        case NodeKind::ERROR, NodeKind::DEFINED, NodeKind::SIZE_OF, NodeKind::ALIGN_OF, NodeKind::TYPE_OF_T,
            NodeKind::UADD..=NodeKind::NOT, NodeKind::ID_ASSIGN, NodeKind::UNSIGNED_T, NodeKind::TYPE_T, NodeKind::YIELD_FROM
            // Unary op
            copy.value.expr = deep_copy_node(node.value.expr, clear_svalue)
        case NodeKind::RANGE, NodeKind::RANGE_INC, NodeKind::MEMBER_ACCESS,
            NodeKind::CAST, NodeKind::ADD..=NodeKind::OR,
            NodeKind::BAND..=NodeKind::SHR_EQ
            // Binary op
            copy.value.bin_op.left = deep_copy_node(node.value.bin_op.left, clear_svalue)
            copy.value.bin_op.right = deep_copy_node(node.value.bin_op.right, clear_svalue)
        case NodeKind::FROM
            copy.value.from_.module = deep_copy_node(node.value.from_.module, clear_svalue)
            copy.value.from_.idents = deep_copy_vector_of_nodes(node.value.from_.idents, clear_svalue)
        case NodeKind::TYPE_CONSTRUCTOR
            copy.value.type_constructor.name = deep_copy_node(node.value.type_constructor.name, clear_svalue)
            copy.value.type_constructor.args = deep_copy_vector_of_nodes(node.value.type_constructor.args, clear_svalue)
        case NodeKind::INTEGER, NodeKind::CHAR, NodeKind::FLOAT,
            NodeKind::BOOLEAN, NodeKind::NULL, NodeKind::UNDEF, NodeKind::BREAK, NodeKind::CONTINUE,
            NodeKind::WORD_T, NodeKind::STAR
        case NodeKind::LAMBDA
            copy.value.lambda.parameters = deep_copy_vector_of_nodes(node.value.lambda.parameters, clear_svalue)
            copy.value.lambda.body = deep_copy_vector_of_nodes(node.value.lambda.body, clear_svalue)
        case
            error(node.kind, "\n")
            assert
    }

    return copy
}

export def identifier_to_str(node: &Node, types: bool = true) -> Str {
    assert node.kind == NodeKind::IDENTIFIER
    var res: StringBuffer = ""
    let len = vector::length(node.value.identifier.path)
    for var i in 0..len {
        res += node.value.identifier.path(i)
        if i < len - 1 {
            res += "::"
        }
    }
    if types and node.value.identifier.types {
        let len = vector::length(node.value.identifier.types)
        res += "::"
        if len > 0 {
            res += '('
            for var i in 0..len {
                let np = node.value.identifier.types(i)
                res += debug::type_to_str(np.tpe, full_name = true)
                if i < len - 1 {
                    res += ", "
                }
            }
            res += ')'
        }
    }

    return res
}

def make_node(kind: NodeKind, line: int, column: int, state: &ParseState) -> &Node {
    state.last_string = null

    var end_line = 0
    var end_column = 0

    if state.last_token {
        end_line = state.last_token.value.end_line
        end_column = state.last_token.value.end_column
    } else {
        let current_token = peek(state)
        end_line = current_token.line
        end_column = current_token.column
    }

    return [
        kind = kind,
        loc = [
            filename = state.filename,
            display_name = state.display_name,
            module = state.module,
            line = line,
            column = column,
            end_line = end_line,
            end_column = end_column
        ] !SourceLoc
    ] !Node
}

def make_bin_op(state: &ParseState, token: lexer::Token, kind: NodeKind, left: &Node, right: &Node, check_arity: bool = true) -> &Node {
    var node = make_node(kind, token.line, token.column, state)
    node.value.bin_op = [
        left = left, right = right
    ] !NodeBinaryOp
    node._hash = combine_hashes(kind !uint64, left.hash, right.hash)

    if check_arity {
        if not left {
            errors::errorn(node, "Expected left hand side of operator")
        } else if not right {
            errors::errorn(node, "Expected right hand side of operator")
        }
    }

    return node
}

def make_un_op(state: &ParseState, token: lexer::Token, kind: NodeKind, right: &Node) -> &Node {
    var node = make_node(kind, token.line, token.column, state)
    node.value.expr = right
    node._hash = combine_hashes(kind !uint64, right.hash)

    return node
}

def skip_whitespace(state: &ParseState) {
    if not state.tokens { return }
    var tt = state.tokens.value.tpe
    while tt == lexer::TokenType::WHITESPACE or 
        tt == lexer::TokenType::COMMENT or
        tt == lexer::TokenType::ERROR {

        if tt == lexer::TokenType::ERROR {
            let token = state.tokens.value
            errors::errort(token, state, token.value.str)
        }

        state.tokens = state.tokens.next
        if not state.tokens { return }
        tt = state.tokens.value.tpe
    }
}

def make_eof(state: &ParseState) -> lexer::Token {
    let lines = state.lines
    var line = 0
    var column = 0
    if lines.size > 0 {
        line = (lines.size - 1) !int
        column = (lines(line).length) !int
    }
    return [ 
        tpe = lexer::TokenType::EOF, 
        line = line, 
        column = column, 
        end_line = line, 
        end_column = column + 1 
    ] !lexer::Token
}

def pop(state: &ParseState) -> lexer::Token {
    skip_whitespace(state)
    if not state.tokens {
        return make_eof(state)
    }
    let token = state.tokens.value
    state.last_token = state.tokens
    state.tokens = state.tokens.next
    return token
}

def peek(state: &ParseState) -> lexer::Token {
    skip_whitespace(state)
    if not state.tokens {
        return make_eof(state)
    }
    return state.tokens.value
}

def peek(state: &ParseState, look_ahead: int) -> lexer::Token {
    skip_newline(state)
    if not state.tokens {
        return make_eof(state)
    }
    let prev_tokens = state.tokens
    while look_ahead > 0 and state.tokens {
        state.tokens = state.tokens.next
        skip_whitespace(state)
        look_ahead -= 1
    }
    let end = state.tokens
    state.tokens = prev_tokens
    if not end {
        return make_eof(state)
    }
    return end.value
}

def back(state: &ParseState) {
    assert state.last_token != null
    state.tokens = state.last_token
    state.last_token = null
}

def expect(state: &ParseState, tpe: lexer::TokenType, msg: Str) -> lexer::Token {
    let token = pop(state)
    if token.tpe != tpe {
        errors::errort(token, state, msg)
    }
    return token
}

def skip_newline(state: &ParseState) {
    loop {
        let token = peek(state)
        if token.tpe == lexer::TokenType::NEW_LINE {
            pop(state)
            continue
        }
        break
    }
}

def next_token(state: &ParseState, tpe: lexer::TokenType) -> bool {
    let token = peek(state)
    if token.tpe == tpe {
        pop(state)
        return true
    }
    return false
}

def expect_identifier(parse_state: &ParseState) -> &Node {
    var token = peek(parse_state)
    if token.tpe != lexer::TokenType::IDENTIFIER {
        errors::errort(token, parse_state, "Expected identifier")
        return null
    }
    return parse_identifier(parse_state)
}

def parse_identifier(parse_state: &ParseState) -> &Node {
    var token = pop(parse_state)
    let line = token.line
    let column = token.column

    var prefixed = false
    if token.tpe == lexer::TokenType::DOUBLE_COLON {
        prefixed = true
        token = pop(parse_state)
    }
    
    let path = vector::make(String)
    loop {
        path.push(token.value.str)
        token = peek(parse_state)
        if token.tpe == lexer::TokenType::DOUBLE_COLON {
            token = pop(parse_state)
            var ident = peek(parse_state)
            if ident.tpe == lexer::TokenType::IDENTIFIER {
                token = pop(parse_state)
                continue
            } else {
                back(parse_state)
            }
        }
        break
    }

    if path.length == 0 { return null }

    var args: &Vector(&Node) = null
    token = peek(parse_state)
    if token.tpe == lexer::TokenType::DOUBLE_COLON {
        pop(parse_state)
        // We have a function reference
        token = peek(parse_state)
        if token.tpe == lexer::TokenType::O_PAREN {
            args = vector::make(type &Node)
            
            pop(parse_state)
            token = peek(parse_state)
            while token.tpe != lexer::TokenType::C_PAREN and 
                token.tpe != lexer::TokenType::EOF {
                let expr = expect_type(parse_state)
                args.push(expr)
                token = peek(parse_state)
                if token.tpe == lexer::TokenType::COMMA {
                    pop(parse_state)
                    token = peek(parse_state)
                    continue
                }
                break
            }
            expect(parse_state, lexer::TokenType::C_PAREN, "Expected ')'")
        } else {
            path.push("")   // Push an empty last path element so that you can autocomplete based on the head
        }
    }

    var node = make_node(NodeKind::IDENTIFIER, line, column, parse_state)
    node.value.identifier.path = path
    node.value.identifier.args = args
    node.value.identifier.prefixed = prefixed

    var h: uint64 = hash(path)
    if args {
        for var i in 0..args.length {
            h = combine_hashes(h, hash(args(i)))
        }
    }
    node._hash = h

    return node
}

def parse_array_n(parse_state: &ParseState) -> &Node {
    var tok = peek(parse_state)
    let line = tok.line
    let column = tok.column

    if tok.tpe != lexer::TokenType::O_SQUARE {
        return null
    }
    pop(parse_state)
    tok = peek(parse_state)

    var n: &Node = null
    if tok.tpe == lexer::TokenType::QUESTION_MARK {
        pop(parse_state)
    } else {
        n = parse_expression(parse_state)
        if not n {
            return null
        }
    }

    tok = pop(parse_state)
    if tok.tpe != lexer::TokenType::SEMICOLON {
        return null
    }

    var kw = VarDecl::VAR
    tok = peek(parse_state)
    if tok.tpe == lexer::TokenType::K_VAR {
        pop(parse_state)
    } else if tok.tpe == lexer::TokenType::K_LET {
        pop(parse_state)
        kw = VarDecl::LET
    }
    let tpe = parse_type(parse_state)
    if not tpe {
        return null
    }

    tok = peek(parse_state)
    if tok.tpe != lexer::TokenType::C_SQUARE {
        return null
    }
    pop(parse_state)

    var node = make_node(NodeKind::ARRAY_STATIC_T, line, column, parse_state)
    node.value.t_arrs = [
        n = n,
        kw = kw,
        tpe = tpe
    ] !NodeArrayStaticT
    node._hash = combine_hashes(node.kind !uint64, kw !uint64, hash(n), hash(tpe))

    return node
}

def expect_array_or_tuple(parse_state: &ParseState) -> &Node {
    var tok = peek(parse_state)
    let line = tok.line
    let column = tok.column

    // [N; let T], [N; var T] and [N; T]
    var tokens = parse_state.tokens
    var node = parse_array_n(parse_state)
    if node {
        return node
    }
    parse_state.tokens = tokens

    tok = expect(parse_state, lexer::TokenType::O_SQUARE, "Expected '['")

    tok = peek(parse_state)
    if tok.tpe == lexer::TokenType::C_SQUARE {
        pop(parse_state)

        node = make_node(NodeKind::TUPLE_T, line, column, parse_state)
        node.value.t_variant = [
            variants = vector::make(type &Node)
        ] !NodeVariantT
        node._hash = node.kind !uint64

        return node
    }

    // [let T], [var T] and [T]

    var may_be_tuple = true

    var kw = VarDecl::VAR
    tok = peek(parse_state)
    if tok.tpe == lexer::TokenType::K_VAR {
        pop(parse_state)
        may_be_tuple = false
    } else if tok.tpe == lexer::TokenType::K_LET {
        pop(parse_state)
        kw = VarDecl::LET
        may_be_tuple = false
    }

    var tpe = expect_type(parse_state)

    if may_be_tuple {
        skip_newline(parse_state)
        tok = peek(parse_state)

        if tok.tpe == lexer::TokenType::COMMA {
            let variants = vector::make(type &Node)

            while tok.tpe == lexer::TokenType::COMMA {
                variants.push(tpe)
                pop(parse_state)

                tpe = expect_type(parse_state)
                skip_newline(parse_state)
                tok = peek(parse_state)
            }

            variants.push(tpe)

            tok = expect(parse_state, lexer::TokenType::C_SQUARE, "Expected ']'")
            
            node = make_node(NodeKind::TUPLE_T, line, column, parse_state)
            node.value.t_variant = [
                variants = variants
            ] !NodeVariantT
            node._hash = combine_hashes(node.kind !uint64, hash(variants))
            
            return node
        }
    }

    tok = expect(parse_state, lexer::TokenType::C_SQUARE, "Expected ']'")

    node = make_node(NodeKind::ARRAY_T, line, column, parse_state)
    node.value.t_parr = [
        kw = kw,
        tpe = tpe
    ] !NodePtrArrayT
    node._hash = combine_hashes(node.kind !uint64, kw !uint64, hash(tpe))
    
    return node
}

def expect_weak_ref(parse_state: &ParseState, inline_types: bool) -> &Node {
    var tok = expect(parse_state, lexer::TokenType::K_WEAK_REF, "Expected weak_ref")

    let line = tok.line
    let column = tok.column

    var tpe: &Node = null
    var kw = VarDecl::VAR
    tok = peek(parse_state)
    if tok.tpe == lexer::TokenType::O_PAREN {
        pop(parse_state)
        skip_newline(parse_state)
        tok = peek(parse_state)
        if tok.tpe == lexer::TokenType::K_VAR {
            pop(parse_state)
            skip_newline(parse_state)
        } else if tok.tpe == lexer::TokenType::K_LET {
            pop(parse_state)
            kw = VarDecl::LET
            skip_newline(parse_state)
        }

        var tokens = parse_state.tokens
        tpe = parse_type(parse_state, inline_types)
        if not tpe {
            parse_state.tokens = tokens
        }
        
        skip_newline(parse_state)
        expect(parse_state, lexer::TokenType::C_PAREN, "Expected ')'")
    }

    var node = make_node(NodeKind::WEAK_REF_T, line, column, parse_state)
    node.value.t_parr = [
        kw = kw,
        tpe = tpe
    ] !NodePtrArrayT
    node._hash = combine_hashes(node.kind !uint64, kw !uint64, hash(tpe))

    return node
}

def expect_ptr_ref(parse_state: &ParseState, ref: bool, inline_types: bool) -> &Node {
    var kind: NodeKind
    var tok: lexer::Token
    if ref {
        kind = NodeKind::REF_T
        tok = expect(parse_state, lexer::TokenType::OP_BAND, "Expected '&'")
    } else {
        kind = NodeKind::PTR_T
        tok = expect(parse_state, lexer::TokenType::OP_MUL, "Expected '*'")
    }
    let line = tok.line
    let column = tok.column

    var kw = VarDecl::VAR
    tok = peek(parse_state)
    if tok.tpe == lexer::TokenType::K_VAR {
        pop(parse_state)
    } else if tok.tpe == lexer::TokenType::K_LET {
        pop(parse_state)
        kw = VarDecl::LET
    }

    var tokens = parse_state.tokens
    var tpe = parse_type2(parse_state, inline_types)
    if not tpe {
        parse_state.tokens = tokens
    }

    var node = make_node(kind, line, column, parse_state)
    node.value.t_parr = [
        kw = kw,
        tpe = tpe
    ] !NodePtrArrayT
    node._hash = combine_hashes(node.kind !uint64, kw !uint64, hash(tpe))

    return node
}

def parse_id_decl_struct(parse_state: &ParseState) -> &Node {
    var token = peek(parse_state)
    let line = token.line
    let column = token.column
    
    var node: &Node = null
    if token.tpe == lexer::TokenType::K_STRUCT {
        node = expect_struct(parse_state)
    } else {
        var bit_size: uint64 = 0
        var is_bitfield = false
        if token.tpe == lexer::TokenType::PRAGMA {
            pop(parse_state)
            if token.value.str == "#bits" {
                is_bitfield = true
                expect(parse_state, lexer::TokenType::O_PAREN, "Expected '('")
                var n = expect(parse_state, lexer::TokenType::INTEGER, "Expected integer")
                if n.tpe != lexer::TokenType::INTEGER {
                    return null
                }
                bit_size = n.value.i
                expect(parse_state, lexer::TokenType::C_PAREN, "Expected ')'")
            } else {
                errors::errort(token, parse_state, "Invalid pragma")
            }
        }
        skip_newline(parse_state)
        token = peek(parse_state)

        var is_embed = false
        var is_const = false
        var ident: &Node = null
        var tpe: &Node = null
        var value: &Node = null

        if token.tpe == lexer::TokenType::COLON {
            pop(parse_state)
            skip_newline(parse_state)
            tpe = expect_type(parse_state)
        } else if token.tpe == lexer::TokenType::K_CONST {
            pop(parse_state)
            is_const = true
            ident = expect_identifier(parse_state)
            expect(parse_state, lexer::TokenType::COLON, "Expected ':'")
            tpe = expect_type(parse_state)
            expect(parse_state, lexer::TokenType::OP_ASSIGN, "Expected '='")
            value = expect_expression(parse_state)
        } else {
            if token.tpe == lexer::TokenType::OP_BAND {
                is_embed = true
                tpe = expect_type(parse_state)
            } else {
                ident = expect_identifier(parse_state)
                token = peek(parse_state)
                if token.tpe == lexer::TokenType::COLON {
                    pop(parse_state)
                    tpe = expect_type(parse_state)
                } else {
                    tpe = ident
                    ident = null
                    is_embed = true
                }
            }
        }

        if not ident and not is_bitfield and not is_embed {
            errors::errort(token, parse_state, "Expected identifier")
        }
        
        node = make_node(NodeKind::ID_DECL_STRUCT, line, column, parse_state)
        node.value.id_decl_struct = [
            ident = ident,
            tpe = tpe,
            is_bitfield = is_bitfield,
            is_embed = is_embed,
            bit_size = bit_size,
            is_const = is_const,
            value = value
        ] !NodeIdDeclStruct
        node._hash = combine_hashes(node.kind !uint64, is_bitfield !uint64, bit_size, is_embed !uint64, hash(ident), hash(tpe), hash(value))
    }
    
    parse_t_term(parse_state)
    return node
}

def expect_struct(parse_state: &ParseState) -> &Node {
    var token = peek(parse_state)
    let line = token.line
    let column = token.column

    var kind = NodeKind::STRUCT_T

    expect(parse_state, lexer::TokenType::K_STRUCT, "Expected struct")
    skip_newline(parse_state)
    token = peek(parse_state)
    if token.tpe == lexer::TokenType::PRAGMA {
        pop(parse_state)
        if token.value.str == "#union" {
            kind = NodeKind::UNION_T
        } else {
            errors::errort(token, parse_state, "Unexpected pragma, only #union allowed")
            return null
        }
    }
    expect(parse_state, lexer::TokenType::O_BRACE, "Expected '{'")
    skip_newline(parse_state)

    var body = vector::make(type &Node)

    token = peek(parse_state)
    while token.tpe != lexer::TokenType::C_BRACE and
        token.tpe != lexer::TokenType::EOF {
        body.push(parse_id_decl_struct(parse_state))
        skip_newline(parse_state)
        token = peek(parse_state)
    }

    expect(parse_state, lexer::TokenType::C_BRACE, "Expected '}'")

    var node = make_node(kind, line, column, parse_state)
    node.value.body = body
    node._hash = combine_hashes(node.kind !uint64, hash(body))
    return node
}

def parse_id_decl_enum(parse_state: &ParseState) -> &Node {
    var token = peek(parse_state)
    let line = token.line
    let column = token.column

    var ident = expect_identifier(parse_state)
    var value: &Node = null
    token = peek(parse_state)
    if token.tpe == lexer::TokenType::OP_ASSIGN {
        pop(parse_state)
        skip_newline(parse_state)
        value = expect_expression(parse_state)
    }

    var node = make_node(NodeKind::ID_DECL_ENUM, line, column, parse_state)
    node.value.id_decl_enum = [
        ident = ident,
        value = value
    ] !NodeIdDeclEnum
    node._hash = combine_hashes(node.kind !uint64, hash(ident), hash(value))
    
    parse_t_term(parse_state)
    return node
}

def expect_enum(parse_state: &ParseState) -> &Node {
    var token = peek(parse_state)
    let line = token.line
    let column = token.column

    expect(parse_state, lexer::TokenType::K_ENUM, "Expected enum")
    skip_newline(parse_state)

    token = peek(parse_state)
    var tpe: &Node = null
    if token.tpe == lexer::TokenType::COLON {
        pop(parse_state)
        skip_newline(parse_state)
        tpe = expect_type(parse_state)
    }

    expect(parse_state, lexer::TokenType::O_BRACE, "Expected '{'")
    skip_newline(parse_state)

    var body = vector::make(type &Node)

    token = peek(parse_state)
    while token.tpe != lexer::TokenType::C_BRACE and
        token.tpe != lexer::TokenType::EOF {
        body.push(parse_id_decl_enum(parse_state))
        skip_newline(parse_state)
        token = peek(parse_state)
    }

    expect(parse_state, lexer::TokenType::C_BRACE, "Expected '}'")

    var node = make_node(NodeKind::ENUM_T, line, column, parse_state)
    node.value.t_enum = [
        tpe = tpe,
        body = body
    ] !NodeEnumT
    node._hash = combine_hashes(node.kind !uint64, hash(tpe), hash(body))
    return node
}

def expect_type_of(parse_state: &ParseState) -> &Node {
    let tok = expect(parse_state, lexer::TokenType::K_TYPE_OF, "Expected type_of")
    skip_newline(parse_state)
    let expr = expect_expression(parse_state)
    var node = make_node(NodeKind::TYPE_OF_T, tok.line, tok.column, parse_state)
    node.value.expr = expr
    node._hash = combine_hashes(node.kind !uint64, hash(expr))
    return node
}

def expect_structural_type(parse_state: &ParseState) -> &Node {
    var tok = peek(parse_state)
    let line = tok.line
    let column = tok.column

    expect(parse_state, lexer::TokenType::K_INTERFACE, "Expected interface")
    skip_newline(parse_state)
    expect(parse_state, lexer::TokenType::O_BRACE, "Expected '{'")

    let defs = vector::make(type &Node)
    loop {
        skip_newline(parse_state)
        tok = peek(parse_state)
        if tok.tpe == lexer::TokenType::K_DEF {
            tok = pop(parse_state)
            let line = tok.line
            let column = tok.column
        	
            skip_newline(parse_state)
            var name: &Node = null 
            tok = peek(parse_state)
            var operator_token = tok
            if tok.tpe == lexer::TokenType::IDENTIFIER or
                tok.tpe == lexer::TokenType::DOUBLE_COLON {
                name = expect_identifier(parse_state)
                if peek(parse_state).tpe == lexer::TokenType::OP_ASSIGN {
                    operator_token = peek(parse_state)
                    pop(parse_state)
                }
            } else {
                tok = pop(parse_state)
            }

            skip_newline(parse_state)
            
            let params = vector::make(type &Node)
            let returns = vector::make(type &Node)

            tok = peek(parse_state)
            if tok.tpe == lexer::TokenType::O_PAREN {
                pop(parse_state)
                tok = peek(parse_state)
                if tok.tpe != lexer::TokenType::C_PAREN and tok.tpe != lexer::TokenType::EOF {
                    loop {
                        skip_newline(parse_state)
                        tok = peek(parse_state)
                        let line = tok.line
                        let column = tok.column

                        let name = expect_identifier(parse_state)
                        skip_newline(parse_state)
                        expect(parse_state, lexer::TokenType::COLON, "Expected ':'")
                        skip_newline(parse_state)
                        let tpe = expect_type(parse_state)

                        let param = make_node(NodeKind::PARAMETER, line, column, parse_state)
                        param.value.param = [
                            name = name,
                            tpe = tpe
                        ] !NodeParam
                        param._hash = combine_hashes(param.kind !uint64, hash(name), hash(tpe))

                        params.push(param)

                        tok = peek(parse_state)
                        if tok.tpe == lexer::TokenType::COMMA {
                            pop(parse_state)
                            continue
                        } else {
                            break
                        }
                    }
                }
                expect(parse_state, lexer::TokenType::C_PAREN, "Expected ')'")
                tok = peek(parse_state)
            }

            skip_newline(parse_state)
            tok = peek(parse_state)
            if tok.tpe == lexer::TokenType::ARROW {
                pop(parse_state)
                skip_newline(parse_state)
                loop {
                    let tpe = expect_type(parse_state)
                    returns.push(tpe)

                    tok = peek(parse_state)
                    if tok.tpe == lexer::TokenType::COMMA {
                        pop(parse_state)
                        skip_newline(parse_state)
                        continue
                    } else {
                        break
                    }
                }
            }

            
            let op_name = operator_token_to_name(params.length == 0, name, operator_token, parse_state) 
            if op_name {
                name = op_name
            } else if operator_token.tpe != lexer::TokenType::IDENTIFIER and 
                operator_token.tpe != lexer::TokenType::DOUBLE_COLON {
                errors::errort(tok, parse_state, "Expected identifier or operator")
            }

            let member = make_node(NodeKind::STRUCTURAL_T_MEMBER, line, column, parse_state)
            member.value.structural_member = [
                name = name,
                kw = MemberType::DEF,
                params = params,
                returns = returns
            ] !NodeStructuralMember
            member._hash = combine_hashes(member.kind !uint64, MemberType::DEF !uint64, hash(name), hash(params), hash(returns))

            defs.push(member)
        } else if tok.tpe == lexer::TokenType::K_VAR or tok.tpe == lexer::TokenType::K_LET {
            let member_type = MemberType::VAR if tok.tpe == lexer::TokenType::K_VAR else MemberType::LET
            skip_newline(parse_state)
            tok = pop(parse_state)
            let line = tok.line
            let column = tok.column
            let name = expect_identifier(parse_state)

            skip_newline(parse_state)
            expect(parse_state, lexer::TokenType::COLON, "Expected ':'")
            skip_newline(parse_state)
            let tpe = expect_type(parse_state)

            let returns = vector::make(type &Node)
            returns.push(tpe)
            
            let member = make_node(NodeKind::STRUCTURAL_T_MEMBER, line, column, parse_state)
            member.value.structural_member = [
                name = name,
                kw = member_type,
                returns = returns
            ] !NodeStructuralMember

            member._hash = combine_hashes(member.kind !uint64, member_type !uint64, hash(name), hash(returns))

            defs.push(member)
        } else if tok.tpe == lexer::TokenType::C_BRACE or tok.tpe == lexer::TokenType::EOF {
            tok = pop(parse_state)
            break
        } else {
            tok = pop(parse_state)
            errors::errort(tok, parse_state, "Expected def, var or let")
        }
    }
    if tok.tpe != lexer::TokenType::C_BRACE {
        errors::errort(tok, parse_state, "Expected '}'")
    }

    let node = make_node(NodeKind::STRUCTURAL_T, line, column, parse_state)
    node.value.body = defs
    node._hash = combine_hashes(node.kind !uint64, hash(defs))
    return node
}

def parse_type_identifier(parse_state: &ParseState, inline_types: bool) -> &Node {
    var token = peek(parse_state)
    let line = token.line
    let column = token.column
    var name = parse_identifier(parse_state)
    
    token = peek(parse_state)
    if token.tpe == lexer::TokenType::O_PAREN {
        pop(parse_state)
        token = peek(parse_state)
        if token.tpe == lexer::TokenType::C_PAREN {
            pop(parse_state)
            return name
        } else {
            let args = vector::make(type &Node)
            while token.tpe != lexer::TokenType::C_PAREN and 
                token.tpe != lexer::TokenType::EOF {
                let tpe = expect_type(parse_state, inline_types)
                args.push(tpe)

                token = peek(parse_state)
                if token.tpe == lexer::TokenType::COMMA {
                    skip_newline(parse_state)
                    pop(parse_state)
                    continue
                } else {
                    expect(parse_state, lexer::TokenType::C_PAREN, "Expected ')'")
                    break
                }
            }
            let node = make_node(NodeKind::TYPE_CONSTRUCTOR, line, column, parse_state)
            node.value.type_constructor = [
                name = name,
                args = args
            ] !NodeTypeConstructor
            node._hash = combine_hashes(node.kind !uint64, hash(name), hash(args))
            return node
        }
    }

    return name
}

def parse_variant_type(parse_state: &ParseState, inline_types: bool) -> &Node {
    var token = peek(parse_state)
    let start_token = token
    var node = parse_type2(parse_state, inline_types)
    
    var variant: &Node
    loop {
        if next_token(parse_state, lexer::TokenType::OP_BOR) {
            if not variant {
                variant = make_node(NodeKind::VARIANT_T, start_token.line, start_token.column, parse_state)
                variant.value.t_variant.variants = vector::make(type &Node)
                variant.value.t_variant.variants.push(node)
            }

            skip_newline(parse_state)
            node = parse_type2(parse_state, inline_types)
            variant.value.t_variant.variants.push(node)
        } else { break }
        token = peek(parse_state)
    }
    if variant {
        variant.loc.end_line = token.line
        variant.loc.end_column = token.column
        variant._hash = combine_hashes(NodeKind::VARIANT_T !uint64, hash(variant.value.t_variant.variants))
        return variant
    }
    return node
}

def parse_type2(parse_state: &ParseState, inline_types: bool) -> &Node {
    var tok = pop(parse_state)

    if tok.tpe == lexer::TokenType::K_INTERFACE {
        back(parse_state)
        return expect_structural_type(parse_state)
    } else if tok.tpe == lexer::TokenType::O_PAREN {
        var node = expect_type(parse_state, inline_types)
        expect(parse_state, lexer::TokenType::C_PAREN, "Expected ')'")
        return node
    } else if tok.tpe == lexer::TokenType::K_TYPE {
        let tpe_node = expect_type(parse_state, inline_types)
        if inline_types { return tpe_node }
        let node = make_node(NodeKind::TYPE_T, tok.line, tok.column, parse_state)
        node.value.expr = tpe_node
        node._hash = combine_hashes(node.kind !uint64, hash(tpe_node))
        return node
    } else if tok.tpe == lexer::TokenType::K_WORD {
        expect(parse_state, lexer::TokenType::O_PAREN, "Expected '('")
        var n = expect(parse_state, lexer::TokenType::INTEGER, "Expected integer")
        if n.tpe != lexer::TokenType::INTEGER {
            return null
        }
        expect(parse_state, lexer::TokenType::C_PAREN, "Expected ')'")
        var node = make_node(NodeKind::WORD_T, tok.line, tok.column, parse_state)
        node.value.i = n.value.i
        node._hash = combine_hashes(node.kind !uint64, n.value.i !uint64)

        return node
    } else if tok.tpe == lexer::TokenType::K_TYPE_OF {
        back(parse_state)
        return expect_type_of(parse_state)
    } else if tok.tpe == lexer::TokenType::K_UNSIGNED {
        let tpe_node = expect_type(parse_state)
        var node = make_node(NodeKind::UNSIGNED_T, tok.line, tok.column, parse_state)
        node.value.expr = tpe_node
        node._hash = combine_hashes(node.kind !uint64, hash(tpe_node))

        return node
    } else if tok.tpe == lexer::TokenType::O_SQUARE {
        back(parse_state)
        return expect_array_or_tuple(parse_state)
    } else if tok.tpe == lexer::TokenType::OP_MUL or
        tok.tpe == lexer::TokenType::OP_BAND {
        back(parse_state)
        return expect_ptr_ref(parse_state, tok.tpe == lexer::TokenType::OP_BAND, inline_types)
    } else if tok.tpe == lexer::TokenType::K_WEAK_REF {
        back(parse_state)
        return expect_weak_ref(parse_state, inline_types)
    } else if tok.tpe == lexer::TokenType::DOUBLE_COLON or
        tok.tpe == lexer::TokenType::IDENTIFIER {
        back(parse_state)
        return parse_type_identifier(parse_state, inline_types)
    } else if tok.tpe == lexer::TokenType::K_STRUCT {
        back(parse_state)
        return expect_struct(parse_state)
    } else if tok.tpe == lexer::TokenType::K_ENUM {
        back(parse_state)
        return expect_enum(parse_state)
    } else {
        back(parse_state)
        return null
    }
}

// TODO Allow things like (A, B) -> (C, D) -> (E, F)
export def parse_type(parse_state: &ParseState, inline_types: bool = true) -> &Node {
    var is_def = false
    var token = peek(parse_state)
    if token.tpe == lexer::TokenType::K_DEF {
        pop(parse_state)
        is_def = true
    }
    let left = parse_variant_type(parse_state, inline_types)
    token = peek(parse_state)
    if token.tpe == lexer::TokenType::ARROW {
        pop(parse_state)
        let right = parse_type(parse_state, inline_types)

        let args = left.value.t_variant.variants if left and left.kind == NodeKind::TUPLE_T else vector::make(type &Node)
        let ret = right.value.t_variant.variants if right and right.kind == NodeKind::TUPLE_T else vector::make(type &Node)

        if left and left.kind != NodeKind::TUPLE_T { args.push(left) }
        if right and right.kind != NodeKind::TUPLE_T { ret.push(right) }

        var node = make_node(NodeKind::FUNCTION_T if is_def else NodeKind::CLOSURE_T, token.line, token.column, parse_state)
        node.value.t_func = [
            args = args,
            ret = ret
        ] !NodeFunctionT
        node._hash = combine_hashes(node.kind !uint64, hash(args), hash(ret))
        
        return node
    }
    
    return left
}

// inline_types is a flag to wrap type expressions in Type
def expect_type(parse_state: &ParseState, inline_types: bool = true) -> &Node {
    let token = peek(parse_state)
    let node = parse_type(parse_state, inline_types)
    if not node {
        errors::errort(token, parse_state, "Expected type") 
    }
    return node
}

// TODO: Remove duplicated code, see expect_func_args
def expect_struct_lit(parse_state: &ParseState) -> &Node {
    var token = peek(parse_state)
    let line = token.line
    let column = token.column

    // First try to parse [N; T]
    var tokens = parse_state.tokens
    var node = parse_array_n(parse_state)
    if node { return node }
    parse_state.tokens = tokens
    
    expect(parse_state, lexer::TokenType::O_SQUARE, "Expecting '['")
    var body = vector::make(type &Node)
    skip_newline(parse_state)
    token = peek(parse_state)

    // [var N]
    if token.tpe == lexer::TokenType::K_VAR or token.tpe == lexer::TokenType::K_LET {
        parse_state.tokens = tokens
        return expect_array_or_tuple(parse_state)
    }

    var args = vector::make(type &Node)
    while token.tpe != lexer::TokenType::C_SQUARE and
        token.tpe != lexer::TokenType::EOF {
        
        skip_newline(parse_state)
        token = peek(parse_state)
        if token.tpe == lexer::TokenType::IDENTIFIER {
            var tokens = parse_state.tokens
            pop(parse_state)
            skip_newline(parse_state)
            if peek(parse_state).tpe == lexer::TokenType::OP_ASSIGN {
                parse_state.tokens = tokens
                break // Start list of named arguments
            }
            parse_state.tokens = tokens
        }

        args.push(expect_expression_no_assign(parse_state))

        skip_newline(parse_state)
        token = peek(parse_state)
        if token.tpe != lexer::TokenType::C_SQUARE {
            if token.tpe != lexer::TokenType::COMMA {
                errors::errort(token, parse_state, "Expected ','")
                return null
            } else {
                pop(parse_state)
                token = peek(parse_state)
            }
        }
    }

    var kwargs = vector::make(type &Node)
    while token.tpe != lexer::TokenType::C_SQUARE and
        token.tpe != lexer::TokenType::EOF {

        skip_newline(parse_state)
        token = peek(parse_state)
        let line = token.line
        let column = token.column

        let ident = expect_identifier(parse_state)
        skip_newline(parse_state)

        expect(parse_state, lexer::TokenType::OP_ASSIGN, "expected '='")
        skip_newline(parse_state)
        let expr = expect_expression_no_assign(parse_state)

        let named_arg = make_node(NodeKind::NAMED_ARG, line, column, parse_state)
        (@named_arg).value.named_arg = [
            name = ident,
            value = expr
        ] !NodeNamedArg
        named_arg._hash = combine_hashes(named_arg.kind !uint64, hash(ident), hash(expr))
        kwargs.push(named_arg)

        skip_newline(parse_state)
        token = peek(parse_state)
        if token.tpe != lexer::TokenType::C_SQUARE {
            if token.tpe != lexer::TokenType::COMMA {
                errors::errort(token, parse_state, "Expected ','")
                return null
            } else {
                pop(parse_state)
                token = peek(parse_state)
            }
        }
    }

    expect(parse_state, lexer::TokenType::C_SQUARE, "Expecting ']'")

    var call = make_node(NodeKind::STRUCT_LIT, line, column, parse_state)
    (@call).value.struct_lit = [
        args = args,
        kwargs = kwargs
    ] !NodeStructLit
    call._hash = combine_hashes(call.kind !uint64, hash(args), hash(kwargs))

    return call
}

def parse_term(parse_state: &ParseState) -> &Node {
    let token = pop(parse_state)
    var node = [] !&Node
    var last_string: String
    
    if token.tpe == lexer::TokenType::O_BRACE {
        back(parse_state)
        return expect_lambda(parse_state)
    } else if token.tpe == lexer::TokenType::O_PAREN {
        node = parse_expression(parse_state)
        let end_token = expect(parse_state, lexer::TokenType::C_PAREN, "Expecting ')'")
        if node {
            // Set start and end token to include the parens
            node.loc.line = token.line
            node.loc.column = token.column
            node.loc.end_line = end_token.end_line
            node.loc.end_column = end_token.end_column
        }
        return node
    } else if token.tpe == lexer::TokenType::K_TYPE {
        skip_newline(parse_state)
        return expect_type(parse_state)
    } else if token.tpe == lexer::TokenType::K_DEFINED {
        skip_newline(parse_state)
        node.kind = NodeKind::DEFINED
        node.value.expr = expect_identifier(parse_state)
    } else if token.tpe == lexer::TokenType::INTEGER {
        node.kind = NodeKind::INTEGER
        node.value.i = token.value.i
        node._hash = combine_hashes(node.kind !uint64, token.value.i !uint64)
    } else if token.tpe == lexer::TokenType::FLOAT {
        node.kind = NodeKind::FLOAT
        node.value.f = token.value.f
        node._hash = combine_hashes(node.kind !uint64, @((*token.value.f) !*uint64))
    } else if token.tpe == lexer::TokenType::IDENTIFIER or
        token.tpe == lexer::TokenType::DOUBLE_COLON {
        back(parse_state)
        return expect_identifier(parse_state)
    } else if token.tpe == lexer::TokenType::STRING {
        node.kind = NodeKind::STRING
        last_string = token.value.str
        node.value.str = token.value.str
        node._hash = combine_hashes(node.kind !uint64, hash(token.value.str))
    } else if token.tpe == lexer::TokenType::CHAR {
        node.kind = NodeKind::CHAR
        node.value.i = token.value.ch
        node._hash = combine_hashes(node.kind !uint64, token.value.ch !uint64)
    } else if token.tpe == lexer::TokenType::K_TRUE or
        token.tpe == lexer::TokenType::K_FALSE {
        
        var value = 0
        if token.tpe == lexer::TokenType::K_TRUE {
            value = 1
        }

        node.kind = NodeKind::BOOLEAN
        node.value.i = value
        node._hash = combine_hashes(node.kind !uint64, node.value.i !uint64)
    } else if token.tpe == lexer::TokenType::K_NULL {
        node.kind = NodeKind::NULL
        node._hash = node.kind !uint64
    } else if token.tpe == lexer::TokenType::K_UNDEF {
        node.kind = NodeKind::UNDEF
        node._hash = node.kind !uint64
    } else if token.tpe == lexer::TokenType::O_SQUARE {
        back(parse_state)
        return expect_struct_lit(parse_state)
    } else {
        // errors::errort(token, parse_state, "Expected literal or identifier")
        return null
    }

    if node.kind == NodeKind::STRING {
        parse_state.last_string = last_string
    }

    node.tpe = null
    node.scope = null
    node.loc = [
        filename = parse_state.filename,
        display_name = parse_state.display_name,
        module = parse_state.module,
        line = token.line,
        column = token.column,
        end_line = token.end_line,
        end_column = token.end_column
    ] !SourceLoc
    return node
}

def expect_func_args(parse_state: &ParseState, node: &Node) -> &Node {
    var token = peek(parse_state)
    let line = node.loc.line if node else token.line
    let column = node.loc.column if node else token.column

    var args = vector::make(type &Node)
    while token.tpe != lexer::TokenType::C_PAREN and
        token.tpe != lexer::TokenType::EOF {
        if token.tpe == lexer::TokenType::IDENTIFIER {
            token = pop(parse_state)
            if peek(parse_state).tpe == lexer::TokenType::OP_ASSIGN {
                back(parse_state)
                break // Start list of named arguments
            }
            back(parse_state)
        }

        args.push(expect_expression_no_assign(parse_state))

        token = peek(parse_state)
        if token.tpe != lexer::TokenType::C_PAREN {
            if token.tpe != lexer::TokenType::COMMA {
                errors::errort(token, parse_state, "Expected ','")
                return null
            } else {
                pop(parse_state)
                token = peek(parse_state)
                if token.tpe == lexer::TokenType::C_PAREN {
                    args.push(null)
                    break
                }
            }
        }
    }

    var kwargs = vector::make(type &Node)
    while token.tpe != lexer::TokenType::C_PAREN and
        token.tpe != lexer::TokenType::EOF {

        token = peek(parse_state)
        let line = token.line
        let column = token.column

        let ident = expect_identifier(parse_state)

        expect(parse_state, lexer::TokenType::OP_ASSIGN, "expected '='")
        let expr = expect_expression_no_assign(parse_state)

        let named_arg = make_node(NodeKind::NAMED_ARG, line, column, parse_state)
        (@named_arg).value.named_arg = [
            name = ident,
            value = expr
        ] !NodeNamedArg
        kwargs.push(named_arg)
        named_arg._hash = combine_hashes(named_arg.kind !uint64, hash(ident), hash(expr))

        token = peek(parse_state)
        if token.tpe != lexer::TokenType::C_PAREN {
            if token.tpe != lexer::TokenType::COMMA {
                errors::errort(token, parse_state, "Expected ','")
                return null
            } else {
                pop(parse_state)
                token = peek(parse_state)
                if token.tpe == lexer::TokenType::C_PAREN {
                    kwargs.push(null)
                    break
                }
            }
        }
    }
    if token.tpe == lexer::TokenType::C_PAREN {
        pop(parse_state)
    }

    var call = make_node(NodeKind::FUNC_CALL, line, column, parse_state)
    (@call).value.func_call = [
        left = node,
        args = args,
        kwargs = kwargs
    ] !NodeFuncCall
    call._hash = combine_hashes(call.kind !uint64, hash(node), hash(args), hash(kwargs))

    return call
}

def parse_post_expression(parse_state: &ParseState) -> &Node {
    var token = peek(parse_state)
    let start_token = token
    var node = parse_term(parse_state)
    loop {
        if next_token(parse_state, lexer::TokenType::O_PAREN) {
            node = expect_func_args(parse_state, node)
        /*} else if next_token(parse_state, lexer::TokenType::O_SQUARE) {
            skip_newline(parse_state)
            let expr = parse_expression(parse_state)
            skip_newline(parse_state)
            expect(parse_state, lexer::TokenType::C_SQUARE, "Expected ']'")
            node = make_bin_op(parse_state, token, NodeKind::ARRAY_SUBSCRIPT, node, expr)*/
        } else if next_token(parse_state, lexer::TokenType::DOT) {
            token = peek(parse_state)
            var right: &Node
            if token.tpe == lexer::TokenType::K_TYPE {
                right = make_operator_ident("type", token, parse_state)
                pop(parse_state)
            } else {
                right = expect_identifier(parse_state)
            }
            node = make_bin_op(parse_state, token, NodeKind::MEMBER_ACCESS, node, right)
        } else {
            return node
        }
        if node {
            node.loc.line = start_token.line
            node.loc.column = start_token.column
        }
        token = peek(parse_state)
    }
}

def parse_ident_as_func_call(parse_state: &ParseState, specifier: InlineSpecifier) -> &Node {
    let ident = expect_identifier(parse_state)
    let open_paren = peek(parse_state)
    if open_paren.tpe == lexer::TokenType::O_PAREN {
        pop(parse_state)
        let node = expect_func_args(parse_state, ident)
        node.value.func_call.inline = specifier
        return node
    } else {
        let line = ident.loc.line
        let column = ident.loc.column
        let call = make_node(NodeKind::FUNC_CALL, line, column, parse_state)
        call.value.func_call = [
            inline = specifier,
            left = ident,
            args = vector::make(type &Node),
            kwargs = vector::make(type &Node)
        ] !NodeFuncCall
        return call
    }
}

def parse_pre_expression(parse_state: &ParseState) -> &Node {
    var token = peek(parse_state)
    if token.tpe == lexer::TokenType::PRAGMA and (token.value.str == "#inline" or token.value.str == "#no_inline") {
        let specifier = InlineSpecifier::INLINE if token.value.str == "#inline" else InlineSpecifier::NO_INLINE
        pop(parse_state)
        return parse_ident_as_func_call(parse_state, specifier)
    } else if next_token(parse_state, lexer::TokenType::K_SIZE_OF) {
        skip_newline(parse_state)
        return make_un_op(parse_state, token, NodeKind::SIZE_OF, expect_type(parse_state))
    } else if next_token(parse_state, lexer::TokenType::K_ALIGN_OF) {
        skip_newline(parse_state)
        return make_un_op(parse_state, token, NodeKind::ALIGN_OF, expect_type(parse_state))
    } else if next_token(parse_state, lexer::TokenType::OP_ADD) {
        skip_newline(parse_state)
        return make_un_op(parse_state, token, NodeKind::UADD, parse_pre_expression(parse_state))
    } else if next_token(parse_state, lexer::TokenType::OP_SUB) {
        skip_newline(parse_state)
        return make_un_op(parse_state, token, NodeKind::USUB, parse_pre_expression(parse_state))
    } else if next_token(parse_state, lexer::TokenType::OP_BAND) {
        // For now you can only use these as prefix expression, therefore we don't need to stay ambiguous
        back(parse_state)
        return expect_ptr_ref(parse_state, true, false)
    } else if next_token(parse_state, lexer::TokenType::OP_MUL) {
        let next = peek(parse_state)
        if next.tpe == lexer::TokenType::K_VAR or next.tpe == lexer::TokenType::K_LET {
            // We definitely have a pointer in this case
            back(parse_state)
            return expect_ptr_ref(parse_state, false, false)
        }
        skip_newline(parse_state)
        return make_un_op(parse_state, token, NodeKind::PTR, parse_pre_expression(parse_state))
    } else if next_token(parse_state, lexer::TokenType::OP_DEREF) {
        skip_newline(parse_state)
        return make_un_op(parse_state, token, NodeKind::DEREF, parse_pre_expression(parse_state))
    } else if next_token(parse_state, lexer::TokenType::OP_BNOT) {
        skip_newline(parse_state)
        return make_un_op(parse_state, token, NodeKind::BNOT, parse_pre_expression(parse_state))
    } else if next_token(parse_state, lexer::TokenType::K_NOT) {
        skip_newline(parse_state)
        return make_un_op(parse_state, token, NodeKind::NOT, parse_pre_expression(parse_state))
    } else {
        return parse_post_expression(parse_state)
    }
}

def parse_cast_expression(parse_state: &ParseState) -> &Node {
    var token = peek(parse_state)
    let start_token = token  
    var node = parse_pre_expression(parse_state)
    loop {
        if next_token(parse_state, lexer::TokenType::OP_CAST) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::CAST, node, parse_type2(parse_state, false), check_arity = false)
        } else {
            return node
        }
        if node {
            node.loc.line = start_token.line
            node.loc.column = start_token.column
        }
        token = peek(parse_state)
    }
}

def parse_bin_expression(parse_state: &ParseState) -> &Node {
    var token = peek(parse_state)
    let start_token = token
    var node = parse_cast_expression(parse_state)
    loop {
        if next_token(parse_state, lexer::TokenType::OP_BAND) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::BAND, node, parse_cast_expression(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_BOR) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::BOR, node, parse_cast_expression(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_BXOR) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::BXOR, node, parse_cast_expression(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_SHL) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::SHL, node, parse_cast_expression(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_SHR) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::SHR, node, parse_cast_expression(parse_state))
        } else {
            return node
        }
        if node {
            node.loc.line = start_token.line
            node.loc.column = start_token.column
        }
        token = peek(parse_state)
    }
}

def parse_mul_expression(parse_state: &ParseState) -> &Node {
    var token = peek(parse_state)
    let start_token = token
    var node = parse_bin_expression(parse_state)
    loop {
        if next_token(parse_state, lexer::TokenType::OP_MUL) {
            skip_newline(parse_state)
            let right = parse_bin_expression(parse_state)
            let is_pointer = node != null and (node.kind == NodeKind::PTR or node.kind == NodeKind::MUL) and right == null
            node = make_bin_op(parse_state, token, NodeKind::MUL, node, right, check_arity = not is_pointer)
        } else if next_token(parse_state, lexer::TokenType::OP_DIV) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::DIV, node, parse_bin_expression(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_MOD) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::MOD, node, parse_bin_expression(parse_state))
        } else {
            return node
        }
        if node {
            node.loc.line = start_token.line
            node.loc.column = start_token.column
        }
        token = peek(parse_state)
    }
}

def parse_add_expression(parse_state: &ParseState) -> &Node {
    var token = peek(parse_state)
    let start_token = token
    var node = parse_mul_expression(parse_state)
    loop {
        if next_token(parse_state, lexer::TokenType::OP_ADD) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::ADD, node, parse_mul_expression(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_SUB) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::SUB, node, parse_mul_expression(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_INC) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::PADD, node, parse_mul_expression(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_DEC) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::PSUB, node, parse_mul_expression(parse_state))
        } else {
            return node
        }
        if node {
            node.loc.line = start_token.line
            node.loc.column = start_token.column
        }
        token = peek(parse_state)
    }
}

def parse_cmp_expression(parse_state: &ParseState) -> &Node {
    var token = peek(parse_state)
    let start_token = token
    var node = parse_add_expression(parse_state)
    loop {
        if next_token(parse_state, lexer::TokenType::OP_EQ) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::EQ, node, parse_add_expression(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_NEQ) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::NEQ, node, parse_add_expression(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_GEQ) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::GEQ, node, parse_add_expression(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_LEQ) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::LEQ, node, parse_add_expression(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_GT) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::GT, node, parse_add_expression(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_LT) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::LT, node, parse_add_expression(parse_state))
        } else {
            return node
        }
        if node {
            node.loc.line = start_token.line
            node.loc.column = start_token.column
        }
        token = peek(parse_state)
    }
}

def parse_and_expression(parse_state: &ParseState) -> &Node {
    var token = peek(parse_state)
    let start_token = token
    var node = parse_cmp_expression(parse_state)
    loop {
        if next_token(parse_state, lexer::TokenType::K_AND) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::AND, node, parse_cmp_expression(parse_state))
        } else {
            return node
        }
        if node {
            node.loc.line = start_token.line
            node.loc.column = start_token.column
        }
        token = peek(parse_state)
    }
}

def parse_or_expression(parse_state: &ParseState) -> &Node {
    var token = peek(parse_state)
    let start_token = token
    var node = parse_and_expression(parse_state)
    loop {
        if next_token(parse_state, lexer::TokenType::K_OR) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::OR, node, parse_and_expression(parse_state))
        } else {
            return node
        }
        if node {
            node.loc.line = start_token.line
            node.loc.column = start_token.column
        }
        token = peek(parse_state)
    }
}

def parse_range_expression(parse_state: &ParseState) -> &Node {
    var token = peek(parse_state)
    let start_token = token
    var node = parse_or_expression(parse_state)
    loop {
        if next_token(parse_state, lexer::TokenType::OP_RANGE) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::RANGE, node, parse_or_expression(parse_state))
        } else if next_token(parse_state, lexer::TokenType::OP_RANGE_INC) {
            skip_newline(parse_state)
            node = make_bin_op(parse_state, token, NodeKind::RANGE_INC, node, parse_or_expression(parse_state))
        } else {
            return node
        }
        if node {
            node.loc.line = start_token.line
            node.loc.column = start_token.column
        }
        token = peek(parse_state)
    }
}

def parse_assign_and_op(parse_state: &ParseState) -> &Node {
    var token = peek(parse_state)
    let start_token = token

    var node = parse_range_expression(parse_state)
    if next_token(parse_state, lexer::TokenType::OP_PADD_EQ) {
        skip_newline(parse_state)
        node = make_bin_op(parse_state, token, NodeKind::PADD_EQ, node, parse_assign_and_op(parse_state))
    } else if next_token(parse_state, lexer::TokenType::OP_PSUB_EQ) {
        skip_newline(parse_state)
        node = make_bin_op(parse_state, token, NodeKind::PSUB_EQ, node, parse_assign_and_op(parse_state))
    } else if next_token(parse_state, lexer::TokenType::OP_ADD_EQ) {
        skip_newline(parse_state)
        node = make_bin_op(parse_state, token, NodeKind::ADD_EQ, node, parse_assign_and_op(parse_state))
    } else if next_token(parse_state, lexer::TokenType::OP_SUB_EQ) {
        skip_newline(parse_state)
        node = make_bin_op(parse_state, token, NodeKind::SUB_EQ, node, parse_assign_and_op(parse_state))
    } else if next_token(parse_state, lexer::TokenType::OP_MUL_EQ) {
        skip_newline(parse_state)
        node = make_bin_op(parse_state, token, NodeKind::MUL_EQ, node, parse_assign_and_op(parse_state))
    } else if next_token(parse_state, lexer::TokenType::OP_DIV_EQ) {
        skip_newline(parse_state)
        node = make_bin_op(parse_state, token, NodeKind::DIV_EQ, node, parse_assign_and_op(parse_state))
    } else if next_token(parse_state, lexer::TokenType::OP_MOD_EQ) {
        skip_newline(parse_state)
        node = make_bin_op(parse_state, token, NodeKind::MOD_EQ, node, parse_assign_and_op(parse_state))
    } else if next_token(parse_state, lexer::TokenType::OP_AND_EQ) {
        skip_newline(parse_state)
        node = make_bin_op(parse_state, token, NodeKind::AND_EQ, node, parse_assign_and_op(parse_state))
    } else if next_token(parse_state, lexer::TokenType::OP_OR_EQ) {
        skip_newline(parse_state)
        node = make_bin_op(parse_state, token, NodeKind::OR_EQ, node, parse_assign_and_op(parse_state))
    } else if next_token(parse_state, lexer::TokenType::OP_XOR_EQ) {
        skip_newline(parse_state)
        node = make_bin_op(parse_state, token, NodeKind::XOR_EQ, node, parse_assign_and_op(parse_state))
    } else if next_token(parse_state, lexer::TokenType::OP_SHL_EQ) {
        skip_newline(parse_state)
        node = make_bin_op(parse_state, token, NodeKind::SHL_EQ, node, parse_assign_and_op(parse_state))
    } else if next_token(parse_state, lexer::TokenType::OP_SHR_EQ) {
        skip_newline(parse_state)
        node = make_bin_op(parse_state, token, NodeKind::SHR_EQ, node, parse_assign_and_op(parse_state))
    }
    if node {
        node.loc.line = start_token.line
        node.loc.column = start_token.column
    }
    return node
}

def parse_function_t(parse_state: &ParseState) -> &Node {
    var token = peek(parse_state)
    
    if token.tpe == lexer::TokenType::K_DEF or token.tpe == lexer::TokenType::ARROW {
        return parse_type(parse_state, false)
    }

    var tokens = parse_state.tokens
    let left = parse_assign_and_op(parse_state)

    token = peek(parse_state)
    if token.tpe == lexer::TokenType::ARROW {
        parse_state.tokens = tokens
        return parse_type(parse_state, false)
    }

    return left
}

def parse_type_of(parse_state: &ParseState) -> &Node {
    var token = peek(parse_state)

    if token.tpe == lexer::TokenType::K_TYPE_OF {
        return expect_type_of(parse_state)
    } else {
        return parse_function_t(parse_state)
    }
}

def parse_assign(parse_state: &ParseState) -> &Node {
    var token = peek(parse_state)
    let line = token.line
    let column = token.column

    var node = parse_type_of(parse_state)
    var left = vector::make(type &Node)
    var right = vector::make(type &Node)

    left.push(node)
    
    token = peek(parse_state)
    while token.tpe == lexer::TokenType::COMMA {
        pop(parse_state)
        skip_newline(parse_state)
        node = parse_type_of(parse_state)
        left.push(node)
        token = peek(parse_state)
    }

    if token.tpe != lexer::TokenType::OP_ASSIGN {
        if vector::length(left) == 1 {
            return left(0)
        }
    } else {
        pop(parse_state)
        
        node = parse_assign(parse_state)
        if node and node.kind == NodeKind::ASSIGN and vector::length(node.value.assign.right) == 0 {
            right = node.value.assign.left
        } else {
            right.push(node)
            token = peek(parse_state)
            while token.tpe == lexer::TokenType::COMMA {
                pop(parse_state)
                skip_newline(parse_state)
                node = parse_assign(parse_state)
                right.push(node)
                token = peek(parse_state)
            }
        }
    }
    
    var result = make_node(NodeKind::ASSIGN, line, column, parse_state)
    (@result).value.assign = [
        left = left,
        right = right
    ] !NodeAssign
    result._hash = combine_hashes(result.kind !uint64, hash(left), hash(right))

    return result
}

def parse_expression(parse_state: &ParseState) -> &Node {
    let node = parse_assign(parse_state)
    var token = peek(parse_state)
    if token.tpe == lexer::TokenType::K_IF {
        return expect_if_expr(parse_state, node)
    }
    return node
}

def expect_expression(parse_state: &ParseState) -> &Node {
    let node = parse_expression(parse_state)
    if not node {
        let token = peek(parse_state)
        errors::errort(token, parse_state, "Expected expression")
    }
    return node
}

def parse_expression_no_assign(parse_state: &ParseState) -> &Node {
    let node = parse_type_of(parse_state)
    var token = peek(parse_state)
    if token.tpe == lexer::TokenType::K_IF {
        return expect_if_expr(parse_state, node)
    }
    return node
}

def expect_expression_no_assign(parse_state: &ParseState) -> &Node {
    let node = parse_expression_no_assign(parse_state)
    if not node {
        let token = peek(parse_state)
        errors::errort(token, parse_state, "Expected expression")
    }
    return node
}

def make_operator_ident(name: String, token: Token, parse_state: &ParseState) -> &Node {
    let ident = make_node(NodeKind::IDENTIFIER, token.line, token.column, parse_state)
    let path = vector::make(String)
    path.push(name)
    ident.value.identifier.path = path
    ident._hash = combine_hashes(ident.kind !uint64, hash(path))
    return ident
}

def operator_token_to_name(is_prefix: bool, name: &Node, operator_token: Token, parse_state: &ParseState) -> &Node {
    if operator_token.tpe == lexer::TokenType::OP_ASSIGN {
        return make_operator_ident("__set_" + identifier_to_str(name) + "__", operator_token, parse_state)
    } else if operator_token.tpe == lexer::TokenType::OP_ADD {
        if is_prefix {
            return make_operator_ident("__pos__", operator_token, parse_state)
        } else {
            return make_operator_ident("__add__", operator_token, parse_state)
        }
    } else if operator_token.tpe == lexer::TokenType::OP_SUB {
        if is_prefix {
            return make_operator_ident("__neg__", operator_token, parse_state)
        } else {            
            return make_operator_ident("__sub__", operator_token, parse_state)
        }
    } else if operator_token.tpe == lexer::TokenType::OP_MUL {
        return make_operator_ident("__mul__", operator_token, parse_state)
    } else if operator_token.tpe == lexer::TokenType::OP_DIV {
        return make_operator_ident("__div__", operator_token, parse_state)
    } else if operator_token.tpe == lexer::TokenType::OP_MOD {
        return make_operator_ident("__mod__", operator_token, parse_state)
    } else if operator_token.tpe == lexer::TokenType::OP_SHR {
        return make_operator_ident("__rshift__", operator_token, parse_state)
    } else if operator_token.tpe == lexer::TokenType::OP_SHL {
        return make_operator_ident("__lshift__", operator_token, parse_state)
    } else if operator_token.tpe == lexer::TokenType::OP_BAND {
        return make_operator_ident("__and__", operator_token, parse_state)
    } else if operator_token.tpe == lexer::TokenType::OP_BOR {
        return make_operator_ident("__or__", operator_token, parse_state)
    } else if operator_token.tpe == lexer::TokenType::OP_BXOR {
        return make_operator_ident("__xor__", operator_token, parse_state)
    } else if operator_token.tpe == lexer::TokenType::OP_BNOT {
        return make_operator_ident("__invert__", operator_token, parse_state)
    } else if operator_token.tpe == lexer::TokenType::OP_LT {
        return make_operator_ident("__lt__", operator_token, parse_state)
    } else if operator_token.tpe == lexer::TokenType::OP_GT {
        return make_operator_ident("__gt__", operator_token, parse_state)
    } else if operator_token.tpe == lexer::TokenType::OP_LEQ {
        return make_operator_ident("__le__", operator_token, parse_state)
    } else if operator_token.tpe == lexer::TokenType::OP_GEQ {
        return make_operator_ident("__ge__", operator_token, parse_state)
    } else if operator_token.tpe == lexer::TokenType::OP_EQ {
        return make_operator_ident("__eq__", operator_token, parse_state)
    } else if operator_token.tpe == lexer::TokenType::OP_NEQ {
        return make_operator_ident("__ne__", operator_token, parse_state)
    } else if operator_token.tpe == lexer::TokenType::OP_SUB_EQ {
        return make_operator_ident("__isub__", operator_token, parse_state)
    } else if operator_token.tpe == lexer::TokenType::OP_ADD_EQ {
        return make_operator_ident("__iadd__", operator_token, parse_state)
    } else if operator_token.tpe == lexer::TokenType::OP_MUL_EQ {
        return make_operator_ident("__imul__", operator_token, parse_state)
    } else if operator_token.tpe == lexer::TokenType::OP_DIV_EQ {
        return make_operator_ident("__idiv__", operator_token, parse_state)
    } else if operator_token.tpe == lexer::TokenType::OP_MOD_EQ {
        return make_operator_ident("__imod__", operator_token, parse_state)
    } else if operator_token.tpe == lexer::TokenType::OP_SHR_EQ {
        return make_operator_ident("__irshift__", operator_token, parse_state)
    } else if operator_token.tpe == lexer::TokenType::OP_SHL_EQ {
        return make_operator_ident("__ilshift__", operator_token, parse_state)
    } else if operator_token.tpe == lexer::TokenType::OP_AND_EQ {
        return make_operator_ident("__iand__", operator_token, parse_state)
    } else if operator_token.tpe == lexer::TokenType::OP_OR_EQ {
        return make_operator_ident("__ior__", operator_token, parse_state)
    } else if operator_token.tpe == lexer::TokenType::OP_XOR_EQ {
        return make_operator_ident("__ixor__", operator_token, parse_state)
    }
    return null
}

def parse_def(parse_state: &ParseState, share: ShareMarker, impl: bool = false) -> &Node {
    var token = peek(parse_state)
    let line = token.line
    let column = token.column

    expect(parse_state, lexer::TokenType::K_DEF, "Expected def")
    skip_newline(parse_state)

    token = peek(parse_state)
    var extern = false
    var dllimport = false
    var dllexport = false
    var test = false
    var inline = false
    while token.tpe == lexer::TokenType::PRAGMA {
        pop(parse_state)
        if token.value.str == "#extern" {
            extern = true
        } else if token.value.str == "#dllimport" {
            dllimport = true
        } else if token.value.str == "#dllexport" {
            dllexport = true
        } else if token.value.str == "#test" {
            test = true
        } else if token.value.str == "#inline" {
            inline = true
        } else {
            errors::errort(token, parse_state, "Invalid pragma")
        }
        skip_newline(parse_state)
        token = peek(parse_state)
    }

    var name: &Node = null 
    token = peek(parse_state)
    var operator_token = token
    if token.tpe == lexer::TokenType::IDENTIFIER or
        token.tpe == lexer::TokenType::DOUBLE_COLON {
        name = expect_identifier(parse_state)
        if peek(parse_state).tpe == lexer::TokenType::OP_ASSIGN {
            operator_token = peek(parse_state)
            pop(parse_state)
        }
    } else {
        token = pop(parse_state)
    }

    //skip_newline(parse_state)
    var params = vector::make(type &Node)
    token = peek(parse_state)
    if token.tpe == lexer::TokenType::O_PAREN {
        pop(parse_state)
        skip_newline(parse_state)
        token = peek(parse_state)
        if token.tpe != lexer::TokenType::C_PAREN {
            var varargs = false
            var default = false

            loop {
                token = peek(parse_state)

                let line = token.line
                let column = token.column

                var kw = VarDecl::VAR
                var name: &Node = null
                var tpe: &Node = null
                var value: &Node = null

                if token.tpe == lexer::TokenType::OP_VARARGS {
                    if varargs {
                        errors::errort(token, parse_state, "Only the last parameter is allowed to be varargs")
                    }
                    varargs = true
                    pop(parse_state)
                } else {
                    if token.tpe == lexer::TokenType::K_LET {
                        kw = VarDecl::LET
                        pop(parse_state)
                    } else if token.tpe == lexer::TokenType::K_VAR {
                        kw = VarDecl::VAR
                        pop(parse_state)
                    } else if token.tpe == lexer::TokenType::K_TYPE {
                        kw = VarDecl::TYPE
                        pop(parse_state)
                    }

                    skip_newline(parse_state)
                    name = expect_identifier(parse_state)
                    skip_newline(parse_state)
                    
                    token = peek(parse_state)
                    if token.tpe == lexer::TokenType::COLON {
                        pop(parse_state)
                        tpe = expect_type(parse_state, false)
                        token = peek(parse_state)
                        if token.tpe == lexer::TokenType::OP_VARARGS {
                            if varargs {
                                errors::errort(token, parse_state, "Only the last parameter is allowed to be varargs")
                            }
                            varargs = true
                            pop(parse_state)
                        }
                    }
                    
                    skip_newline(parse_state)
                    token = peek(parse_state)
                    
                    if token.tpe == lexer::TokenType::OP_ASSIGN {
                        default = true
                        pop(parse_state)
                        if kw == VarDecl::TYPE {
                            value = expect_type(parse_state)
                        } else {
                            value = expect_expression_no_assign(parse_state)
                        }
                    } else {
                        if default {
                            errors::errort(token, parse_state, "Argument needs to have a default value")
                        }
                    }
                }

                let param = make_node(NodeKind::PARAMETER, line, column, parse_state)
                (@param).value.param = [
                    varargs = varargs,
                    kw = kw,
                    name = name,
                    tpe = tpe,
                    value = value
                ] !NodeParam
                param._hash = combine_hashes(param.kind !uint64, varargs !uint64, kw !uint64, hash(name), hash(tpe), hash(value))

                params.push(param)

                token = peek(parse_state)
                if token.tpe == lexer::TokenType::COMMA {
                    pop(parse_state)
                    continue
                } else {
                    expect(parse_state, lexer::TokenType::C_PAREN, "Expected ')'")
                    break
                }
            }
        } else {
            pop(parse_state)
        }     
    }

    var returns = vector::make(type &Node)
    token = peek(parse_state)
    if token.tpe == lexer::TokenType::ARROW {
        pop(parse_state)
        loop {
            let tpe = expect_type(parse_state)
            returns.push(tpe)

            token = peek(parse_state)
            if token.tpe == lexer::TokenType::COMMA {
                pop(parse_state)
                skip_newline(parse_state)
                continue
            } else {
                break
            }
        }
    }

    let has_yield = parse_state.has_yield

    var body: &Vector(&Node) = null
    var tokens = parse_state.tokens
    skip_newline(parse_state)
    token = peek(parse_state)
    if token.tpe != lexer::TokenType::O_BRACE {
        parse_state.tokens = tokens
    } else {
        pop(parse_state)
        body = vector::make(type &Node)
        parse_block(parse_state, body)
        expect(parse_state, lexer::TokenType::C_BRACE, "Expected '}'")
    }

    let op_name = operator_token_to_name(params.length == 1, name, operator_token, parse_state) 
    if op_name {
        name = op_name
    } else if operator_token.tpe != lexer::TokenType::IDENTIFIER and 
        operator_token.tpe != lexer::TokenType::DOUBLE_COLON {
        errors::errort(token, parse_state, "Expected identifier or operator")
    }
    
    let signature_hash = combine_hashes(
        impl !uint64, dllimport !uint64, dllexport !uint64, extern !uint64, 
        test !uint64, share !uint64, 
        hash(name), hash(params), hash(returns)
    )

    var node = make_node(NodeKind::DEF, line, column, parse_state)
    node.value.def_ = [
        impl = impl,
        has_yield = parse_state.has_yield,
        dllimport = dllimport,
        dllexport = dllexport or test,
        test = test,
        extern = extern,
        share = share,
        name = name,
        params = params,
        returns = returns,
        body = body,
        inline = inline
    ] !NodeDef
    if body and body.length > 0 and body(0).kind == NodeKind::STRING {
        node.value.def_.doc = body(0).value.str
    }

    node.body = body
    node._hash = combine_hashes(node.kind !uint64, signature_hash, hash(body))
    node.signature_hash = signature_hash

    parse_state.has_yield = has_yield
    return node
}

def parse_vardecl(parse_state: &ParseState, share: ShareMarker, vardecl: VarDecl) -> &Node {
    var last_string = parse_state.last_string

    var tok = pop(parse_state)
    let line = tok.line
    let column = tok.column

    if not (tok.tpe == lexer::TokenType::K_VAR or 
        tok.tpe == lexer::TokenType::K_CONST or 
        tok.tpe == lexer::TokenType::K_LET) {

        return null
    }
    skip_newline(parse_state)
    tok = peek(parse_state)

    var extern = false
    var dllimport = false
    var dllexport = false
    while tok.tpe == lexer::TokenType::PRAGMA {
        pop(parse_state)
        if tok.value.str == "#extern" {
            extern = true
        } else if tok.value.str == "#dllimport" {
            dllimport = true
        } else if tok.value.str == "#dllexport" {
            dllexport = true
        } else {
            errors::errort(tok, parse_state, "Invalid pragma")
        }
        skip_newline(parse_state)
        tok = peek(parse_state)
    }

    var vec_left = vector::make(type &Node)
    loop {
        tok = pop(parse_state)
        if tok.tpe == lexer::TokenType::O_PAREN {
            // Assignment
            let expr = expect_expression_no_assign(parse_state)
            expect(parse_state, lexer::TokenType::C_PAREN, "Expected ')'")
            var node = make_node(NodeKind::ID_ASSIGN, tok.line, tok.column, parse_state)
            node._hash = combine_hashes(node.kind !uint64, hash(expr))
            node.value.expr = expr
            vec_left.push(node)
        } else {
            // Id decl
            back(parse_state)
            let start_tok = peek(parse_state)
            var ident = expect_identifier(parse_state)

            tok = peek(parse_state)
            var tpe: &Node = null
            if tok.tpe == lexer::TokenType::COLON {
                // Type
                pop(parse_state)
                tpe = expect_type(parse_state)
            }
            var node = make_node(NodeKind::ID_DECL, start_tok.line, start_tok.column, parse_state)
            node.value.id_decl = [
                value = ident,
                tpe = tpe
            ] !NodeIdDecl
            node._hash = combine_hashes(node.kind !uint64, hash(ident), hash(tpe))
            vec_left.push(node)
        }
        tok = pop(parse_state)
        if tok.tpe == lexer::TokenType::COMMA {
            skip_newline(parse_state)
            continue
        } else if tok.tpe == lexer::TokenType::OP_ASSIGN or
            tok.tpe == lexer::TokenType::NEW_LINE or
            tok.tpe == lexer::TokenType::EOF {
            back(parse_state)
            break
        } else {
            errors::errort(tok, parse_state, "Expected identifier, (expression) or '='")
            return null
        }
    }

    var vec_right = vector::make(type &Node)
    if tok.tpe == lexer::TokenType::OP_ASSIGN {
        pop(parse_state)
        loop {
            var expr = expect_expression_no_assign(parse_state)
            vec_right.push(expr)
            
            tok = pop(parse_state)
            if tok.tpe == lexer::TokenType::COMMA {
                skip_newline(parse_state)
                continue
            } else if tok.tpe == lexer::TokenType::NEW_LINE or
                tok.tpe == lexer::TokenType::EOF or
                tok.tpe == lexer::TokenType::SEMICOLON {
                back(parse_state)
                break
            }
        }
        //if vector::length(vec_left) != vector::length(vec_right) {
        //    errors::errort(tok, parse_state, "Unbalanced assignment")
        //}
    } else if vardecl == VarDecl::LET or
        vardecl == VarDecl::CONST {
        errors::errort(tok, parse_state, "Expected '='")
        //return null
    }

    var node = make_node(NodeKind::VAR_DECL, line, column, parse_state)
    node.value.var_decl = [
        extern = extern,
        dllimport = dllimport,
        dllexport = dllexport,
        share = share,
        kw = vardecl,
        left = vec_left,
        right = vec_right
    ] !NodeVarDecl
    if last_string {
        node.value.var_decl.doc = last_string
    }

    let left_hash = hash(vec_left)
    node._hash = combine_hashes(
        node.kind !uint64, extern !uint64, dllimport !uint64, 
        share !uint64, vardecl !uint64, left_hash, hash(vec_right)
    )
    node.signature_hash = left_hash

    if parse_state.current_module {
        parse_state.current_module.inlay_hints.push(node)
    }

    return node
}

export def hash_type_decl(node: &Node) -> uint64 {
    let left_hash = hash(node.value.type_decl.left)
    node._hash = combine_hashes(node.kind !uint64, node.value.type_decl.share !uint64, left_hash, hash(node.value.type_decl.right))
    node.signature_hash = left_hash
}

def parse_typedecl(parse_state: &ParseState, share: ShareMarker) -> &Node {
    var last_string = parse_state.last_string
    var token = pop(parse_state)
    let line = token.line
    let column = token.column

    if token.tpe != lexer::TokenType::K_TYPE {
        return null
    }
    var vec_left = vector::make(type &Node)
    loop {
        let line = token.line
        let column = token.column
        var ident = expect_identifier(parse_state)
    
        token = pop(parse_state)
        if token.tpe == lexer::TokenType::O_PAREN {
            token = peek(parse_state)
            if token.tpe == lexer::TokenType::C_PAREN {
                token = pop(parse_state)
                vec_left.push(ident)
            } else {
                let args = vector::make(type &Node)
                while token.tpe != lexer::TokenType::C_PAREN and
                        token.tpe != lexer::TokenType::EOF {
                    
                    // TODO We want to take regular values too not just types
                    expect(parse_state, lexer::TokenType::K_TYPE, "Expected 'type'")
                    token = peek(parse_state)
                    let name = expect_identifier(parse_state)
                    let param = make_node(NodeKind::PARAMETER, token.line, token.column, parse_state)
                    param.value.param = [
                        name = name
                    ] !NodeParam
                    param._hash = combine_hashes(param.kind !uint64, hash(name))
                    args.push(param)
                    
                    token = peek(parse_state)
                    if token.tpe == lexer::TokenType::COMMA {
                        skip_newline(parse_state)
                        pop(parse_state)
                        continue
                    } else {
                        expect(parse_state, lexer::TokenType::C_PAREN, "Expected ')'")
                        token = pop(parse_state)
                        break
                    }
                }

                let typec = make_node(NodeKind::TYPE_CONSTRUCTOR, line, column, parse_state)
                typec.value.type_constructor = [
                    name = ident,
                    args = args
                ] !NodeTypeConstructor
                typec._hash = combine_hashes(typec.kind !uint64, hash(ident), hash(args))
                vec_left.push(typec)
            }
        } else {
            vec_left.push(ident)
        }

        if token.tpe == lexer::TokenType::COMMA {
            skip_newline(parse_state)
            continue
        } else if token.tpe == lexer::TokenType::OP_ASSIGN or
            token.tpe == lexer::TokenType::NEW_LINE or
            token.tpe == lexer::TokenType::EOF {
            back(parse_state)
            break
        }
    }

    var vec_right = vector::make(type &Node)
    if token.tpe == lexer::TokenType::OP_ASSIGN {
        pop(parse_state)
        loop {
            var tpe = expect_type(parse_state)
            vec_right.push(tpe)

            token = pop(parse_state)
            if token.tpe == lexer::TokenType::COMMA {
                skip_newline(parse_state)
                continue
            } else if token.tpe == lexer::TokenType::NEW_LINE or
                token.tpe == lexer::TokenType::EOF {
                back(parse_state)
                break
            }
        }
    }

    var node = make_node(NodeKind::TYPE_DECL, line, column, parse_state)
    node.value.type_decl = [
        share = share,
        left = vec_left,
        right = vec_right
    ] !NodeTypeDecl
    if last_string {
        node.value.type_decl.doc = last_string
    }
    hash_type_decl(node)

    return node
}

def expect_loop_stmt(parse_state: &ParseState) -> &Node {
    var token = peek(parse_state)
    let line = token.line
    let column = token.column

    expect(parse_state, lexer::TokenType::K_LOOP, "Expected loop")
    skip_newline(parse_state)
    expect(parse_state, lexer::TokenType::O_BRACE, "Expected '{'")
    var body = vector::make(type &Node)
    parse_block(parse_state, body)
    expect(parse_state, lexer::TokenType::C_BRACE, "Expected '}'")

    var node = make_node(NodeKind::LOOP, line, column, parse_state)
    node.value.body = body
    node.body = body
    node._hash = combine_hashes(node.kind !uint64, hash(body))

    return node
}

def expect_while_stmt(parse_state: &ParseState) -> &Node {
    var token = peek(parse_state)
    let line = token.line
    let column = token.column

    expect(parse_state, lexer::TokenType::K_WHILE, "Expected while")
    skip_newline(parse_state)
    let expr = expect_expression(parse_state)
    skip_newline(parse_state)
    expect(parse_state, lexer::TokenType::O_BRACE, "Expected '{'")
    var body = vector::make(type &Node)
    parse_block(parse_state, body)
    expect(parse_state, lexer::TokenType::C_BRACE, "Expected '}'")

    var node = make_node(NodeKind::WHILE, line, column, parse_state)
    node.value.while_loop = [
        expr = expr,
        body = body
    ] !NodeWhile
    node.body = body
    node._hash = combine_hashes(node.kind !uint64, hash(expr), hash(body))

    return node
}

def expect_for_stmt(parse_state: &ParseState) -> &Node {
    var token = peek(parse_state)
    let line = token.line
    let column = token.column

    expect(parse_state, lexer::TokenType::K_FOR, "Expected for")
    skip_newline(parse_state)

    var iddecl: &Node = null
    token = peek(parse_state)
    if token.tpe == lexer::TokenType::K_VAR or
        token.tpe == lexer::TokenType::K_LET {
        
        var kw = VarDecl::VAR
        if token.tpe == lexer::TokenType::K_LET {
            kw = VarDecl::LET
        }

        pop(parse_state)
        let ident = expect_identifier(parse_state)
        iddecl = make_node(NodeKind::FOR_ID_DECL, token.line, token.column, parse_state)
        // TODO Have an optional type here
        (@iddecl).value.for_id_decl = [
            kw = kw,
            ident = ident
        ] !NodeForIdDecl
        iddecl._hash = combine_hashes(iddecl.kind !uint64, kw !uint64, hash(ident))
    } else {
        iddecl = expect_identifier(parse_state)
    }

    skip_newline(parse_state)
    expect(parse_state, lexer::TokenType::K_IN, "Expected in")
    skip_newline(parse_state)
    var expr = expect_expression(parse_state)
    expect(parse_state, lexer::TokenType::O_BRACE, "Expected '{'")
    var body = vector::make(type &Node)
    parse_block(parse_state, body)
    expect(parse_state, lexer::TokenType::C_BRACE, "Expected '}'")

    var node = make_node(NodeKind::FOR, line, column, parse_state)
    node.value.for_loop = [
        iddecl = iddecl,
        expr = expr,
        body = body
    ] !NodeFor
    node.body = body
    node._hash = combine_hashes(node.kind !uint64, hash(iddecl), hash(expr), hash(body))

    return node
}

def expect_if_expr(parse_state: &ParseState, if_true: &Node) -> &Node {
    var token = peek(parse_state)
    let line = if_true.loc.line if if_true else token.line
    let column = if_true.loc.column if if_true else token.column

    expect(parse_state, lexer::TokenType::K_IF, "Expected if")
    let cond = expect_expression_no_assign(parse_state)
    skip_newline(parse_state)
    expect(parse_state, lexer::TokenType::K_ELSE, "Expected else")
    skip_newline(parse_state)
    let if_false = expect_expression_no_assign(parse_state)

    var node = make_node(NodeKind::IF_EXPR, line, column, parse_state)
    node.value.if_expr = [
        cond = cond,
        if_true = if_true,
        if_false = if_false
    ] !NodeIfExpr
    node._hash = combine_hashes(node.kind !uint64, hash(cond), hash(if_true), hash(if_false))

    return node
}

def expect_if_stmt(parse_state: &ParseState, static_if: bool) -> &Node {
    var token = peek(parse_state)
    let line = token.line
    let column = token.column

    if static_if {
        if not (token.tpe == lexer::TokenType::PRAGMA and token.value.str == "#if") {
            errors::errort(token, parse_state, "Expected #if")
            return null
        }
        pop(parse_state)
    } else {
        expect(parse_state, lexer::TokenType::K_IF, "Expected if")
    }
    
    skip_newline(parse_state)
    let cond = expect_expression(parse_state)
    skip_newline(parse_state)
    expect(parse_state, lexer::TokenType::O_BRACE, "Expected '{'")
    var body = vector::make(type &Node)
    parse_block(parse_state, body)
    expect(parse_state, lexer::TokenType::C_BRACE, "Expected '}'")
    
    var tokens = parse_state.tokens
    skip_newline(parse_state)

    var else_if = vector::make(type &Node)
    var else_node: &Node = null

    token = peek(parse_state)
    if token.tpe != lexer::TokenType::K_ELSE {
        parse_state.tokens = tokens
    }
    loop {
        if token.tpe == lexer::TokenType::K_ELSE {
            pop(parse_state)
            skip_newline(parse_state)
            token = peek(parse_state)
            if token.tpe == lexer::TokenType::K_IF {
                pop(parse_state)
                var cond = expect_expression(parse_state)
                
                skip_newline(parse_state)
                expect(parse_state, lexer::TokenType::O_BRACE, "Expected '{'")
                var body = vector::make(type &Node)
                parse_block(parse_state, body)
                expect(parse_state, lexer::TokenType::C_BRACE, "Expected '}'")

                tokens = parse_state.tokens
                skip_newline(parse_state)

                let elif_node = make_node(NodeKind::ELSE_IF, token.line, token.column, parse_state)
                (@elif_node).value.else_if = [
                    cond = cond,
                    body = body
                ] !NodeElseIf
                elif_node.body = body
                elif_node._hash = combine_hashes(elif_node.kind !uint64, hash(cond), hash(body))

                else_if.push(elif_node)

                token = peek(parse_state)
            
                if token.tpe != lexer::TokenType::K_ELSE {
                    parse_state.tokens = tokens
                }
            } else {
                skip_newline(parse_state)

                expect(parse_state, lexer::TokenType::O_BRACE, "Expected '{'")
                var body = vector::make(type &Node)
                parse_block(parse_state, body)
                expect(parse_state, lexer::TokenType::C_BRACE, "Expected '}'")

                else_node = make_node(NodeKind::ELSE, token.line, token.column, parse_state)
                (@else_node).value.body = body
                else_node.body = body
                else_node._hash = combine_hashes(else_node.kind !uint64, hash(body))
                    
                break
            }
        } else {
            break
        }
    }

    var node_kind = NodeKind::IF
    if static_if {
        node_kind = NodeKind::STATIC_IF
    }

    var node = make_node(node_kind, line, column, parse_state)
    node.value.if_ = [
        cond = cond,
        body = body,
        else_if = else_if,
        else_ = else_node
    ] !NodeIf
    node.body = body
    node._hash = combine_hashes(node.kind !uint64, hash(cond), hash(body), hash(else_if), hash(else_node))

    return node
}

def expect_switch_stmt(parse_state: &ParseState) -> &Node {
    var token = peek(parse_state)
    let line = token.line
    let column = token.column   

    expect(parse_state, lexer::TokenType::K_SWITCH, "Expected switch")
    skip_newline(parse_state)
    let expr = expect_expression(parse_state)
    skip_newline(parse_state)
    expect(parse_state, lexer::TokenType::O_BRACE, "Expected '{'")
    var body = vector::make(type &Node)
    loop {
        skip_newline(parse_state)
        token = pop(parse_state)
        if token.tpe == lexer::TokenType::C_BRACE or
            token.tpe == lexer::TokenType::EOF {
            break        
        } else if token.tpe == lexer::TokenType::K_CASE {
            let line = token.line
            let column = token.column

            var body2 = vector::make(type &Node)
            var expr2 = vector::make(type &Node)

            token = peek(parse_state)
            if token.tpe != lexer::TokenType::NEW_LINE {
                if token.tpe == lexer::TokenType::SEMICOLON {
                    pop(parse_state)
                } else {
                    loop {
                        expr2.push(expect_expression_no_assign(parse_state))
                        
                        token = peek(parse_state)
                        if token.tpe == lexer::TokenType::COMMA {
                            pop(parse_state)
                            skip_newline(parse_state)
                        } else if token.tpe == lexer::TokenType::SEMICOLON {
                            pop(parse_state)
                            break
                        } else {
                            break    
                        }
                    }
                }
            }
            
            skip_newline(parse_state)
            token = peek(parse_state)
            while token.tpe != lexer::TokenType::K_CASE and
                token.tpe != lexer::TokenType::C_BRACE and
                token.tpe != lexer::TokenType::EOF {
                parse_block_stmt(parse_state, body2)
                skip_newline(parse_state)
                token = peek(parse_state)
            }
            var node = make_node(NodeKind::CASE, line, column, parse_state)
            node.value.case_ = [
                expr = expr2,
                body = body2
            ] !NodeCase
            node.body = body
            node._hash = combine_hashes(node.kind !uint64, hash(expr2), hash(body2))

            body.push(node)
        } else {
            errors::errort(token, parse_state, "Expected case")
        }
    }
    if token.tpe != lexer::TokenType::C_BRACE {
        errors::errort(token, parse_state, "Expected '}'")
    }

    var node = make_node(NodeKind::SWITCH, line, column, parse_state)
    node.value.switch_ = [
        expr = expr,
        body = body
    ] !NodeSwitch
    node.body = body
    node._hash = combine_hashes(node.kind !uint64, hash(expr), hash(body))

    return node
}

def expect_import_stmt(parse_state: &ParseState) -> &Node {
    var token = peek(parse_state)
    let line = token.line
    let column = token.column

    var body = vector::make(type &Node)
    expect(parse_state, lexer::TokenType::K_IMPORT, "Expected import")
    skip_newline(parse_state)

    loop {
        let line = token.line
        let column = token.column

        let name = expect_identifier(parse_state)
        token = peek(parse_state)
        var alias: &Node = null
        if token.tpe == lexer::TokenType::K_AS {
            pop(parse_state)
            alias = expect_identifier(parse_state) 
        }

        var module = make_node(NodeKind::IMPORT_MODULE, line, column, parse_state)
        (@module).value.import_module = [
            name = name,
            alias = alias
        ] !NodeImportModule
        module._hash = combine_hashes(module.kind !uint64, hash(name), hash(alias))

        body.push(module)

        token = peek(parse_state)
        if token.tpe == lexer::TokenType::COMMA {
            pop(parse_state)
            skip_newline(parse_state)
            continue
        } else {
            break
        }
    }

    var node = make_node(NodeKind::IMPORT, line, column, parse_state)
    node.value.body = body
    node._hash = combine_hashes(node.kind !uint64, hash(body))

    return node
}

def expect_yield_from(parse_state: &ParseState) -> &Node {
    let token = peek(parse_state)
    expect(parse_state, lexer::TokenType::K_YIELD, "Expected yield from")
    expect(parse_state, lexer::TokenType::K_FROM, "Expected yield from")
    skip_newline(parse_state)
    parse_state.has_yield = true
    
    let call = expect_expression(parse_state)
    let node = make_node(NodeKind::YIELD_FROM, token.line, token.column, parse_state)
    node.value.expr = call
    node._hash = combine_hashes(node.kind !uint64, hash(call))
    return node
}

def expect_yield_or_return(is_yield: bool, parse_state: &ParseState) -> &Node{
    var token = peek(parse_state)
    let line = token.line
    let column = token.column
    
    if is_yield {
        expect(parse_state, lexer::TokenType::K_YIELD, "Expected yield")
        parse_state.has_yield = true
    } else {
        expect(parse_state, lexer::TokenType::K_RETURN, "Expected return")
    }

    var body = vector::make(type &Node)
    token = peek(parse_state)
    while token.tpe != lexer::TokenType::NEW_LINE and
        token.tpe != lexer::TokenType::EOF and
        token.tpe != lexer::TokenType::C_BRACE {

        body.push(expect_expression_no_assign(parse_state))
        token = peek(parse_state)
        if token.tpe == lexer::TokenType::COMMA {
            pop(parse_state)
            skip_newline(parse_state)
            continue
        } else {
            break
        }
    }

    var node = make_node(NodeKind::YIELD if is_yield else NodeKind::RETURN, line, column, parse_state)
    node.value.body = body
    node._hash = combine_hashes(node.kind !uint64, hash(body))
    
    return node
}

def expect_return_stmt(parse_state: &ParseState) -> &Node {
    return expect_yield_or_return(false, parse_state)
}
def expect_yield_stmt(parse_state: &ParseState) -> &Node {
    return expect_yield_or_return(true, parse_state)
}

def expect_lambda(parse_state: &ParseState) -> &Node {
    let start = peek(parse_state)
    expect(parse_state, lexer::TokenType::O_BRACE, "Expected {")
    var token = peek(parse_state)

    var tokens = parse_state.tokens
    var parsed_parameters = true
    var params = vector::make(type &Node)

    // Try to parse parameters
    loop {
        let name_tok = peek(parse_state)
        let name = parse_identifier(parse_state)
        if not name { parsed_parameters = false; break }
        var tpe: &Node

        let colon = peek(parse_state)
        if colon.tpe == lexer::TokenType::COLON {
            pop(parse_state)

            tpe = parse_variant_type(parse_state, false)
            if not tpe {
                errors::errort(peek(parse_state), parse_state, "Expected type")
                break
            }
        }

        let param = make_node(NodeKind::PARAMETER, name_tok.line, name_tok.column, parse_state)
        param.value.param = [
            name = name,
            tpe = tpe
        ] !NodeParam

        param._hash = combine_hashes(param.kind !uint64, hash(name), hash(tpe))
        params.push(param)

        token = peek(parse_state)
        if token.tpe == lexer::TokenType::COMMA or 
            token.tpe == lexer::TokenType::EOF { 
            
            pop(parse_state)
            continue
        }
        break
    }

    if parsed_parameters {
        token = peek(parse_state)
        if token.tpe != lexer::TokenType::ARROW {
            parsed_parameters = false
            params = vector::make(type &Node)
        } else {
            pop(parse_state)
        }
    }

    if not parsed_parameters {
        parse_state.tokens = tokens
    }

    let body = vector::make(type &Node)
    parse_block(parse_state, body)

    expect(parse_state, lexer::TokenType::C_BRACE, "Expected }")

    let lam = make_node(NodeKind::LAMBDA, start.line, start.column, parse_state)
    lam.value.lambda = [
        parameters = params,
        body = body
    ] !NodeLambda
    lam._hash = combine_hashes(lam.kind !uint64, hash(params), hash(body))

    return lam
}

def expect_from(parse_state: &ParseState) -> &Node {
    var token = expect(parse_state, lexer::TokenType::K_FROM, "Expected from")
    let line = token.line
    let column = token.column
    
    skip_newline(parse_state)
    let module = expect_identifier(parse_state)
    skip_newline(parse_state)

    expect(parse_state, lexer::TokenType::K_EXPORT, "Expected export")
    skip_newline(parse_state)

    let idents = vector::make(type &Node)
    loop {
        token = peek(parse_state)
        if token.tpe == lexer::TokenType::OP_MUL {
         idents.push(make_node(NodeKind::STAR, token.line, token.column, parse_state))
            pop(parse_state)
        } else if token.tpe == lexer::TokenType::IDENTIFIER or token.tpe == lexer::TokenType::DOUBLE_COLON {
            let ident = parse_identifier(parse_state)
            if not ident { break }
            idents.push(ident)
        } else {
            break
        }
        token = peek(parse_state)
        if token.tpe == lexer::TokenType::COMMA {
            token = pop(parse_state)
            skip_newline(parse_state)
            continue
        } else {
            break
        }
    }
    if idents.length == 0 {
        errors::errort(token, parse_state, "Need to define at least one identifier")
    }
    let node = make_node(NodeKind::FROM, line, column, parse_state)
    node.value.from_ = [
        module = module,
        idents = idents
    ] !NodeFrom
    return node
}

def parse_t_term(parse_state: &ParseState) {
    let token = peek(parse_state)
    if token.tpe == lexer::TokenType::SEMICOLON or token.tpe == lexer::TokenType::NEW_LINE {
        pop(parse_state)
    } else if token.tpe != lexer::TokenType::EOF and token.tpe != lexer::TokenType::C_BRACE {
        pop(parse_state)
        errors::errort(token, parse_state, "Missing statement separator")
    }
}

def parse_statement2(parse_state: &ParseState, share: ShareMarker) -> &Node {
    let lh = peek(parse_state)
    var node: &Node = null
    if lh.tpe == lexer::TokenType::K_VAR {
        node = parse_vardecl(parse_state, share, VarDecl::VAR)
    } else if lh.tpe == lexer::TokenType::K_LET {
        node = parse_vardecl(parse_state, share, VarDecl::LET)
    } else if lh.tpe == lexer::TokenType::K_CONST {
        node = parse_vardecl(parse_state, share, VarDecl::CONST)
    } else if lh.tpe == lexer::TokenType::K_TYPE {
        node = parse_typedecl(parse_state, share)
    } else if lh.tpe == lexer::TokenType::K_IMPLICIT {
        pop(parse_state)
        node = parse_def(parse_state, share, impl = true)
    } else if lh.tpe == lexer::TokenType::K_DEF {
        node = parse_def(parse_state, share)
    }
    return node
}

def expect_defer_stmt(parse_state: &ParseState) -> &Node {
    var token = peek(parse_state)
    let line = token.line
    let column = token.column

    expect(parse_state, lexer::TokenType::K_DEFER, "Expected defer")
    skip_newline(parse_state)
    token = peek(parse_state)
    let body = vector::make(type &Node)
    if token.tpe == lexer::TokenType::O_BRACE {
        // Multiline defer
        pop(parse_state)
        parse_block(parse_state, body)
        expect(parse_state, lexer::TokenType::C_BRACE, "Expected '}'")
    } else {
        // Single line defer
        let expr = expect_expression(parse_state)
        body.push(expr)
    }
    let node = make_node(NodeKind::DEFER, line, column, parse_state)
    node.value.body = body
    node.body = body
    node._hash = combine_hashes(node.kind !uint64, hash(body))
    return node
}

def expect_assert_stmt(parse_state: &ParseState) -> &Node {
    var token = peek(parse_state)
    let line = token.line
    let column = token.column

    expect(parse_state, lexer::TokenType::K_ASSERT, "Expected assert")

    var cond: &Node = null
    token = peek(parse_state)
    if token.tpe != lexer::TokenType::NEW_LINE and
        token.tpe != lexer::TokenType::EOF and
        token.tpe != lexer::TokenType::C_BRACE {

        cond = parse_expression_no_assign(parse_state)
    }
   
    var msg: &Node = null
    token = peek(parse_state)
    if token.tpe == lexer::TokenType::COMMA {
        pop(parse_state)
        skip_newline(parse_state)
        msg = expect_expression_no_assign(parse_state)
    }
    let node = make_node(NodeKind::ASSERT, line, column, parse_state)
    node.value.assert_ = [
        cond = cond,
        message = msg
    ] !NodeAssert
    node._hash = combine_hashes(node.kind !uint64, hash(cond), hash(msg))
    return node
}

export def parse_statement(parse_state: &ParseState) -> &Node {
    let lh = peek(parse_state)
    var node: &Node = null
    if lh.tpe == lexer::TokenType::K_IMPORT {
        let share = ShareMarker::IMPORT
        let tok = pop(parse_state)
        node = parse_statement2(parse_state, share)
        if not node {
            back(parse_state)
            node = expect_import_stmt(parse_state)
        }
    } else if lh.tpe == lexer::TokenType::K_EXPORT {
        var share = ShareMarker::EXPORT
        pop(parse_state)
        let lh = peek(parse_state)
        if lh.tpe == lexer::TokenType::K_IMPORT {
            share = ShareMarker::BOTH
            pop(parse_state)
        }
        node = parse_statement2(parse_state, share)
        if not node {
            errors::errort(peek(parse_state), parse_state, "Expected def, type, var, let, const")
            return null
        }
    } else if lh.tpe == lexer::TokenType::K_FROM {
        node = expect_from(parse_state)
    } else if lh.tpe == lexer::TokenType::K_IF {
        node = expect_if_stmt(parse_state, false)
    } else if lh.tpe == lexer::TokenType::PRAGMA and lh.value.str == "#if" {
        node = expect_if_stmt(parse_state, true)
    } else if lh.tpe == lexer::TokenType::K_SWITCH {
        node = expect_switch_stmt(parse_state)  
    } else if lh.tpe == lexer::TokenType::K_LOOP {
        node = expect_loop_stmt(parse_state)
    } else if lh.tpe == lexer::TokenType::K_FOR {
        node = expect_for_stmt(parse_state)
    } else if lh.tpe == lexer::TokenType::K_WHILE {
        node = expect_while_stmt(parse_state)
    } else if lh.tpe == lexer::TokenType::K_RETURN {
        node = expect_return_stmt(parse_state)
    } else if lh.tpe == lexer::TokenType::K_YIELD {
        if peek(parse_state, 1).tpe == lexer::TokenType::K_FROM {
            node = expect_yield_from(parse_state)
        } else {
            node = expect_yield_stmt(parse_state)
        }
    } else if lh.tpe == lexer::TokenType::K_DEFER {
        node = expect_defer_stmt(parse_state)
    } else if lh.tpe == lexer::TokenType::K_ASSERT {
        node = expect_assert_stmt(parse_state)
    } else if lh.tpe == lexer::TokenType::K_BREAK {
        pop(parse_state)
        node = make_node(NodeKind::BREAK, lh.line, lh.column, parse_state)
        node._hash = NodeKind::BREAK !uint64
    } else if lh.tpe == lexer::TokenType::K_CONTINUE {
        pop(parse_state)
        node = make_node(NodeKind::CONTINUE, lh.line, lh.column, parse_state)
        node._hash = NodeKind::CONTINUE !uint64
    } else if lh.tpe == lexer::TokenType::PRAGMA and lh.value.str == "#error" {
        pop(parse_state)
        node = make_un_op(parse_state, lh, NodeKind::ERROR, expect_expression(parse_state))
    } else {
        node = parse_statement2(parse_state, ShareMarker::NONE)
        if not node {
            node = parse_expression(parse_state)
        }
    }
    parse_t_term(parse_state)
    return node
}

def parse_block_stmt(parse_state: &ParseState, vec: &Vector(&Node)) {
    let node = parse_statement(parse_state)
    parse_state.has_error = false
    if not node {
        // We encountered an error, skip to the next newline
        var lh = peek(parse_state)
        while lh.tpe != lexer::TokenType::NEW_LINE and 
            lh.tpe != lexer::TokenType::EOF and
            lh.tpe != lexer::TokenType::C_BRACE {

            lh = pop(parse_state)
        }
    } else {
        vec.push(node)
    }
}

def parse_block(parse_state: &ParseState, vec: &Vector(&Node)) {
    skip_newline(parse_state)
    var token = peek(parse_state)
    while token.tpe != lexer::TokenType::EOF and
        token.tpe != lexer::TokenType::C_BRACE {
        parse_block_stmt(parse_state, vec)
        skip_newline(parse_state)
        token = peek(parse_state)
    }
}

export def make_state(
    filename: Str, display_name: String, module: String, 
    lines: &[Str], tokens: *lexer::TokenList) -> &ParseState {

    return [
        filename = filename,
        display_name = display_name,
        module = module,
        lines = lines,
        tokens = tokens
    ] !&ParseState
}

export def parse(list: *lexer::TokenList, lines: &[Str], filename: String, module: String, display_name: String = null) -> &Node {
    var parse_state = make_state(
        filename = filename,
        display_name = display_name,
        module = module,
        lines = lines,
        tokens = list
    )
    
    var vec = vector::make(type &Node)
    parse_block(parse_state, vec)
    var token = peek(parse_state)
    if token.tpe != lexer::TokenType::EOF {
        errors::errort(token, parse_state, "Unexpected closing '}'")
    }

    let program_node = make_node(NodeKind::PROGRAM, 0, 0, parse_state)
    program_node.loc.end_column += 1 // We need the extra column to autocomplete at the end of the file
    program_node.value.program = [
        body = vec
    ] !NodeProgram
    program_node.body = vec
    program_node._hash = combine_hashes(program_node.kind !uint64, hash(vec))
    
    return program_node
}