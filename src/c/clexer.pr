import map
import set
import util
import json

export type Location = struct {
    line: int
    column: int
    end_line: int
    end_column: int
    file: Str
}

export type TokenKind = enum {
    EMPTY; EOF; EOL; START

    K_AUTO; K_BREAK; K_CASE; K_CHAR; K_CONST; K_CONTINUE
    K_DEFAULT; K_DO; K_DOUBLE; K_ELSE; K_ENUM; K_EXTERN
    K_FLOAT; K_FOR; K_GOTO; K_IF; K_INLINE; K_INT; K_LONG
    K_REGISTER; K_RESTRICT; K_RETURN; K_SHORT; K_SIGNED
    K_SIZEOF; K_STATIC; K_STRUCT; K_SWITCH; K_TYPEDEF; K_UNION
    K_UNSIGNED; K_VOID; K_VOLATILE; K_WHILE; K_BOOL

    P_DEFINED; P_MACRO; P_MACRO_FUNLIKE; P_IF; P_ELSE; P_ELIF; P_ENDIF;
    P_IFDEF; P_IFNDEF; P_LINE; P_PRAGMA; P_UNDEF; P_INCLUDE

    STRINGIFY; CONCAT; INCLUDE_ANGLE; INCLUDE_QOUTE
    PP_OPERATOR // Stringify and concat get replaced with this one because they are not set to be expanded again
    PLACEMARKER // See C standard for this one

    OP_ASSIGN; OP_ADD; OP_SUB; OP_MUL; OP_DIV
    OP_MOD; OP_BOR; OP_BAND; OP_BXOR; OP_BNOT; OP_SHL
    OP_SHR; OP_INC; OP_DEC; OP_EQ; OP_NEQ; OP_LEQ; OP_GEQ
    OP_LT; OP_GT; OP_ADD_EQ; OP_SUB_EQ; OP_MUL_EQ; OP_DIV_EQ
    OP_MOD_EQ; OP_OR_EQ; OP_AND_EQ; OP_XOR_EQ; OP_SHL_EQ
    OP_SHR_EQ; OP_DOT; OP_VARARGS; OP_NOT; OP_AND; OP_OR
    OP_COLON; OP_ARROW

    O_BRACE; C_BRACE
    O_SQUARE; C_SQUARE
    O_PAREN; C_PAREN

    QUESTION_MARK; COMMA; SEMICOLON

    PP_NUMBER
    IDENTIFIER
    INTEGER
    CHARACTER
    FLOAT
    STRING
}

export let keywords = map::make(TokenKind)
keywords["auto"] = TokenKind::K_AUTO
keywords["break"] = TokenKind::K_BREAK
keywords["case"] = TokenKind::K_CASE
keywords["char"] = TokenKind::K_CHAR
keywords["const"] = TokenKind::K_CONST
keywords["continue"] = TokenKind::K_CONTINUE
keywords["default"] = TokenKind::K_DEFAULT
keywords["do"] = TokenKind::K_DO
keywords["double"] = TokenKind::K_DOUBLE
keywords["else"] = TokenKind::K_ELSE
keywords["enum"] = TokenKind::K_ENUM
keywords["extern"] = TokenKind::K_EXTERN
keywords["float"] = TokenKind::K_FLOAT
keywords["for"] = TokenKind::K_FOR
keywords["goto"] = TokenKind::K_GOTO
keywords["if"] = TokenKind::K_IF
keywords["inline"] = TokenKind::K_INLINE
keywords["int"] = TokenKind::K_INT
keywords["long"] = TokenKind::K_LONG
keywords["register"] = TokenKind::K_REGISTER
keywords["restrict"] = TokenKind::K_RESTRICT
keywords["return"] = TokenKind::K_RETURN
keywords["short"] = TokenKind::K_SHORT
keywords["signed"] = TokenKind::K_SIGNED
keywords["sizeof"] = TokenKind::K_SIZEOF
keywords["static"] = TokenKind::K_STATIC
keywords["struct"] = TokenKind::K_STRUCT
keywords["switch"] = TokenKind::K_SWITCH
keywords["typedef"] = TokenKind::K_TYPEDEF
keywords["union"] = TokenKind::K_UNION
keywords["unsigned"] = TokenKind::K_UNSIGNED
keywords["void"] = TokenKind::K_VOID
keywords["volatile"] = TokenKind::K_VOLATILE
keywords["while"] = TokenKind::K_WHILE
keywords["_Bool"] = TokenKind::K_BOOL

let prep_directives = map::make(TokenKind)
prep_directives["define"] = TokenKind::P_MACRO
prep_directives["if"] = TokenKind::P_IF
prep_directives["else"] = TokenKind::P_ELSE
prep_directives["elif"] = TokenKind::P_ELIF
prep_directives["endif"] = TokenKind::P_ENDIF
prep_directives["ifdef"] = TokenKind::P_IFDEF
prep_directives["ifndef"] = TokenKind::P_IFNDEF
prep_directives["undef"] = TokenKind::P_UNDEF
prep_directives["include"] = TokenKind::P_INCLUDE

export type PPToken = struct {
    kind: TokenKind
    loc: Location
    value: Str
}

export type PPTokenList = struct {
    token: PPToken
    next: *PPTokenList
}

export def destruct(list: *PPTokenList) {
    list = list.next
    while list {
        let next = list.next
        __destruct__(*list.token)
        free(list)
        list = next
    }
}

export def delete_single(list: *PPTokenList) {
    __destruct__(*list.token)
    free(list)
}

type State = struct {
    i: int
    line: int
    column: int
    input: Str
    file: Str
}

const EOF: char = 0x1A !char

def peek(state: *State, ahead: int = 0) -> char {
    def _peek(ahead: int) -> char {
        if state.i + ahead >= state.input.length() {
            return EOF
        }
        return state.input[state.i + ahead]
    }

    var n = 0
    loop {
        var ch = _peek(n)
        var ch2 = ch
        while ch2 == '\\' {
            ch2 = _peek(1 + n)
            if ch2 == '\r' {
                ch2 = _peek(2 + n)
                if ch2 == '\n' {
                    state.line += 1
                    state.column = 0
                    ch2 = ch = _peek(3 + n)
                    state.i += 3
                }
            } else if ch2 == '\n' {
                state.line += 1
                state.column = 0
                ch2 = ch = _peek(2 + n)
                state.i += 2
            }
        }
        if n == ahead { return ch }
        n += 1
    }
}

def pop(state: *State) -> char {
    let ch = peek(state, 1)
    if ch == '\n' {
        state.line += 1
        state.column = 0
    } else if ch != EOF {
        state.column += 1
    }
    state.i += 1
    return ch
}

def is_text(a: char) -> bool {
    return a == '_' or a >= 'a' and a <= 'z' or a >= 'A' and a <= 'Z'
}

def is_alphanumeric(a: char) -> bool {
    return is_text(a) or a >= '0' and a <= '9'
}

def is_hex_digit(a: char) -> bool {
    return get_hex_digit(a) >= 0
}

def get_hex_digit(a: char) -> int {
    if a >= '0' and a <= '9' { return a - '0' }
    if a >= 'a' and a <= 'f' { return a - 'a' }
    if a >= 'A' and a <= 'F' { return a - 'A' }
    return -1
}

def lex_identifier(state: *State) -> PPToken {
    let start = state.i
    var end = state.i
    var next = peek(state)
    
    var buf: StringBuffer = ""
    while next != EOF and is_alphanumeric(next) {
        buf += next

        pop(state)
        end += 1
        next = peek(state)
    }
    //if keywords.contains(res) {
    //    let token = { kind = keywords[res] } !PPToken
    //    token.value = res
    //}
    let token = { kind = TokenKind::IDENTIFIER } !PPToken
    token.value = buf
    return token
}


def lex_pp_number(state: *State) -> PPToken {
    var c = peek(state)
    var buf: StringBuffer = ""
    while c != EOF {
        if c == 'e' or c == 'E' or c == 'p' or c == 'P' {
            buf += c
            c = pop(state)
            if c == '+' or c == '-' {
                buf += c
                c = pop(state)
                continue
            }
        }
        if c != '.' and not is_alphanumeric(c) {
            break
        }

        buf += c
        c = pop(state)
    }
    
    let tok = { kind = TokenKind::PP_NUMBER } !PPToken
    tok.value = buf

    return tok
}

def lex_escape_sequence(state: *State) -> Str {
    var str: StringBuffer = ""
    var ch = pop(state)
    switch ch {
        case 'a': str += '\a';   pop(state)
        case 'b': str += '\b';   pop(state)
        case 'e': str += '\x1B'; pop(state)
        case 'f': str += '\f';   pop(state)
        case 'n': str += '\n';   pop(state)
        case 'r': str += '\r';   pop(state)
        case 't': str += '\t';   pop(state)
        case 'v': str += '\v';   pop(state)
        case '\\': str += '\\';  pop(state)
        case '\'': str += '\'';  pop(state)
        case '"': str += '"';    pop(state)
        case '?': str += '?';    pop(state)
        case '0'..'8':
            var i = 0
            var res: char = 0
            while ch != EOF and ch >= '0' and ch <= '8' and i < 3 {
                res *= 8
                res += ch - '0'
                ch = pop(state)
                i += 1
            }
            str += res
        case 'x', 'u', 'U':
            ch = pop(state)
            var i = 0
            let n = MAX_INT32 if ch == 'x' else 4 if ch == 'u' else 8
            var res: char = 0
            while ch != EOF and is_hex_digit(ch) and i < n {
                res *= 16
                res += get_hex_digit(ch)
                ch = pop(state)
                i += 1
            }
            str += res
    }
    return str
}

def lex_string(state: *State) -> PPToken {
    pop(state)
    var ch = peek(state)
    var str: StringBuffer = ""
    while ch != EOF and ch != '"' and ch != '\n' {
        if ch == '\\' {
            str += lex_escape_sequence(state)
            ch = peek(state)
        } else {
            str += ch
            ch = pop(state)
        }
    }
    pop(state)

    let tok = { kind = TokenKind::STRING } !PPToken
    tok.value = str
    return tok
}

def lex_char(state: *State) -> PPToken {
    pop(state)
    var ch = peek(state)
    if ch == '\\' {
        let str = lex_escape_sequence(state)
        if str {
            ch = str[0]
        }
    }
    pop(state)
    pop(state)

    let tok = { kind = TokenKind::CHARACTER } !PPToken
    tok.value = to_string(ch)
    return tok
}

def lex_symbol(state: *State) -> PPToken {
    let first = peek(state, 0)
    let second = peek(state, 1)
    let third = peek(state, 2)

    var tt: TokenKind = TokenKind::EMPTY
    var length = 3

    if first == '<' and second == '<' and third == '=' {
        tt = TokenKind::OP_SHL_EQ
    } else if first == '>' and second == '>' and third == '=' {
        tt = TokenKind::OP_SHR_EQ
    } else if first == '.' and second == '.' and third == '.' {
        tt = TokenKind::OP_VARARGS
    } else {
        length = 2
        if second == '=' {
            switch first {
                case '+': tt = TokenKind::OP_ADD_EQ
                case '-': tt = TokenKind::OP_SUB_EQ
                case '*': tt = TokenKind::OP_MUL_EQ
                case '/': tt = TokenKind::OP_DIV_EQ
                case '%': tt = TokenKind::OP_MOD_EQ
                case '&': tt = TokenKind::OP_AND_EQ
                case '|': tt = TokenKind::OP_OR_EQ
                case '^': tt = TokenKind::OP_XOR_EQ
                case '!': tt = TokenKind::OP_NEQ
                case '>': tt = TokenKind::OP_GEQ
                case '<': tt = TokenKind::OP_LEQ
                case '=': tt = TokenKind::OP_EQ
            }
        } else if first == '-' and second == '>' {
            tt = TokenKind::OP_ARROW
        } else if first == '+' and second == '+' {
            tt = TokenKind::OP_INC
        } else if first == '-' and second == '-' {
            tt = TokenKind::OP_DEC
        } else if first == '<' and second == '<' {
            tt = TokenKind::OP_SHL
        } else if first == '>' and second == '>' {
            tt = TokenKind::OP_SHR
        } else if first == '&' and second == '&' {
            tt = TokenKind::OP_AND
        } else if first == '|' and second == '|' {
            tt = TokenKind::OP_OR
        } else {
            length = 1
            switch first {
                case '>': tt = TokenKind::OP_GT
                case '<': tt = TokenKind::OP_LT
                case '{': tt = TokenKind::O_BRACE
                case '}': tt = TokenKind::C_BRACE
                case '[': tt = TokenKind::O_SQUARE
                case ']': tt = TokenKind::C_SQUARE
                case '(': tt = TokenKind::O_PAREN
                case ')': tt = TokenKind::C_PAREN
                case '+': tt = TokenKind::OP_ADD
                case '-': tt = TokenKind::OP_SUB
                case '*': tt = TokenKind::OP_MUL
                case '/': tt = TokenKind::OP_DIV
                case '%': tt = TokenKind::OP_MOD
                case '&': tt = TokenKind::OP_BAND
                case '|': tt = TokenKind::OP_BOR
                case '^': tt = TokenKind::OP_BXOR
                case '~': tt = TokenKind::OP_BNOT
                case '!': tt = TokenKind::OP_NOT
                case '=': tt = TokenKind::OP_ASSIGN                    
                case ',': tt = TokenKind::COMMA  
                case ':': tt = TokenKind::OP_COLON
                case '?': tt = TokenKind::QUESTION_MARK
                case '.': tt = TokenKind::OP_DOT
                case ';': tt = TokenKind::SEMICOLON
            }
        }
    }

    var ch = peek(state)
    var buf: StringBuffer = ""
    for var j in 0..length {
        buf += ch
        ch = pop(state)
    }

    return { kind = tt, value = buf } !PPToken
}

export def lex_next_token(s: String) -> PPToken {
    let state = {
        input = s
    } !State

    return lex_next_token(*state)
}

def lex_next_token(state: *State) -> PPToken {
    var start_line = state.line
    var start_col = state.column

    var token: PPToken
    loop {
        var ch = peek(state)
        switch ch {
            case EOF: 
                pop(state)
            case '\n':
                start_col = 0
                start_line += 1
                pop(state)
                continue
            case '\r', ' ', '\t':
                start_col += 1
                pop(state)
                continue
            case '0'..='9': token = lex_pp_number(state)
            case 'a'..='z', 'A'..'Z', '_': token = lex_identifier(state)
            case '"': token = lex_string(state)
            case '\'': token = lex_char(state)
            case '/':
                let second = peek(state, 1)
                if second == '*' {
                    pop(state)
                    pop(state)
                    while ch != '*' and peek(state, 1) != '/' and ch != EOF {
                        ch = pop(state)
                    }
                    pop(state)
                } else if second == '/' {
                    pop(state)
                    pop(state)
                    while ch != '\n' and ch != EOF {
                        ch = pop(state)
                    }
                } else {
                    token = lex_symbol(state)
                }
            case '#': break
            case: token = lex_symbol(state)
        }
        break
    }

    token.loc = {
        line = start_line,
        column = start_col,
        end_line = state.line,
        end_column = state.column,
        file = state.file
    } !Location

    return token
}

export def lex_include(s: String) -> PPToken {
    let state = {
        input = s
    } !State
    return lex_include(*state)
}

def lex_include(state: *State) -> PPToken {
    var ch = peek(state)
    while ch != TokenKind::EOF and ch == ' ' or ch == '\t' or ch == '\n' {
        ch = pop(state)
    }
    
    var buf: StringBuffer = ""
    var kind = TokenKind::EMPTY

    if ch == '"' { kind = TokenKind::INCLUDE_QOUTE }
    else if ch == '<' { kind = TokenKind::INCLUDE_ANGLE }
    if ch == '<' {
        ch = pop(state)
        while ch != '>' {
            buf += ch
            ch = pop(state) 
        }
    } else if ch == '"' {
        ch = pop(state)
        while ch != '"' { 
            buf += ch
            ch = pop(state) 
        }
    }

    if kind != TokenKind::EMPTY {
        ch = pop(state)
        let token = { kind = kind } !PPToken
        token.value = buf

        return token
    }
    return {} !PPToken
}

def lex_directive(state: *State) -> PPToken {
    var name: PPToken
    while state.i < state.input.length() {
        name = lex_next_token(state)
        if name.kind == TokenKind::IDENTIFIER or name.kind == TokenKind::EOF {
            break
        }
    }
    
    var directive: TokenKind
    if prep_directives.contains(name.value) {
        directive = prep_directives[name.value]
    }

    if directive != TokenKind::P_MACRO {
        yield { kind = directive, loc = name.loc } !PPToken
    }

    if directive == TokenKind::P_INCLUDE {
        let include_tok = lex_include(state)
        if include_tok.kind != TokenKind::EMPTY {
            yield include_tok
        }
    }

    var first_token = true
    while state.i < state.input.length() {
        let start_line = state.line
        let start_col = state.column

        var token: PPToken
        var ch = peek(state)
        switch ch {
            case ' ', '\t':
                pop(state)
                continue
            case '\n': 
                token = { kind = TokenKind::EOL } !PPToken
                pop(state)
            case '#':
                pop(state)
                token = { kind = TokenKind::STRINGIFY, value = "#" } !PPToken
                if peek(state) == '#' {
                    pop(state)
                    token = { kind = TokenKind::CONCAT, value = "##" } !PPToken
                }
            case: 
                let next = lex_next_token(state)
                if next.kind == TokenKind::IDENTIFIER and directive == TokenKind::P_MACRO and first_token {
                    if peek(state) == '(' {
                        yield { kind = TokenKind::P_MACRO_FUNLIKE, loc = name.loc } !PPToken
                    } else {
                        yield { kind = directive, loc = name.loc } !PPToken
                    }
                    first_token = false
                }
                yield next
                continue
                
        }

        first_token = false

        token.loc = {
            line = start_line,
            column = start_col,
            end_line = state.line,
            end_column = state.column,
            file = state.file
        } !Location
        yield token

        if token.kind == TokenKind::EOL {
            return
        }
    }
}

export def lex(path: Str) -> *PPTokenList {
    let fp = open(path, "r")
    let input = read_all(fp)
    close(fp)

    return lex(input, path)
}

export def lex(input: Str, path: Str) -> *PPTokenList {
    let state = {
        input = input,
        file = path
    } !State
    
    var first = zero_allocate(PPTokenList)
    var res = first
    res.token.kind = TokenKind::START
    res.next = zero_allocate(PPTokenList)
    res = res.next
    for var token in lex(*state) {
        if token.kind == TokenKind::EMPTY {
            continue
        }
        let next = zero_allocate(PPTokenList)
        res.token = token
        res.next = next
        res = next
    }

    res.token.kind = TokenKind::EOF
    return first
}

def lex(state: *State) -> PPToken {
    while state.i < state.input.length() {
        var token: PPToken
        var ch = peek(state)
        if ch == '#' {
            pop(state)
            yield from lex_directive(state)
        } else {
            token = lex_next_token(state)
            yield token
        }
    }
}

export def pp_tokens_to_json(list: *PPTokenList) -> &Json {
    let res = json::make_array()
    loop {
        let token = list.token
        let elem = json::make_object()
        elem["kind"] = to_string(token.kind)
        if token.kind != TokenKind::START and 
            token.kind != TokenKind::EOF and
            token.kind != TokenKind::EOL and
            token.kind != TokenKind::EMPTY {
            elem["value"] = token.value
        }

        res.push(elem)
        if not list.next {
            break
        }
        list = list.next
    }
    return res
}