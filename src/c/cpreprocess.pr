import vector
import map
import clexer
import util

type Define = struct {
    token: PPToken
    is_function_like: bool
    arguments: &Vector(PPToken)
    replacement_list: *TokenList
    nesting: int
}

type State = struct {
    prev: *TokenList
    list: *TokenList
    defines: &SMap(Define)
    context_stack: &Vector(Str)
    ifdef_stack: &Vector(bool)
}

def is_macro_disabled(state: *State, macro_name: Str) -> bool {
    for var context in state.context_stack {
        if context == macro_name {
            //error("Disabled! ", macro_name, "\n")
            return true
        }
    }
    return false
}

def copy_replacement_list(to_copy: *TokenList, tail: *TokenList, mask_operators: bool = false) -> *TokenList {
    var start = zero_allocate(TokenList)
    var result = start
    loop {
        @result = @to_copy
        // Make sure we don't expand these again
        if mask_operators and (result.token.kind == TokenKind::CONCAT or result.token.kind == TokenKind::STRINGIFY) {
            result.token.kind = TokenKind::PP_OPERATOR
        }

        to_copy = to_copy.next
        if not result.next or result.token.kind == TokenKind::EOL {
            break
        }
        let new = zero_allocate(TokenList)
        result.next = new
        result = new
    }
    result.next = tail
    return start
}

def delete_next(s: *State) {
    let next = s.list.next
    s.prev.next = next
    delete_single(s.list)
    s.list = next
}

def next_token(s: *State) {
    while s.list and s.list.token.kind == TokenKind::EOL {
        if s.context_stack.length > 0 {
            s.context_stack.pop()
        }
        delete_next(s)
    }
}

def skip_to_endif(s: *State) {
    while s.list and s.list.token.kind != TokenKind::P_ENDIF {
        delete_next(s)
    }
    delete_next(s)
    delete_next(s)
}

def skip_to_else(s: *State) {
    var nesting = 1
    while s.list {
        if s.list.token.kind == TokenKind::P_IF or 
            s.list.token.kind == TokenKind::P_IFDEF or
            s.list.token.kind == TokenKind::P_IFNDEF {
            nesting += 1
        } else if s.list.token.kind == TokenKind::P_ENDIF or 
            s.list.token.kind == TokenKind::P_ELSE or
            s.list.token.kind == TokenKind::P_ELIF {
            nesting -= 1
        }

        if nesting == 0 { break }

        delete_next(s)
    }
}

def find_argument(arguments: &Vector(PPToken), list: *TokenList) -> int {
    var arg_index = -1
    var i = 0
    for var arg in arguments {
        if arg.value == list.token.value {
            arg_index = i
            break
        }
        i += 1
    }
    return arg_index
}

export def preprocess(list: *TokenList) {
    let state = {
        list = list,
        defines = map::make(Define),
        context_stack = vector::make(Str),
        ifdef_stack = vector::make(bool)
    } !State

    preprocess(*state)

    for var key in @state.defines.keys() {
        let define = state.defines[key]
        delete(define.replacement_list)
    }
}

def preprocess(s: *State) {
    s.prev = s.list

    while s.list {
        let token = s.list.token
        if token.kind == TokenKind::P_UNDEF {
            delete_next(s)
            let name = s.list.token.value
            s.defines.remove(name)
            delete_next(s)
            delete_next(s)
        } else if token.kind == TokenKind::P_MACRO or token.kind == TokenKind::P_MACRO_FUNLIKE {
            let prev = s.prev
            delete_next(s)
            let name = s.list.token

            var args: &Vector(PPToken)
            if token.kind == TokenKind::P_MACRO_FUNLIKE {
                args = vector::make(PPToken)

                delete_next(s)
                delete_next(s)
                while s.list.token.kind != TokenKind::C_PAREN and s.list.token.kind != TokenKind::EOF {
                    if s.list.token.kind != TokenKind::COMMA {
                        args.push(s.list.token)
                    }
                    delete_next(s)
                }
            }

            let start = s.list.next
            delete_single(s.list)
            s.list = start
            while s.list and s.list.token.kind != TokenKind::EOL and 
                s.list.token.kind != TokenKind::EOF {
                s.list = s.list.next
            }
            if not s.list { return }
            let next = s.list.next
            s.list.next = null

            s.prev = prev
            s.prev.next = next
            s.list = next

            s.defines[name.value] = {
                token = name,
                is_function_like = token.kind == TokenKind::P_MACRO_FUNLIKE,
                replacement_list = start,
                arguments = args
            } !Define
        } else if token.kind == TokenKind::IDENTIFIER and 
            s.defines.contains(token.value) and 
            not is_macro_disabled(s, token.value) {
            
            if s.prev.token.kind == TokenKind::STRINGIFY or
                s.prev.token.kind == TokenKind::CONCAT or 
                (s.list.next and s.list.next.token.kind == TokenKind::CONCAT) {

                s.prev = s.list
                s.list = s.list.next

                continue
            }

            let prev = s.prev
            let list = s.list
            let define = *s.defines[token.value]

            delete_next(s)
            next_token(s)
            if s.list and s.list.token.kind == TokenKind::O_PAREN and define.is_function_like {
                //print("Pushing ", token.value, "\n")
                s.context_stack.push(token.value)
                delete_next(s)

                let arguments = vector::make(type *TokenList)

                var nesting = 0

                if not (s.list and s.list.token.kind == TokenKind::C_PAREN) {
                    while s.list and s.list.token.kind != TokenKind::EOF {
                        var arg_start = zero_allocate(TokenList)
                        arg_start.token.kind = TokenKind::START
                        var result = zero_allocate(TokenList)
                        arg_start.next = result

                        if s.list.token.kind != TokenKind::COMMA and s.list.token.kind != TokenKind::C_PAREN {
                            loop {
                                if result.token.kind == TokenKind::O_PAREN {
                                    nesting += 1
                                } else if result.token.kind == TokenKind::C_PAREN {
                                    nesting -= 1
                                }
                                
                                @result = @s.list
                                delete_single(s.list)
                                s.list = result.next

                                if nesting <= 0 and 
                                    (s.list.token.kind == TokenKind::COMMA or 
                                    s.list.token.kind == TokenKind::C_PAREN) {
                                    
                                    result.next = null
                                    break
                                }

                                let new = zero_allocate(TokenList)
                                result.next = new
                                result = new
                            }
                        }

                        //error("Arg: ", tokens_to_json(arg_start), "\n")
                        arguments.push(arg_start)

                        if s.list.token.kind == TokenKind::C_PAREN {
                            let next = s.list.next
                            delete_single(s.list)
                            s.list = next

                            break
                        }

                        let next = s.list.next
                        delete_single(s.list)
                        s.list = next
                    }
                }
                //s.list = s.list.next
                
                //if not s.list { return }

                let tokens = copy_replacement_list(define.replacement_list, null)
                var cur2 = tokens
                prev.next = tokens
                let rescan_start = prev
                s.prev = prev

                // Replacement of concat with arguments (or placemarkers)
                loop {
                    if cur2.next and cur2.next.token.kind == TokenKind::CONCAT {
                        if cur2.token.kind == TokenKind::IDENTIFIER {
                            let arg_index = find_argument(define.arguments, cur2)
                            if arg_index != -1 and arg_index < arguments.length {
                                let next = cur2.next
                                let rl = copy_replacement_list(arguments[arg_index], next, mask_operators = true)                                
                                let args = rl.next
                                delete_single(rl)

                                if args.token.kind == TokenKind::EMPTY {
                                    args.token.kind = TokenKind::PLACEMARKER
                                }
                                s.prev.next = args
                                delete_single(cur2)
                                cur2 = next.next
                                s.prev = next
                            }
                        } else {
                            cur2 = cur2.next.next
                        }
                    }
                    if s.prev.token.kind == TokenKind::CONCAT and cur2 and cur2.token.kind == TokenKind::IDENTIFIER {
                        let arg_index = find_argument(define.arguments, cur2)
                        if arg_index != -1 and arg_index < arguments.length {
                            let next = cur2.next
                            let rl = copy_replacement_list(arguments[arg_index], next, mask_operators = true)
                            let args = rl.next
                            delete_single(rl)

                            if args.token.kind == TokenKind::EMPTY {
                                args.token.kind = TokenKind::PLACEMARKER
                            }
                            s.prev.next = args
                            delete_single(cur2)
                            cur2 = next
                            //error(tokens_to_json(cur2), "\n")
                            continue
                        }
                    }

                    s.prev = cur2
                    if not cur2.next { break }
                    cur2 = cur2.next
                }

                s.prev = prev
                cur2 = prev.next
                //error(tokens_to_json(cur2), "\n")

                loop {
                    if cur2.token.kind == TokenKind::STRINGIFY {
                        s.prev.next = cur2.next
                        cur2 = cur2.next

                        let arg_index = find_argument(define.arguments, cur2)

                        if arg_index != -1 and arg_index < arguments.length {
                            let arg = arguments[arg_index].next
                            var str: StringBuffer = ""

                            var prev: *TokenList = null
                            var cur3 = arg
                            while cur3 and cur3.token.kind != TokenKind::EOL {
                                if prev and not (prev.token.loc.end_line == cur3.token.loc.line and 
                                    prev.token.loc.end_column == cur3.token.loc.column) {

                                    str += " "
                                }
                                if cur3.token.kind == TokenKind::STRING or cur3.token.kind == TokenKind::CHARACTER {
                                    for var c in cur3.token.value {
                                        if c == '\\' {
                                            str += "\\\\"
                                        } else if c == '"' {
                                            str += "\\\""
                                        } else {
                                            str += c
                                        }
                                    }
                                } else {
                                    str += cur3.token.value
                                }
                                prev = cur3
                                cur3 = cur3.next
                            }
                            cur2.token.kind = TokenKind::STRING
                            cur2.token.value = str
                        }
                    } else if cur2.next and cur2.next.token.kind == TokenKind::CONCAT {
                        let left = cur2
                        let op = cur2.next
                        let right = cur2.next.next
                        //error(left.token.kind, " ", right.token.kind, "\n")

                        if right { 
                            if left.token.kind == TokenKind::PLACEMARKER {
                                delete_single(left)
                                delete_single(op)
                                s.prev.next = right
                                cur2 = right
                                continue
                            } else if right.token.kind == TokenKind::PLACEMARKER {
                                let prev = left.next
                                left.next = right.next
                                delete_single(op)
                                delete_single(right)
                                cur2 = left
                                continue
                            } else {
                                // Concat!
                                var new_token = lex_next_token(left.token.value + right.token.value)
                                if new_token.kind == TokenKind::CONCAT {
                                    new_token.kind = TokenKind::PP_OPERATOR
                                }
                                let list = zero_allocate(TokenList)
                                list.token = new_token
                                list.next = right.next
                                s.prev.next = list
                                delete_single(left)
                                delete_single(op)
                                delete_single(right)
                                cur2 = list
                                continue
                            }
                        }
                    } else if cur2.token.kind == TokenKind::IDENTIFIER {
                        let arg_index = find_argument(define.arguments, cur2)
                        //error(arg_index, " ", cur2.token.value, " ", arguments.length, "\n")

                        if arg_index != -1 and arg_index < arguments.length {
                            var next = cur2.next
                            delete_single(cur2)
                            //error(tokens_to_json(arguments[arg_index]), "\n")
                            let args = copy_replacement_list(arguments[arg_index], null, mask_operators = true)
                            
                            // Preprocess as if it was the rest of the file
                            let list = s.list
                            let prev = s.prev
                            s.list = args

                            preprocess(s)
                            s.prev.next = next

                            s.list = list
                            s.prev = prev

                            //error("Args: ")
                            //error(tokens_to_json(args.next), "\n")
                            
                            next = args.next
                            delete_single(args)
                            s.prev.next = next
                            cur2 = s.prev.next
                        }
                    }

                    s.prev = cur2
                    if not cur2.next {
                        cur2.next = s.list
                        break
                    }
                    cur2 = cur2.next

                    //error("Next tokens: ")
                    //error(tokens_to_json(cur2), "\n")
                }
                s.list = rescan_start

                //error("Start at: ")
                //error(tokens_to_json(rescan_start), "\n")

                for var arg in arguments {
                    delete(arg)
                }
            } else if not define.is_function_like {
                s.context_stack.push(token.value)
                s.list = copy_replacement_list(define.replacement_list, s.list)
                s.prev.next = s.list
            }
        } else if token.kind == TokenKind::P_INCLUDE {
            let prev = s.prev
            let start = s.list
            next_token(s)
            var include = s.list.next.token
            if include.kind != TokenKind::INCLUDE_ANGLE and include.kind != TokenKind::INCLUDE_QOUTE {
                s.list = s.list.next
                
                let start2 = zero_allocate(TokenList)
                start2.token.kind = TokenKind::START
                start2.next = s.list

                s.prev = null
                s.list = start2
                while s.list and s.list.token.kind != TokenKind::EOL and s.list.token.kind != TokenKind::EOF {
                    s.prev = s.list
                    s.list = s.list.next
                }
                let next = s.list
                s.prev.next = null

                s.prev = null
                s.list = start2
                preprocess(s)

                var include_str: StringBuffer = ""
                s.prev = null
                s.list = start2
                while s.list and s.list.token.kind != TokenKind::EOL and s.list.token.kind != TokenKind::EOF {
                    if s.prev and not (s.prev.token.loc.end_line == s.list.token.loc.line and 
                        s.prev.token.loc.end_column == s.list.token.loc.column) {

                        include_str += " "
                    }

                    include_str += s.list.token.value
                    s.prev = s.list
                    s.list = s.list.next
                }

                include = lex_include(include_str)

                s.prev = prev
                s.prev.next = next
                s.list = next
            } else {
                delete_next(s)
            }

            let file = include.value
            for var path in include_path {
                let full_path = path + "/" + file
                if util::exists(full_path) {
                    var tokens = lex(full_path)
                    preprocess(tokens)
                    s.prev.next = tokens.next
                    s.prev = tokens
                    loop {
                        if not tokens.next or tokens.next.token.kind == TokenKind::EOF {
                            tokens.next = s.list.next
                            s.list = s.list.next
                            s.prev = tokens
                            break
                        }
                        s.prev = tokens
                        tokens = tokens.next
                    }
                    break
                }
            }
        } else if token.kind == TokenKind::P_IFDEF or token.kind == TokenKind::P_IFNDEF {
            var start = s.prev
            delete_next(s)
            let macro = s.list.token
            delete_next(s)
            if macro.kind != TokenKind::IDENTIFIER { continue }

            if s.defines.contains(macro.value) == (token.kind == TokenKind::P_IFNDEF) {
                s.ifdef_stack.push(false)
                skip_to_else(s)

                start.next = s.list
                s.prev = start

            } else {
                s.ifdef_stack.push(true)
                delete_next(s)
                start.next = s.list
            }
        } else if token.kind == TokenKind::P_ELIF {
            if s.ifdef_stack.peek() {
                skip_to_endif(s)    
            }
        } else if token.kind == TokenKind::P_ENDIF {
            delete_next(s)
            if s.ifdef_stack.length > 0 {
                s.ifdef_stack.pop()
            }
        } else if token.kind == TokenKind::P_ELSE {
            delete_next(s)
            if s.ifdef_stack.peek() {
                skip_to_endif(s)
            }  
        } else if token.kind == TokenKind::EOL {
            next_token(s)
        } else if token.kind == TokenKind::EMPTY or token.kind == TokenKind::PLACEMARKER {
            delete_next(s)
        } else {
            s.prev = s.list
            s.list = s.list.next
        }
    }

    //print(s.context_stack.length, "\n")
}

let include_path = [
    ".",
    "/usr/local/include",
    "/usr/include/x86_64-linux-gnu",
    "/usr/include"
]


/*
var input = """
    #define f(a) a*g
    #define g(a) f(a)
    f(1)(2)(3)
"""

let tokens = lex(input, "<snippet>")
preprocess(tokens)
let res = tokens_to_json(tokens)
delete(tokens)
print(res)*/